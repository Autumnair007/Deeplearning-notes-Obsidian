---
type: paper-note
tags:
  - cv
  - image-segmentation
  - mask-refinement
  - sam
  - full-supervision
  - semi-supervision
  - weakly-supervised
  - instance-segmentation
  - semantic-segmentation
  - tfs
status: done
model: SAMRefiner
year: 2025
---
论文网址：[[2502.06756] SAMRefiner: Taming Segment Anything Model for Universal Mask Refinement](https://arxiv.org/abs/2502.06756)

本地PDF文件：[SamRefiner](../../../../../99_Assets%20(资源文件)/images/SAMREFINER%20TAMING%20SEGMENT%20ANYTHING%20MODEL.pdf)
***
# SAMRefiner: 驯服Segment Anything模型实现通用掩码精修

## 摘要

本文提出了一种名为 SAMRefiner 的通用且高效的方法，旨在提升现有粗糙掩码的质量，使其能够作为分割模型可靠的训练数据，从而降低标注成本。与现有针对特定模型或任务的精修技术不同，SAMRefiner 通过调整 Segment Anything Model (SAM) 来完成掩码精修任务。我们模型的核心技术是**噪声容忍式提示方案**。具体来说，我们引入了**多提示挖掘策略**，从初始粗糙掩码中提取多样化的输入提示，包括：**距离引导点、上下文感知弹性边界框 (CEBox) 和高斯风格掩码**。这些提示可以相互协作，以减轻粗糙掩码中缺陷的影响。特别是，考虑到 SAM 在语义分割中处理多对象情况的局限性，我们引入了**分拆-合并 (STM) 流水线**。此外，我们还将方法扩展到 **SAMRefiner++**，通过引入一个额外的 **IoU 自适应步骤**，进一步提升通用 SAMRefiner 在目标数据集上的性能。该步骤是自增强的，无需额外标注。所提出的框架具有通用性，可以灵活地与现有分割方法协同工作。我们在各种基准测试的不同设置下评估了我们的掩码精修框架，展示了其更高的准确性和效率。SAMRefiner 在加速精修工具发展方面具有重要潜力。

## 1. 引言

图像分割旨在为图像中的每个像素分配一个标签，使得具有相同标签的像素共享某些特征。在过去几年中，图像分割取得了显著进展，但主流方法依赖于全标注训练图像，这通常耗时费力。为了减少人工成本，一种更高效的选择是利用现有模型（特别是那些在不完全监督下设计的模型，如无监督、弱监督或半监督标注）生成分割掩码。这些生成的分割掩码可以作为伪标签来训练先进的分割模型或迭代升级现有模型。随着数据量的不断增加，这种伪标签范式在扩展大规模学习数据集方面展现出巨大的实用性和潜力。然而，初始伪掩码通常存在噪声且缺乏细节，尤其是在对象边界或高频区域（参见图 1a），这阻碍了它们为模型训练提供可靠的监督。

![](../../../../../99_Assets%20(资源文件)/images/4d2d212bb4c888f2e3111c58f0e754e8.png)

图 1a 展示了分割掩码的可视化效果：左侧是初始掩码，中间是经过密集 CRF 精修后的掩码，右侧是经过我们框架精修后的掩码。通过对比可以看出，我们的框架在细节和边界处理上表现更好。

**现有掩码精修技术的局限性**：
1. **模型依赖性 (model-dependent)**：某些方法开发定制的精修模块，为特定网络量身定制，并以端到端方式进行训练，使其无法在不同模型上工作。
2. **任务特定性 (task-specific)**：另一类技术采用模型无关的精修机制，但通常只专注于特定任务（例如，语义分割或实例分割）。
3. **类别受限 (category-limited)**：大多数先前的工作需要使用带标注数据的目标数据集进行训练，这限制了它们推广到未见类别和粒度的能力。
4. **时间效率低下 (time-inefficient)**：最近的工作虽然表现出更好的性能，但每次只能精修一个实例，这在复杂的实例分割任务中效率低下。

最近，**Segment Anything Model (SAM)** 作为一个交互式图像分割模型被提出，它通过用户提供的提示（例如点、框）来分割目标对象，并在许多图像分割任务中取得了显著成功。一些研究人员试图将 SAM 应用于各种任务，以利用其强大的表示能力来缓解训练样本不足的问题。然而，这些研究大多关注从头预测掩码，**如何将 SAM 适配到现有粗糙掩码的掩码精修任务中仍然是一个未被探索且具有挑战性的问题**。我们认为，由于广泛存在的现有掩码（例如离线模型提供的掩码、不准确的人工标注或其他形式的预处理），这项任务在实际应用中具有巨大价值。对其进行修改可以促进标注并有益于各种下游任务。

然而，由于 SAM 是**提示驱动**的，将 SAM 适配到精修任务并非易事，因为仅从粗糙掩码中难以获得准确的提示。直接使用朴素策略将 SAM 应用于掩码精修会导致提示失真，从而产生次优性能。例如，在图 2 中，我们采用了常用的框提示（粗糙掩码的紧密边界框），并观察到这种朴素的方法未能获得令人满意的性能，因为粗糙掩码中包含的各种错误（例如，假阴性、假阳性）会误导提示提取。此外，直接将粗糙掩码作为提示对 SAM 来说效果也很差（图 2 中的第 4 列），这是由于其预训练的固有性质。（更多提示分析在方法部分和附录中提供。）因此，**如何从粗糙掩码中挖掘噪声容忍的提示是一个巨大的挑战。**

![](../../../../../99_Assets%20(资源文件)/images/9d9d8914a7b3ebdf076c6f92ab214e1b.png)

图 2 展示了 SAM 使用粗糙掩码的紧密边界框（红色框）和直接使用粗糙掩码作为提示的失败案例。紧密边界框对粗糙掩码中的假阴性（第一行）和假阳性（最后一行）错误很敏感，这会误导 SAM 的预测。独立的掩码提示对 SAM 也无效。我们提出的多提示挖掘策略对噪声具有鲁棒性。

在本文中，我们驯服 SAM 以完成掩码精修任务，该任务因粗糙掩码的存在而具有独特的特点。我们提出了一个通用且高效的框架，名为 SAMRefiner，其核心技术是**噪声容忍式提示方案**。具体而言，为了减轻粗糙掩码中缺陷对提示生成的影响，我们提出了**多提示挖掘策略**，以挖掘多样且看似合理的提示，包括**距离引导点、上下文感知弹性边界框 (CEBox) 和高斯风格掩码**。这些多提示可以相互协作，生成高质量的掩码，并且比单一提示对噪声更具鲁棒性。为了克服多对象情况造成的混淆，我们引入了**分拆-合并 (STM) 流水线**，使其更适用于语义分割。同时，考虑到原始 SAM 缺乏数据集特定的先验知识，导致 IoU 分支预测不准确，我们提出了 **SAMRefiner++**。该方法通过利用粗糙掩码先验知识，引入了一个额外的 IoU 自适应步骤，以增强 SAM 在特定数据集上的预测准确性。这种最小化自适应策略以**自增强**的方式运行，无需额外标注。

我们对各种语义和实例分割设置进行了实验，使用不完全监督、现有模型和合成数据生成的伪掩码。实验结果表明 SAMRefiner 具有出色的掩码精修能力（参见图 1b）。我们的方法是一种通用的后处理工具，可以自训练方式整合到任何图像分割方法中，并持续改进性能。

![](../../../../../99_Assets%20(资源文件)/images/c660b027e67c670ac09cde8d81f7f871.png)

**我们的贡献总结如下：**
* **新路线图 (New Roadmap)**：SAMRefiner 首次提出基于 SAM 的掩码精修解决方案，在实际应用中具有巨大价值。
* **新方法 (New Method)**：我们发现了 SAM 在掩码精修任务中的不足，并提出了一个有效且高效的框架来挖掘噪声容忍的提示，成功解决了这一具有挑战性的通用掩码精修任务。
* **新见解 (Novel Insights)**：尽管我们的工作基于 SAM，但它提供了一些新颖的见解和观察，如掩码提示的影响和 IoU 自适应策略。
* **更强的实用性和性能 (Stronger practicality and performance)**：该框架具有通用性，可以灵活地与各种设置下的现有分割方法协同工作。它显著提高了伪掩码质量（例如，WSSIS 提高了 10% 以上），同时耗时更少（例如，比 CascadePSP 快 5 倍）。

## 2. 相关工作

### 2.1 图像分割中的粗糙掩码

由于像素级精确标注的严格标准，粗糙掩码在图像分割任务中普遍存在。为了减轻人工负担，一些工作采用伪标签范式来获取分割掩码。这些方法通常利用不完全标注（例如，无、点、框、图像级标签或部分全标注数据）来获取分割掩码，大致可分为无监督、弱监督和半监督。尽管节省了人工，但伪掩码的质量不尽如人意，这可能严重损害后续分割模型训练的性能。即使在人工标注中也存在噪声标签（例如 MS COCO），这对于实现大规模像素级精确标注是不可避免的。本文旨在提高粗糙掩码的质量，从而为后续模型训练做出贡献。

### 2.2 掩码精修技术

为了克服粗糙掩码的不准确性，已经探索了几种掩码精修方法。大多数现有工作是为特定网络或任务设计的，因此缺乏通用性和灵活性。例如，PointRend 和 RefineMask 构建在 Mask R-CNN 之上用于实例分割；BPR 提出了一种模型无关的后处理机制，但主要关注实例分割。在封闭世界范式中对数据集进行依赖性训练使它们容易过拟合特定数据集。CascadePSP 和 CRM 在一个大型合并数据集上进行训练，并在不同的语义分割数据集上表现良好，但性能在复杂的实例分割设置中较差。SegRefiner 将分割精修解释为数据生成过程，但扩散步骤对于实际使用来说效率低下。密集 CRF 是一种无需训练的后处理方法，但它缺乏高级语义上下文，并且通常难以在复杂场景中工作。不同的是，我们的目标是设计一种通用的、通用且高效的后处理工具，适用于多样的分割模型、任务和数据集，使其成为一个具有广泛应用的高度有意义和有价值的工具。

### 2.3 Segment Anything Model

Segment Anything Model (SAM) 被认为是可提示图像分割的里程碑式视觉基础模型。一些工作利用这个强大的基础模型来促进下游视觉任务，包括目标跟踪、图像编辑、3D 对象重建和许多现实世界场景，而 SAM 在分割精修任务中的潜力以及不同提示类型的影响鲜有探索。

## 3. 方法

在本节中，我们介绍了我们提出的掩码精修框架，如图 3 所示。我们首先回顾 SAM 的架构及其用法。然后，我们介绍了利用 SAM 的多提示挖掘策略。我们进一步提出了一种高效的自适应变体，以自增强的方式提高 IoU 预测的准确性。

![](../../../../../99_Assets%20(资源文件)/images/381b5dfc8616ca2bd6f5cff612f37775.png)

图 3 提供了我们提出框架的概览：
(a) SAMRefiner：它利用 SAM 通过从粗糙掩码中自动生成提示来精修粗糙掩码，这些提示包括距离引导点、上下文感知弹性边界框和高斯风格掩码。我们根据 SAM 的 IoU 预测从多个生成的掩码中选择最佳掩码。
(b) IoU 自适应：旨在增强特定数据集上 SAM 的 IoU 预测能力。我们在 IoU MLP 的最后一层采用 LoRA 风格的适配器，并使用排序损失来提高 IoU 预测的 Top-1 准确性。该步骤是自增强的，无需额外标注。

### 3.1 SAM回顾

我们首先介绍 SAM 的组件，它由**图像编码器 (Image Encoder)、提示编码器 (Prompt Encoder) 和掩码解码器 (Mask Decoder)** 组成。
1. **图像编码器** 基于一个由 MAE 预训练的标准 Vision Transformer (ViT)。它生成输入图像的 $16 \times$ 下采样嵌入。
2. **提示编码器** 可以是**稀疏的 (sparse)**（点、框、文本）或**密集的 (dense)**（掩码）。对于稀疏提示，点和框被表示为位置编码与学习到的嵌入相加。文本提示由 CLIP 的文本编码器处理。密集提示直接与图像嵌入进行卷积并按元素相加。
3. **掩码解码器** 采用基于提示的自注意力 (self-attention) 和双向交叉注意力 (two-way cross-attention)。这允许提示到图像和图像到提示嵌入之间的交互，从而能够同时更新编码的图像和提示特征。经过两个解码器层后，输出的掩码 token 由一个 3 层 MLP 处理，然后与上采样的图像嵌入进行空间点积，以获得目标掩码。

SAM 能够为每个输入提示生成单个掩码或多个掩码（即三个掩码）。多掩码模式旨在解决歧义问题，并采用一个额外的 IoU token 来学习每个掩码的置信度，这反映了每个预测掩码与目标对象之间的 IoU。在图 5a 中，我们凭经验发现，通过简单地选择具有最佳 IoU 预测的掩码，多掩码模式通常优于单掩码模式，因此我们在实验中采用了多掩码模式。

### 3.2 提示挖掘 (Prompt Excavation)

作为一种可提示的分割模型，输入提示在 SAM 中扮演着至关重要的角色，因为这些提示提供了目标对象的定位指导。为了将 SAM 用于掩码精修，我们需要仅根据初始粗糙掩码来挖掘提示，这对于噪声和缺陷的存在具有挑战性。与之前大多数只使用一种提示的工作不同，我们的提示挖掘策略旨在挖掘多样且看似合理的提示（包括点、框和掩码），使它们相互协作以减轻粗糙掩码中缺陷的影响。请注意，SAM 无法仅使用掩码作为单独的输入提示，我们将在后续部分提供分析。

**点 (Points)**。点提示可以提供前景或背景对象的位置信息。然而，在使用二值粗糙掩码时，很难确定最显著的点。为了解决这个挑战，我们利用了一个简单但经验有效的**以对象为中心**的先验知识：对象的中心倾向于是正向且具有特征区分性的，而模糊性主要位于边界。基于这个标准，我们选择距离最近背景位置最远的前景点作为**正向提示**。类似地，**负向提示**应满足以下原则：1) 该点离前景区域最远；2) 该点位于前景区域的边界框内。

**框 (Boxes)**。框提示由于其包含的丰富线索而显示出更强大的定位能力。给定一个二值掩码，很容易找到前景区域的最大边界矩形（紧密边界框）作为框提示。然而，粗糙掩码中的**假阴性像素**可能会损害边界框的质量，导致对潜在对象的覆盖不完整（图 4a）。

![](../../../../../99_Assets%20(资源文件)/images/ddae6ce312902e189e17008755cf30a3.png)

图 4a 展示了上下文感知弹性框（前两行）和掩码提示（后两行）的效果。所有这些都对减轻粗糙掩码中缺陷的影响起着关键作用。

为了解决这个问题，我们提出了**上下文感知弹性边界框 (CEBox)** 来有条件地调整紧密边界框。边界框可以根据周围上下文向四个方向扩展。具体来说，输入图像 $I \in R^{H \times W \times 3}$ 通过图像编码器编码为 SAM 潜在空间中的特征嵌入 $F_{im} \in R^{h \times w \times c}$，其中 $(H, W)$ 和 $(h, w)$ 分别表示原始图像大小和嵌入大小。粗糙掩码 $M_{coarse} \in R^{H \times W}$ 被调整大小为 $\hat{M} \in R^{h \times w}$ 以与 $F_{im}$ 对齐。我们计算粗糙掩码的平均特征嵌入（表示为查询嵌入），如下所示：
$$F_{query} = \frac{1}{|1_{\hat{M}>0}|} \sum_{1_{\hat{M}>0}} (F_{im})$$
其中 $1_{\hat{M}>0} \in \{0,1\}$ 是用于确定前景区域的指示函数，$| \cdot |$ 表示元素数量。我们计算 $F_{query}$ 与调整大小后的图像嵌入 $\hat{F}_{im} \in R^{H \times W \times c}$ 中每个空间位置的亲和力，以获得相似度图 $Sim \in R^{H \times W}$ 并将其二值化为 0.5：
$$Sim = [F_{query} \cdot \hat{F}_{im}]_{\gt=0.5}$$
对于 $\{left, right, up, down\}$ 中的每个方向，我们将紧密边界框 $B$ 扩大其相应边长的 10%，并近似计算扩展区域中的正向比例 $Sim_{context}$。使用阈值 $\lambda$ 来确定在该方向上扩展当前框的必要性。为了避免过度放大，我们每次限制最大扩展像素数量，并进行多次迭代以进行渐进式扩展。

**掩码 (Masks)**。大多数现有工作使用点或框作为初始提示，而掩码提示通常被丢弃。掩码无法单独作为 SAM 的初始输入提示（参见图 2 中的定性结果和表 1 中的定量结果）。这是因为掩码提示在 SAM 预训练期间的级联精修中仅作为点和框的辅助，以前一次迭代的预测 logits 作为输入来指导下一次迭代。然而，我们认为掩码提示对于掩码精修任务中区分前景和背景至关重要，尤其是在框提示失效的情况下（例如，过大的框导致图 4a 中错误检测到对象或背景）。考虑到粗糙掩码的不准确性，我们利用基于点提示中使用的距离变换的**高斯风格掩码 $GM$**：
$$GM(x,y) = \omega \cdot \exp(-\frac{(x-x_0)^2 + (y-y_0)^2}{|1_{M_{coarse}>0}| \cdot \gamma})$$
其中 $GM(x,y)$ 表示位置 $(x,y)$ 处的掩码提示，$(x_0,y_0)$ 是距离背景区域最远的掩码中心点，$\omega, \gamma$ 是控制分布振幅和跨度的因子。我们在附录 C.2 中提供了高斯掩码的详细分析。

**在语义分割中的应用 (Application on Semantic Segmentation)**。语义分割掩码是类别感知型的，在一个语义掩码中可能存在许多对象。在图 4b 中，我们发现 SAM 在使用常用提示分割大跨度的多个对象时会遇到困难（要么漏检要么误检）。虽然掩码提示可以缓解这个问题，但当不同类别的对象混杂在一起时，它仍然会失效。我们进一步提出了**分拆-合并 (STM) 流水线**来解决这个问题。1) **分拆 (Split)**：我们通过查找所有连接区域来分拆掩码。请注意，由于粗糙掩码的不准确性，一些区域是带噪声且微不足道的。2) **合并 (Merge)**：为了形成语义上有意义的区域，我们根据边界框面积变化和掩码面积占用情况迭代地合并相邻区域。只有当区域合并前后边界框面积变化很小且合并后的边界框掩码面积占用率足够时，才会合并两个区域。算法 1 中提供了该策略的详细说明。

![](../../../../../99_Assets%20(资源文件)/images/4f485f22e25ed5e682ffb7e664565bd1.png)

图 4b 展示了所提出的分拆-合并 (STM) 策略的效果。

### 3.3 IoU 自适应 (IoU Adaption)

对于 SAM，生成掩码的质量由输入提示决定，而最佳掩码的选择基于 IoU 预测（表示为 $IoU_{pred}$）。传统的 SAM 在给定多个提示时使用单个 token 来生成掩码（单掩码模式）。然而，在图 5a 中，我们经验性地观察到，在所有提示组合下，基于 $IoU_{pred}$ 从 SAM 的多个预测中选择最佳掩码通常优于单掩码模式。我们在附录 C.4 中提供了详细分析。然而，在图 5b 中，我们发现基于 $IoU_{pred}$ 的掩码选择仍然达不到上限（通过真实值 IoU $IoU_{GT}$ 选择掩码），这表明 SAM 的 Top-1 IoU 预测不准确。这是因为上述 SAMRefiner 是免训练且适用于大多数情况的，但对下游类别是不可知的。SAM 的 IoU 头未针对目标对象进行专门训练，导致 IoU 预测次优。

![](../../../../../99_Assets%20(资源文件)/images/15b0b02ff91f641526c6b25f3a002e6e.png)

图 5 展示了不同提示类型、掩码模式和 IoU 选择标准对 DAVIS-585 的影响。
(a) 使用不同提示类型的掩码质量。
(b) 不同 IoU 选择标准的效果。
(c) 使用不同 IoU 选择标准的 Top-1 准确率。

对于掩码精修任务，由于真实值掩码不可用，我们提出粗糙掩码可以作为有效的先验知识来指导特定领域的 IoU 预测。为了验证这一点，我们表示 SAM 的输出掩码与粗糙掩码之间的 IoU 为 $IoU_{coarse}$，并比较 $IoU_{coarse}$ 与 $IoU_{pred}$ 的 Top-1 IoU 准确性。图 5c 中的结果表明，对于简单的点和框提示，基于 $IoU_{coarse}$ 的 Top-1 性能优于 $IoU_{pred}$，并且接近基于真实值的性能。相比之下，粗糙 IoU 在多提示情况下表现较差。这可能是因为较少的提示为 SAM 提供了模糊的指导，导致变体掩码，使得粗糙掩码在选择目标掩码方面提供有效指导。然而，多提示生成的掩码质量优于粗糙掩码，因此可能会误导选择。为了追求更好的性能，我们通过在单提示情况下进行训练，并由 $IoU_{coarse}$ 进行监督，来增强 SAM 的 IoU 排序能力，并期望它能惠及多提示情况。这个过程以**自增强**的方式进行，无需额外标注。

具体来说，我们专注于对 SAM 进行最小化的自适应，以实现更好的 IoU 预测。为了保留 SAM 的零样本迁移能力，我们固定了预训练 SAM 的模型参数，仅在 IoU 头部添加了一个 **LoRA 风格的适配器**，如图 3b 所示。考虑到 $IoU_{coarse}$ 的不准确性，我们采用**基于排序的损失**而不是回归损失。特别是，对于每个 SAM 预测掩码 $M_i$ 及其预测 IoU $x_i$，我们计算它们的粗糙 IoU，并将具有最佳粗糙 IoU 的掩码索引表示为 $j$。成对排序损失计算如下：
$$loss = \sum_{i=1, i \ne j}^n \max(0, x_i - x_j + m)$$
其中 $n$ 是总掩码数（SAM 为 3），$m$ 是控制最小差异的边距。这个损失鼓励最佳 IoU 分数 $x_j$ 高于其余分数，从而提高 Top-1 预测的准确性。我们基于单提示训练适配器，并在推理期间使用多提示。请注意，尽管 LoRA 流行，但其最佳放置位置仍不明确。先前的工作在某些特定层（例如骨干网络）凭经验放置 LoRA 层，改变现有知识以适应新域，这修改了学习到的知识并影响了掩码生成。相比之下，我们的方法将 LoRA 层插入到 IoU 头部，保留了 SAM 生成高质量掩码的全部能力，同时改进了掩码选择。据我们所知，这种最小化的自适应尚未得到充分探索，并且可能为该领域提供新的见解。我们将带有此自适应步骤的 SAMRefiner 表示为 **SAMRefiner++**，它仅关注在目标数据集上选择更好的掩码，对掩码生成没有影响。

## 4. 实验

### 4.1 实验设置

**数据集和实现细节 (Datasets and Implementation Details)**。为了全面评估 SAMRefiner 的掩码精修性能，我们在各种基准测试中进行了实验，包括专门用于掩码纠正的 DAVIS-585、实例分割的 COCO 和语义分割的 VOC，涵盖了不同的设置。作为掩码精修器，我们的方法与每个基线保持相同的设置以进行配对比较。我们使用的指标包括 (边界) IoU、(边界) 掩码 AP 和 mIoU。框和掩码提示中使用的阈值 $\lambda$ 和 $\mu$ 分别设置为 0.1 和 0.5。高斯分布的因子 $\omega, \gamma$ 默认设置为 15 和 4。我们采用带有 ViT-H 图像编码器的预训练 SAM 作为分割基础模型，更多细节在附录中提供。

### 4.2 消融实验

在本节中，我们进行了详细的消融研究，以分析我们框架中每个组件的效果。我们主要在 DAVIS-585 上进行实验，因为它专门用于掩码纠正，并且包含掩码中的各种缺陷。我们还利用流行的 COCO 和 VOC 来评估我们方法在特定场景下的表现。

**不同提示和 IoU 自适应的效果 (Effect of different prompts and IoU adaption)**。表 1 显示了使用不同提示的 SAMRefiner 的性能。结果表明，我们提出的多提示挖掘策略优于单一提示。掩码提示在以往工作中很少被考虑，其单独使用时表现不佳，但对于点和框，可以带来近 20% IoU 的显著优势。此外，我们比较了 SAM 原始 IoU 预测（数字前 /）和我们自适应 IoU 头部（数字后 /）的掩码选择。IoU 自适应步骤可以显著提高最佳掩码选择的 Top-1 准确率，并进一步有益于最终的 IoU 性能。为了篇幅限制，我们在附录中提供了更多的消融研究。

表 1: 使用不同提示精修掩码的质量以及 IoU 自适应对 DAVIS-585 的影响。结果表示为 SAMRefiner / SAMRefiner++。

| 提示类型         | IoU (总体/边界) | Top-1 Acc   |
| ------------ | ----------- | ----------- |
| Coarse Mask  | 81.4 / 71.4 | -           |
| Point        | 53.7 / 56.4 | 51.5 / 62.1 |
| Box          | 68.8 / 70.8 | 36.4 / 56.8 |
| Mask         | 37.3 / 40.4 | 28.4 / 30.8 |
| Point + Box  | 76.7 / 79.1 | 37.1 / 53.7 |
| Point + Mask | 77.5 / 80.6 | 43.2 / 72.6 |
| Box + Mask   | 84.6 / 85.1 | 36.2 / 60.7 |
| ALL          | 86.9 / 87.1 | 44.1 / 63.8 |

**SAMRefiner 中不同设计选择的效果 (Effect of different design choices in SAMRefiner)**。我们分析了每个提示的不同设计选择的影响，并在表 2 中报告了它们的相对贡献。（1）我们在表 2a 中比较了采样正向点提示的不同策略，包括从粗糙掩码中随机选择、选择边界框中心以及选择距离背景最远的点。与随机选择相比，使用边界框中心表现更差。这是因为边界框对掩码中的噪声（例如，遥远的假阳性）很敏感，导致边界框中心不准确。我们的距离引导点对噪声更具鲁棒性，仅使用一个正向点即可获得 52.5% 的 IoU。通过添加第 3.2 节中提到的额外负向点，性能可以进一步提高到 53.7%。（2）表 2b 显示了使用紧密边界框和上下文感知弹性边界框 (CEBox) 的影响。我们采用 PointWSSIS 在 COCO 上生成的粗糙掩码，这些掩码通常存在不完整的问题。所提出的 CEBox 可以生成具有更高 $AP_{box}$ 并有益于掩码生成的更好边界框。（3）在表 2c 中，我们比较了常用的 mIoU 使用/不使用 STM 的情况。结果表明，STM 可以为极其粗糙的掩码带来显著的改进（例如，MaskCLIP 提高了 6.2%），并且可以持续提升更好的初始掩码的性能。

表 2: 我们提出的策略在不同案例下的消融研究。

![](../../../../../99_Assets%20(资源文件)/images/d96a72f6c2dab87ad86bd76c41c5fc28.png)

### 4.3 不完全监督的应用

**实例分割 (Instance Segmentation)**。为了验证我们框架的有效性，我们将其应用于各种典型方法，包括无监督 (CutLER)、半监督 (NoisyBoundary) 和弱半监督 (PointWSSIS)。实验在 COCO 上进行，遵循这些方法。我们从两个方面评估掩码质量：1) 伪掩码在训练集上的性能；2) 基于这些伪掩码训练的最终分割模型的性能。伪掩码在 COCO 训练集的一个子集（训练 5K）上进行评估，最终分割模型在验证集上进行评估。我们比较了常用的掩码 AP 和边界 AP。表 3 中的结果表明我们框架的优越性。它可以在所有设置下持续提升伪掩码的质量，特别是对于那些标签受限的场景（例如，PointWSSIS 在 1% 标注下可以达到 10.3% 的改进）。此外，分割模型也可以从精修后的掩码中受益，在不同设置下都有显著改进，这表明 SAM 可以提供有价值的知识和线索来改善这些标签受限的场景。

表 3: COCO 2017 上不同监督下实例分割的结果。标注表示监督类型，包括 U（未标注）、P（点级标签）、F（全标注）。网络代表基于伪掩码训练的最终分割模型。我们遵循每个基线方法的默认设置。

| 方法       | 标注          | 网络           | COCO train5K (AP mask / AP boundary) | COCO val2017 (AP mask / AP boundary) |
|------------|---------------|---------------|-------------------------------------|---------------------------------------|
| **Unsupervised** |               |               |                                     |                                       |
| CutLER     | None          | Cascade R-CNN | -- / --                             | 8.8 / 2.8                             |
| +SAMRefiner| None          | Cascade R-CNN | -- / --                             | 12.1 (+3.3) / 5.0 (+2.2)              |
| **Semi-supervised** |               |               |                                     |                                       |
| NBF        | 1% + U99%     | Mask R-CNN    | 4.4 / 1.6                           | 6.7 / 2.3                             |
| +SAMRefiner| F1% + U99%    | Mask R-CNN    | 6.9 (+2.5) / 4.4 (+2.8)             | 11.8 (+5.1) / 6.5 (+4.2)              |
| NBF        | 5% + U95%     | Mask R-CNN    | 18.3 / 8.8                          | 24.0 / 12.4                           |
| +SAMRefiner| F5% + U95%    | Mask R-CNN    | 22.3 (+4.0) / 14.4 (+5.6)           | 27.4 (+3.4) / 16.5 (+4.1)             |
| NBF        | 10% + U90%    | Mask R-CNN    | 23.0 / 11.8                         | 28.9 / 16.3                           |
| +SAMRefiner| F10% + U90%   | Mask R-CNN    | 26.1 (+3.1) / 17.0 (+5.2)           | 30.5 (+1.6) / 18.6 (+2.3)             |
| **Weakly Semi-supervised** |               |               |                                     |                                       |
| PointWSSIS | F1% + P99%    | SOLOv2        | 15.1 / 6.7                          | 23.9 / 11.5                           |
| +SAMRefiner| F1% + P99%    | SOLOv2        | 25.4 (+10.3) / 16.3 (+9.6)          | 30.2 (+6.3) / 18.2 (+6.7)             |
| PointWSSIS | F5% + P95%    | SOLOv2        | 32.3 / 19.7                         | 33.4 / 19.6                           |
| +SAMRefiner| F5% + P95%    | SOLOv2        | 37.7 (+5.4) / 25.9 (+6.2)           | 34.6 (+1.2) / 21.6 (+2.0)             |
| PointWSSIS | F10% + P90%   | SOLOv2        | 39.9 / 26.4                         | 35.5 / 21.9                           |
| +SAMRefiner| F10% + P90%   | SOLOv2        | 42.8 (+2.9) / 30.2 (+3.8)           | 36.1 (+0.6) / 22.9 (+1.0)             |


**语义分割 (Semantic Segmentation)**。表 4 显示了无监督语义分割 (MaskCLIP) 和弱监督语义分割 (BECO 和 CLIP-ES) 生成的伪掩码的改进。我们精修了训练集上的伪掩码，并使用它们训练了一个 DeepLabV2 模型。结果表明，我们的方法为伪掩码和分割模型都带来了明显的性能提升。伪掩码的平均改进超过 5%，对于 MaskCLIP 和 CLIP-ES 甚至接近 10%。在各种数据集和设置下的卓越性能证明了我们框架的通用性和灵活性。

表 4: PASCAL VOC 2012 上不同监督下语义分割的结果。标注表示监督类型，包括 U（未标注）、I（图像级标签）。验证集上的结果基于训练的 DeepLabV2 模型。

| 方法       | 标注 | mIoU(train) | mIoU(val) |
|------------|-----|-------------|-----------|
| MaskCLIP   | U   | 47.8        | 47.3      |
| +SAMRefiner| U   | 57.3 (+9.5) | 53.5 (+6.2)|
| BECO       | I   | 66.3        | 69.5      |
| +SAMRefiner| I   | 71.8 (+5.5) | 70.9 (+1.4)|
| CLIP-ES    | I   | 70.8        | 70.3      |
| +SAMRefiner| I   | 79.3 (+8.5) | 74.9 (+3.6)|

### 4.4 与最先进方法的比较

在表 5 中，我们将我们的 SAMRefiner 与最先进的模型无关精修方法进行了比较，包括密集 CRF、CascadePSP、CRM 和 SegRefiner。我们首先在之前使用的 DAVIS-585、COCO 和 VOC 上进行了实验。结果证明：1) CRF 由于缺乏高级语义上下文且不适合二值掩码而表现较差。2) CascadePSP 和 CRM 在语义分割（VOC）上表现出竞争力，但在实例分割（DAVIS-585 和 COCO）上改进有限甚至比粗糙掩码更差。这可能是因为这些方法在包含极其精确掩码标注的合并数据集上进行训练，这与 VOC 关系密切，使得它们无法推广到像 COCO 这样复杂的场景。我们还在附录中探讨了在 SAM 上使用高质量数据集（即 HQ-SAM）的情况。3) SegRefiner 的性能在不同设置下不稳定，因为它缺乏处理粗糙掩码中各种缺陷的能力。4) SAMRefiner 更通用，并且由于其对掩码噪声更好的鲁棒性，可以在各种数据集上显著提高性能。

表 5: 与 SOTA 方法的比较。CM 代表粗糙掩码。

| 数据集            | CM   | CRF  | PSP  | CRM  | SR   | Ours |
| -------------- | ---- | ---- | ---- | ---- | ---- | ---- |
| **DAVIS-585**  |      |      |      |      |      |      |
| DAVIS-585      | 81.4 | 81.0 | 81.9 | 82.9 | 80.3 | 87.1 |
| **COCO**       |      |      |      |      |      |      |
| NB             | 15.2 | 13.9 | 15.9 | 15.1 | 15.8 | 18.4 |
| PointWSSIS     | 29.1 | 24.4 | 28.9 | 25.6 | 29.7 | 35.3 |
| MaskRCNN       | 35.2 | 31.5 | 34.6 | 31.7 | 35.4 | 36.5 |
| **PASCAL VOC** |      |      |      |      |      |      |
| MaskCLIP       | 47.8 | 48.2 | 55.3 | 56.8 | 58.5 | 57.3 |
| BECO           | 66.3 | 66.5 | 68.4 | 69.0 | 68.7 | 71.8 |
| CLIP-ES        | 70.8 | 72.6 | 76.9 | 78.7 | 74.7 | 79.3 |
| DeepLabV2      | 76.5 | 77.8 | 81.2 | 81.6 | 83.1 | 78.8 |
| Time (h)       | -    | 1.0  | 3.4  | 1.5  | 1.4  | 0.6  |

此外，我们比较了精修 COCO train5K (包含大约 5K 图像和 37K 掩码) 的总耗时。CRF 使用 16 个工作线程进行测试，其他方法基于一个 3090 GPU。SAMRefiner 的推理时间不到先前方法的一半，因为 SAM 可以同时批量处理图像中的多个掩码，而其他方法每次只能精修一个掩码。批量处理能力使 SAMRefiner 在实际使用中更高效且更具竞争力。

另外，考虑到 COCO 数据集中使用的原始真实标注不准确，我们遵循 SegRefiner 的方法，使用 LVIS 标注评估 COCO 验证集上不同全监督分割模型的预测结果。表 6 中的结果表明，我们的方法大幅优于其他工作，并且可以持续增强各种网络（例如，CNN 和 Transformer）生成的掩码质量，验证了其广泛应用的通用性。

表 6: 使用 LVIS 标注在 COCO val 集上精修掩码的性能。

![](../../../../../99_Assets%20(资源文件)/images/e6fbc83e678344916dbc759aa07a2be2.png)

## 5. 结论

本文揭示了 SAM 在掩码精修任务中的不足，并提出了一个通用且高效的框架 SAMRefiner，用于将 SAM 适配到掩码精修。我们提出了一种多提示挖掘方法来生成对粗糙掩码中的缺陷具有鲁棒性的多样化提示。引入了一个可选的 IoU 自适应步骤，无需额外标注数据即可进一步提升目标数据集上的性能。我们在各种图像分割基准测试的不同设置下评估了 SAMRefiner，展示了其持续的准确性和效率。

## 6. 致谢

这项工作部分得到了中国国家重点研发计划（NO.2022ZD0160101, NO.2022ZD0160102）的支持。

---

## 附录

### A. 额外的细节

#### A.1 数据集细节

**DAVIS-585**。DAVIS-585 在 FocalClick 中提出，用于评估交互式掩码校正任务。它包含 585 个样本，通过使用超像素模拟地面真值掩码上的缺陷来生成有缺陷的初始掩码。存在不同类型的缺陷，例如边界错误、外部假阳性、内部真阴性，使其成为掩码校正任务的综合基准。

**MS COCO 2017**。COCO 包含 80 个对象类别和一个背景类别，拥有 118,287 个训练样本和 5,000 个验证样本。我们遵循先前的工作在 COCO 上进行实例分割实验。为了确保公平比较，我们保持与每个基线方法相同的数据子集划分（例如，1%、5%、10%）。我们通过随机采样 5,000 张训练集图片（表示为 train5K）来评估伪标签质量，这些图片与标注数据子集没有交集。

**PASCAL VOC 2012**。我们遵循 Lin 等人的方法在 PASCAL VOC 2012 上进行语义分割实验。它包含 20 个类别和一个背景类别。我们在包含 1464 张图像的训练集上评估伪掩码质量。一个包含 10,582 张图像的增强集通常用于 WSSS 任务中的训练。

#### A.2 实现细节

我们使用 PyTorch 实现了我们的方法。对于 SAMRefiner，我们没有使用多尺度策略，图像在通过 SAM 处理之前保持其原始大小。对于 IoU 自适应步骤，我们使用 SGD 优化器，学习率为 0.01。批量大小设置为 5，我们只训练 1 个 epoch。学习率在第 60 步和第 100 步降低到十分之一。我们使用边距排序损失，边距为 0.02，LoRA 秩设置为 4。请注意，IoU 自适应步骤是可选的，我们只在 DAVIS-585 上采用它。论文中报告的时间成本在一个 3090 GPU 上进行测试。对于实例分割，框提示的阈值 $\lambda$ 设置为 0.1。对于语义分割，STM 中使用的 $\mu$ 设置为 0.5。高斯分布的因子 $\omega, \gamma$ 默认设置为 15 和 4。我们在算法 1 中提供了区域合并策略的伪代码，这是我们语义分割分拆-合并 (STM) 流水线的重要组成部分。

### B. 额外的实验

#### B.1 与自动掩码生成器的比较

SAM 可以通过在图像上采样点网格作为提示来为整个图像生成掩码。这种自动方式可以通过将潜在掩码与粗糙掩码匹配来用于掩码精修。我们利用两个匹配标准来验证其性能：1) **最大 IoU (Max IoU)**：对于每个粗糙掩码，我们选择 SAM 生成的 IoU 最高的部分作为精修掩码。2) **合并 (Merging)**：对于每个 SAM 生成的部分，如果该部分与粗糙掩码之间的重叠区域超过该部分面积的某个百分比（例如，0.5），则将其视为最终精修掩码的一部分。

我们在表 7 中将我们的提示挖掘策略与这两种自动网格点提示进行了比较。我们注意到，对于最大 IoU 方法，性能严重下降，而对于合并方法，在 DAVIS-585 上几乎没有改进。这源于这种提示生成方式的固有缺点，如图 6 所示。首先，网格点提示将图像分割成几个细粒度的掩码，并且难以控制粒度。通过最大 IoU 选择的最佳匹配掩码通常无法覆盖整个对象。其次，尽管合并策略可以获得相对完整的对象，但它容易受到粗糙掩码中缺陷（例如假阳性）的影响，并倾向于导致过度检测。第三，SAM 生成的部分不是排他性的，有时一个对象可能包含在具有不同粒度的多个掩码中。通过上述策略过滤它们仍然具有挑战性。与这种自下而上的范式相反，我们的提示挖掘策略直接为目标对象生成多样化的提示（自上而下的范式），这更具目的性、准确性，并且对粗糙掩码中的噪声更具鲁棒性。此外，这些基于网格的提示效率低下（即比我们的方法慢 5 倍），因为它们需要大量的提示和耗时的后处理（例如 NMS Neubeck & Van Gool (2006)）来过滤低质量和重复的掩码。


表 7: 自动网格点提示与我们的提示策略在 DAVIS-585 上的定量比较。

| 提示类型     | IoU  | bIoU | 时间 (分钟) |
|--------------|------|------|----------|
| Coarse Mask  | 81.4 | 71.4 | -        |
| Max IoU      | 70.6 | 65.5 | 8.0      |
| Merging      | 81.9 | 73.1 | 8.0      |
| Ours         | 86.9 | 75.1 | 1.6      |

![](../../../../../99_Assets%20(资源文件)/images/dcf72cdeac9171b2e44300731731c6a5.png)

图 6 展示了与网格点提示的定性比较。

#### B.2 不同骨干网络和级联后精修的效果

预训练的 SAM 模型有三种骨干网络尺寸，掩码可以通过级联精修迭代处理。我们在图 7a 中比较了使用不同骨干网络和迭代次数的影响。结果表明，最大的 ViT-H 在第一次迭代中优于其他骨干网络，并且多次迭代可以进一步提高掩码质量，特别是对于 ViT-L 骨干网络。请注意，级联精修中每次迭代的掩码提示都来自我们的提示挖掘策略（即高斯风格掩码）。我们还与原始 SAM 中使用的一些典型实践进行了比较，包括 (a) 在第一次迭代中仅使用点和框提示，并在后续迭代中添加 SAM 预测的掩码 logits（由前一次迭代生成）；(b) 在第一次迭代中使用我们方法生成的所有提示，但将高斯风格掩码替换为 SAM 预测的掩码 logits 以进行后续迭代。图 7b 中的结果表明，SAM 的掩码 logits 可以促进级联精修中点和框的改进（条件 a），但在初始步骤中采用我们的掩码提示时则失效（条件 b）。这表明我们的高斯风格掩码可以提供比掩码 logits 更强大的指导，它不仅在初始步骤中生成高质量掩码，而且对级联精修更有利。

![](../../../../../99_Assets%20(资源文件)/images/85a2dda5cf4b3d6acfc68c41ccbb66aa.png)

图 7: 不同骨干网络和级联后精修策略以及掩码 logits 的消融研究。
(a) 不同骨干网络和级联后精修的效果。
(b) 与 SAM 预测掩码 logits 的比较。

#### B.3 基于 HQ-SAM 的升级结果

HQ-SAM 是 SAM 的高级版本，可以实现更准确的分割。我们的框架也可以应用于这个强大的变体，我们基于它在各种基准测试上进行了实验，以追求更好的性能。在表 8 中，我们比较了我们的框架在 DAVIS-585、VOC (BECO 和 CLIP-ES) 和 COCO (NB 和 WSSIS) 上使用 SAM 和 HQ-SAM 的性能。结果表明，在 DAVIS-585 和 VOC 上有显著改进，而在 COCO 上性能与 SAM 持平。这是因为 HQ-SAM 通过在高精度数据集上专门训练，其中包含大型和显著对象，从而增强了原始 SAM，这与 DAVIS-585 和 VOC 等数据集的特点非常吻合。相比之下，COCO 包含许多小对象，可能不会从 HQ-SAM 中获得太多益处。

表 8: SAM 和 HQ-SAM 之间的比较。我们在 DAVIS-585 上报告 IoU / 边界 IoU，在 COCO 上报告 AP / 边界 AP，在 VOC 上报告 mIoU。

| 模型     | DAVIS-585   | NB          | PointWSSIS  | BECO | CLIP-ES |
| ------ | ----------- | ----------- | ----------- | ---- | ------- |
| SAM    | 87.7 / 78.9 | 18.4 / 11.8 | 35.3 / 24.1 | 71.8 | 79.3    |
| HQ-SAM | 90.6 / 81.7 | 18.4 / 12.2 | 35.0 / 24.3 | 73.6 | 81.0    |

### B.4 不同任务的应用

**高分辨率图像中的应用 (Application on high-resolution images)**。我们在 BIG 数据集上评估了我们的 SAMRefiner，该数据集包括从 2K 到 6K 的超高分辨率图像。我们直接在 SAM 的基础上精修 DeepLabV3+ 生成的粗糙掩码，无需特定于数据集的微调，使用 IoU 和平均边界准确度 (mBA) 作为指标。表 9a 中的结果表明，我们的框架可以有效提高粗糙掩码的质量，并且通过使用强大的 HQ-SAM 优于或可与现有方法媲美。

表 9: BIG 和重标注 PASCAL VOC 数据集上的额外实验结果。粗糙掩码由 DeepLabV3+ 生成。

![](../../../../../99_Assets%20(资源文件)/images/280c0b6ad7ae2b6f9e8ff97c1201aa97.png)

**重标注 VOC 的应用 (Application on relabeled VOC)**。CascadePSP 引入了一个重标注的 VOC 数据集，具有精确的边界标注，以便更好地评估。我们遵循此设置来验证我们的框架在此基准上的表现。表 9b 中的结果表明了我们方法的有效性，IoU 优于现有方法。请注意，语义模糊性可能导致人类主观标注与 SAM 预测之间的不一致（例如，图 17 中的类别“桌子”是否应包含桌子上的物品），这是由于缺乏下游数据而不可避免的，一个潜在的解决方案是特定于数据集的自适应。

**人工标注校正的应用 (Application on human annotations correction)**。由于像素级精确标注的严格标准，人工标注的掩码也可能很粗糙。例如，COCO 掩码以多边形格式标注，在边界区域不准确（参见图 8）。LVIS 为 COCO 图像构建了更精确的标注。我们使用 SAMRefiner 精修 COCO 验证集中的掩码，并根据 LVIS 标注进行评估。表 10 中的结果表明，我们的方法也可以用于不准确的人工标注。掩码质量有显著提高（例如，3.2% 的 mask AP 和 5.7% 的 boundary AP）。我们在图 8 中提供了定性比较。

![](../../../../../99_Assets%20(资源文件)/images/ba4404406c85e129d1125c05901576d2.png)

图 8: COCO 标注和我们精修后的标注的可视化。

表 10: COCO2017 val 上精修掩码的性能。

| 数据集   | $AP_{mask}$ | $AP_{boundary}$ |
| ----- | ----------- | --------------- |
| COCO  | 38.3        | 27.3            |
| +Ours | 41.5 (+3.2) | 33.0 (+5.7)     |

### B.5 额外的消融研究

**掩码提示中 $\omega, \gamma$ 的分析 (Analysis of $\omega, \gamma$ in the mask prompt)**。我们在提示挖掘策略中利用高斯风格掩码，其中两个因子 $\omega, \gamma$ 控制分布的振幅和跨度。我们在图 9a 中对这两个参数进行了敏感性分析。当 $\omega$ 过小（即 $\omega=1$）时，掩码提示的效果可以忽略不计，因为原始 SAM 的掩码输入是预测的 logits，其未缩放到 0-1。我们注意到，相对较高的 $\omega$ 值可以促进掩码提示在掩码精修中的作用，并且性能对这些较高的 $\omega$ 值以及 $\gamma$ 不敏感。

![](../../../../../99_Assets%20(资源文件)/images/400b2fa0057165210b8b25f650fbf267.png)

图 9: 消融研究 (a): $\omega, \gamma$ 和 (b): $\lambda$。
(a) $\omega, \gamma$ 的分析。
(b) $\lambda$ 的分析。

**上下文感知弹性边界框中 $\lambda$ 的分析 (Analysis of $\lambda$ in the context-aware elastic box)**。我们在 CEBox 中引入了一个阈值 $\lambda$ 来确定是否根据上下文特征扩展当前边界框，这控制了边界框大小的权衡。我们在图 9b 中提供了 $\lambda$ 的分析。所提出的 CEBox 在不同阈值下相对于基线 ($\lambda=0$) 具有持续的优势。在我们的实验中，我们将 $\lambda=0.1$ 以避免过度放大。

![](../../../../../99_Assets%20(资源文件)/images/1ae3a42c46db41c49f5ea822330d31dc.png)

图 10: 分拆-合并 (STM) 流水线的图示。红色区域 3 较小。请放大查看。

### C. 技术细节

#### C.1 STM 的进一步阐述

分拆-合并 (STM) 流水线旨在解决语义分割中的多对象情况。在这种情况下，SAM 在使用常用提示分割距离较远的多个对象时会遇到困难，导致漏检或误检（图 4b）。我们提出 STM 将包含多个对象的语义掩码转换为实例掩码，以确保更好地与 SAM 兼容。如图 10 所示，STM 包含两个阶段：1) **分拆 (Split)**：通过查找所有连接区域来分拆掩码，这些区域往往是混乱且嘈杂的；2) **合并 (Merge)**：根据边界框面积变化和掩码面积占用情况迭代地合并相邻区域，以形成语义上有意义的区域（算法 1）。STM 在提示提取之前执行。完成后，我们可以根据合并后的掩码生成提示，并利用 SAMRefiner 进行精修。如图 11 所示，STM 可以有效缓解语义分割中多对象的影响，比基线产生更好的结果。

![](../../../../../99_Assets%20(资源文件)/images/4448e2a7fe839171b0385637edb32dd1.png)

图 11: STM 与基线 (无 STM) 的视觉比较。

#### C.2 高斯风格掩码的进一步阐述

请注意，中心点不是掩码的几何中心点，而是由前一个点提示步骤选择的距离最远的正向点。我们只对掩码的前景区域应用高斯操作，高斯风格掩码是粗糙掩码的广义形式。例如，当振幅 $\omega$ 设置为 1 且跨度 $\gamma$ 足够大时，高斯风格掩码等效于原始粗糙掩码。图 12 展示了高斯掩码的可视化。

![](../../../../../99_Assets%20(资源文件)/images/61e2132a19e9934a7848b7f94d6fdd9e.png)

图 12: 不同 $\gamma$ 下的高斯风格掩码可视化。

使用高斯风格掩码主要有两个原因：
1. **与 SAM 的兼容性 (Compatibility with SAM)**：原始 SAM 不支持二值掩码作为提示。这是因为掩码提示在 SAM 预训练期间的级联精修中仅作为点和框的辅助，以前一次迭代的预测 logits 作为输入来指导下一次迭代。因此，SAM 的掩码输入需要具有连续值的 logits，而原始粗糙掩码是离散值（0 和 1）。高斯操作可以将二值掩码转换为连续值，使其与 SAM 兼容。
2. **以对象为中心的先验 (The object-centric prior)**：对象的中心倾向于是正向且具有特征区分性的，而模糊性主要位于边界。高斯风格掩码有效地降低了边界附近的权重。如图 9a 所示，当 $\omega=1$ 时，由于不兼容的值空间，性能显著下降，而高斯变换后的掩码在不同的 $\omega$ 和 $\gamma$ 下始终优于原始粗糙掩码。

#### C.3 CEBox 的进一步阐述

对于 SAM，不同实例（甚至在同一类别内）的图像特征表现出独特的特性。这使得 SAM 能够生成细粒度的组件级分割，从而支持各种下游应用。为了说明这一点，我们分析了图 13a 中不同掩码之间的特征相似性。如图所示，不同实例的特征，即使在同一类别内，也显示出一定的差异。这种特性使得 SAM 能够有效地区分实例（例如，相邻的书籍）。对于部分分割也可以得出类似的结论，如图 13b 所示。在此基础上，我们可以灵活调整 $\lambda$（一个根据图像特征相似性确定在每个方向上扩展当前边界框必要性的阈值），以适应不同的设置。例如，宽松的阈值可以应用于一般分割，而更严格的阈值可能更适合细粒度分割，例如区分不同的实例或组件。

![](../../../../../99_Assets%20(资源文件)/images/f5e4f529ddcc760cc13fa0b394ab9241.png)

图 13: 基础掩码与其他掩码之间特征相似性的可视化。
(a) 实例级特征相似性。
(b) 组件级特征相似性。

#### C.4 IoU 自适应的进一步阐述

尽管原始 SAM 在提供多个提示时使用单个 token，但我们凭经验观察到，根据 IoU 预测从其余三个掩码中选择最佳掩码比第四个掩码产生更好的性能，如图 5a 所示。这是因为尽管这三个预测是收敛的，但一些细节仍然不同，并且通常优于第四个 token。我们在图 14 中提供了可视化，以比较不同 token 生成的掩码。尽管改进可能不显著，但 IoU 自适应的优势在于它不需要任何额外的标注数据，并且只利用目标数据集中包含的先验知识。当目标数据集上的粗糙掩码可以提供高质量指导时，SAMRefiner++ 作为 SAMRefiner 的补充增强，此步骤不是强制性的。

![](../../../../../99_Assets%20(资源文件)/images/8b7d48f7c4e3f27db0116e48932d676f.png)

图 14: SAM 解码器中不同 token 生成掩码的可视化。

#### C.5 距离引导点采样策略的影响

距离引导点采样策略优于边界框中心方法，因为它有效缓解了假阳性噪声的影响，假阳性噪声通常会扭曲边界框，导致边界框中心偏离实际对象，如图 15 所示。

图 15: 边界框中心点与距离引导点之间的比较。

#### C.6 粗糙掩码质量分析

在图 16 中，我们提供了基于不同质量粗糙掩码的精修掩码的可视化。结果表明，当粗糙掩码满足一定的质量标准时，SAMRefiner 能有效工作，但当粗糙掩码极其不准确时，它可能会失败。这是因为如果初始掩码过于粗糙，掩码精修任务就会成为一个病态问题。例如，如果粗糙掩码只覆盖一个人的头部，在没有额外信息的情况下重建整个人将是不可能的，因为存在固有的模糊性。幸运的是，大多数实际粗糙掩码（例如模型预测生成的掩码）通常满足一定的质量标准，并可以有效地由我们提出的方法处理。

图 16: 基于不同质量粗糙掩码精修掩码的可视化。

### D. 讨论和限制

#### D.1 不同掩码精修方法的比较

我们在表 11 中详细讨论了 SAMRefiner 与相关方法（密集 CRF、CascadePSP、CRM）在设计原则、架构、训练数据、优点和缺点方面的差异。在这些方法中，密集 CRF 是一种无需训练的后处理方法，基于低级颜色特征，使其高效且易于使用。然而，由于缺乏高级语义上下文，它在复杂场景中表现不佳。另一方面，CascadePSP 和 CRM 专注于使用基于 CNN 的架构将特征图与精修目标对齐。它们在一个包含极其精确掩码标注的组合数据集上进行训练，并在语义分割任务上表现出强大的性能。然而，它们在实例分割上的性能竞争力较差，这主要是由于其训练数据中缺乏复杂案例以及 CNN 的固有局限性。此外，CascadePSP 的级联结构和 CRM 所需的多分辨率推理使得它们在处理大量对象的掩码时效率低下。

相比之下，SAMRefiner 通过专门为掩码精修任务设计噪声容忍提示来利用 SAM 的优势。与现有方法相比，这种方法实现了更好的准确性和效率。尽管如此，它可能在具有复杂结构的对象上表现不佳，这是 SAM 本身固有的局限性。这个问题可以通过使用增强变体（例如 HQ-SAM）来解决，如附录 B.3 中所进行的实验。

表 11: 不同掩码精修方法的比较。

| 方法         | 设计原则                    | 架构          | 训练数据       | 优点            | 缺点            |
| ---------- | ----------------------- | ----------- | ---------- | ------------- | ------------- |
| 密集 CRF     | 最大化像素间标签一致性，具有相似的低级颜色特征 | 无           | 无          | 无需训练，易于使用     | 不准确           |
| CascadePSP | 以级联方式将特征图与精修目标对齐        | CNN         | MSRA-10K 等 | 类别无关，在语义分割上准确 | 任务依赖，效率低下     |
| CRM        | 连续地将特征图与精修目标对齐          | CNN         | MSRA-10K 等 | 类别无关，在语义分割上准确 | 任务依赖，效率低下     |
| SAMRefiner | 设计噪声容忍提示以使 SAM 进行掩码精修   | Transformer | SA-1B      | 类别、任务无关，准确，高效 | 对复杂结构对象效果可能不佳 |

#### D.2 SAMRefiner 的目标和相关性

SAMRefiner 旨在成为一个通用框架，用于校正各种来源生成的粗糙伪掩码。由于实际场景中粗糙掩码的广泛来源（例如，模型预测甚至不准确的人工标注），这项任务非常重要。我们的 SAMRefiner 可以被视为一种有效的后处理方法，用于提高数据质量，精修后的掩码可以用于训练特定任务的高级模型，我们将其称为伪标签范式。尽管一些最近的工作试图构建大型基础模型以实现开放词汇能力并展示出令人印象深刻的性能，但我们认为伪标签范式在某些应用场景中仍然具有重要意义。首先，人们在特定的实际应用中通常只关注有限的语义类别（例如，自动驾驶）。开放词汇设置是不必要的，有时甚至对目标对象的性能有害。其次，基础模型往往庞大且推理效率低下，不适用于资源受限和时间敏感的设置。因此，为不同的应用场景定制特定模型比直接使用大型基础模型更有效。我们的框架将基础模型视为一个独立的后处理器，以提高定制模型的数据质量，这更通用和灵活。它可以补充各种分割方法，并有可能补充其他精修技术和基础模型。

#### D.3 SAMRefiner(++) 的应用场景和局限性

**应用场景 (Application scenarios)**。在本文中，我们提出了一个有效的掩码精修方法 SAMRefiner 及其变体 SAMRefiner++。SAMRefiner 是一种无需训练的方法，它使用噪声容忍提示精修掩码。它保留了原始 SAM 的大部分特性，并继承了其“通用能力”。相比之下，SAMRefiner++ 指的是 SAMRefiner 和 IoU 自适应的组合，这需要在目标数据集上进行额外的训练。这种方法是专门为某些条件量身定制的，并且具有严格的先决条件，例如粗糙掩码的质量，这取决于数据集，并且可能无法在所有数据集上取得显著结果。因此，SAMRefiner++ 并非旨在成为一种通用方法。相反，它提供了一种在不需要额外标注的情况下实现进一步改进的潜在方法。

**局限性 (Limitations)**。对于掩码精修任务，最终性能高度受初始粗糙掩码质量的影响。掩码中的缺陷多种多样，因此设计一种适用于所有场景的单一有效方法具有挑战性。我们的提示挖掘策略提出了多样化的提示类型，以减轻粗糙掩码中缺陷的影响。尽管比以前的工作更具噪声鲁棒性，但当初始掩码极其嘈杂时（如图 18 最后几行所示），它仍然会失效。此外，SAM 预测与我们主观性之间可能存在语义模糊性（例如，图 17 中的“桌子”类别是否应包含桌子上的物品），这是由于缺乏下游数据而不可避免的，一个潜在的解决方案是特定于数据集的自适应。最后，SAM 在语义分割中处理多个对象时遇到困难，因为预训练期间不存在这种情况。尽管我们提出的 STM 可以部分缓解这个问题，但有时它会失效（图 17 第二行）。一个可以考虑的选择是微调 SAM，使其适应这种设置。

图 17: 语义分割上的失败案例。

### E. 更多定性结果

在图 18 和图 19 中，我们提供了我们在 PASCAL VOC 2012 和 COCO 2017 上的精修掩码以及先前工作的更多定性结果。我们可以观察到，我们的 SAMRefiner 在边界和详细结构上产生了令人满意的分割结果。它在简单和复杂场景中都有效。失败案例主要源于粗糙掩码的极端不准确性，导致错误激活或漏检。

图 18: VOC 上的更多可视化。最后三行显示了一些失败案例。

图 19: COCO 上的更多可视化。最后两行显示了一些失败案例。