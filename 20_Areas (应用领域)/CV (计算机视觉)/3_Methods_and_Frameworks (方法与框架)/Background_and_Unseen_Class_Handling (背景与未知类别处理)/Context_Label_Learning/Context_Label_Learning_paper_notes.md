---
type: paper-note
tags:
  - cv
  - semantic-segmentation
  - full-supervision
  - context-learning
  - self-supervised-learning
  - multi-task-learning
  - meta-learning
  - medical-imaging
  - colab
  - tfs
status: todo
model: Context Label Learning
year: 2022
summary: 提出上下文标签学习（CoLab），通过元学习自动生成背景子类别（上下文标签），以解决语义分割中背景类别异构性导致的欠拟合和过分割问题，显著提高ROI分割精度。
---
论文网址：[[2407.11859] Mitigating Background Shift in Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2407.11859)

本地PDF文件：[MBS](../../../../../99_Assets%20(资源文件)/papers/Mitigating%20Background%20Shift%20in%20Class-Incremental%20Semantic%20Segmentation.pdf)
***
## 摘要

背景样本在语义分割中为感兴趣区域（ROIs）的分割提供了关键的上下文信息。然而，这些背景通常包含高度多样化的结构，这导致分割模型难以学习到具有高灵敏度和精确度的良好决策边界。问题的核心在于背景类别的高度异构性，这导致了多模态分布。经验上，我们发现使用异构背景训练的神经网络难以将相应的上下文样本映射到特征空间中的紧凑聚类。结果是，背景logit激活的分布可能会跨越决策边界，导致在不同数据集和任务中出现系统的过分割现象。

在这项研究中，我们提出了**上下文标签学习（CoLab）**，通过将背景类别分解为几个子类别来改善上下文表示。具体来说，我们训练一个辅助网络作为任务生成器，与主要分割模型一起，自动生成对ROI分割精度有积极影响的上下文标签。我们在几个具有挑战性的分割任务和数据集上进行了广泛的实验。结果表明，CoLab可以引导分割模型将背景样本的logit值移离决策边界，从而显著提高分割精度。代码已公开。

**索引词**：欠拟合、多任务学习、自监督学习、图像分割。

## I. 引言

卷积神经网络（CNNs）是语义图像分割领域最先进的方法。它们大量的可训练参数使其能够适应各种任务，并在分割精度方面取得高性能。然而，在实际应用中，当训练数据量有限时，CNNs有时似乎无法从复杂、异构的训练集中学习和泛化。具体来说，在医学图像分割的情况下，背景类别样本（为感兴趣区域（ROIs）提供必要的上下文信息）构成了训练集的大部分，同时包含了具有异构特征的各种结构，这使得分割模型难以学习准确的决策边界。

当在具有高度异构背景类别的数据集上进行训练时，分割模型容易欠拟合这些上下文样本，并且未能将与ROI样本具有相似特征的样本分离出来。模型随后会产生假阳性（FP），导致系统的过分割。在这项研究中，我们认为上下文信息的欠拟合是导致分割性能下降的主要原因，因为它影响了精确度（计算公式为 $\frac{TP}{TP+FP}$）。我们观察到，通过分解背景类别来获得更好的上下文表示，例如使用额外的解剖学标签，可以显著提高ROI分割精度。

图1(a)展示了人类定义上下文标签的示例。例如，在肝肿瘤分割中，除了肿瘤类别，拥有肝脏的标签也很有益。经验上，我们发现当使用人类定义上下文标签进行训练时，分割模型在Dice相似系数（DSC）和95% Hausdorff距离（HD）方面可以取得更好的性能，如图1(b)所示。然而，这些人类定义上下文标签并不总是可用，而且获取困难且耗时。在许多应用中，只有ROI标签（例如肿瘤类别）可用。

因此，我们提出了**上下文标签学习（CoLab）**，它自动生成上下文标签，以改善上下文表示的学习，从而获得更好的ROI分割精度。如图1(b)所示，CoLab可以带来与使用人类定义上下文标签训练时相似的改进，而无需专家知识。

这项研究的贡献总结如下：
1. 通过对六个数据集的观察，我们得出结论，背景类别的欠拟合会持续通过降低精确度来降低分割性能。
2. 我们发现通过分解背景类别来获得更好的上下文表示可以改善分割性能。
3. 我们提出了CoLab，一种灵活通用的方法来自动生成软上下文标签。我们通过广泛的实验验证了CoLab，并发现了一致的改进，其分割精度与有人工标注上下文标签的情况相当，甚至更好。

## II. 相关工作

### A. 类别不平衡

CoLab与类别不平衡问题相关，因为背景通常构成图像分割中的多数类别。然而，解决类别不平衡的方法大多明确关注提高少数类别的性能，忽略了多数背景类别的特性，因为它对ROI类别的灵敏度、精确度和DSC等常见评估指标贡献不大。CoLab**专门关注背景类别的表示**，并且与解决类别不平衡的方法（如损失重加权策略）是互补的。

### B. 多任务学习

CoLab被表述为多标签分类，可以看作是多任务学习（MTL）的一种形式。当前的MTL方法通过与主任务共享特征表示一起训练模型，使用不同的预定义任务。之前的工作也尝试将空间先验或任务先验整合到模型训练中，使用一些预定义的辅助任务和优化函数。

相比之下，CoLab通过使用上下文标签分解背景类别来重新表述主任务，并以**自监督方式**自动生成辅助任务。我们认为CoLab通过扩展标签空间可以对主任务产生直接影响。

CoLab方法的主要原理受最近提出的一些方法启发，这些方法旨在通过类似的元学习框架为预定义的辅助任务或标签生成权重。在这项研究中，CoLab专为具有异构背景类别的语义分割而设计，这在医学图像中很常见。

## III. 图像分割中的上下文标签

### A. 预备知识

我们考虑用于多类别分割的CNNs，总共有 $c$ 个类别。给定训练数据集 $D=\{(x_i, y_i)\}_{i=1}^N$，其中 $N$ 个样本，$y_i \in \mathbb{R}^c$ 是图像样本 $x_i \in \mathbb{R}^d$ 中心像素的 one-hot 编码标签，使得 $1 \cdot y_i = 1 \forall i$。分割模型 $f_\phi(\cdot)$ 学习输入样本 $x_i$ 的类别表示，记为 $z_i = f_\phi(x_i) \in \mathbb{R}^c$。我们通过softmax函数计算 $x_i$ 的真实类别是 $j$ 的预测概率 $p_i$，其中 $p_{ij} = e^{z_{ij}} / \sum_{j=1}^c e^{z_{ij}}$。

通常，模型通过最小化经验风险 $R_{L_\text{seg}}(f_\phi) = \frac{1}{N} \sum_{i=1}^N L_\text{seg}(f_\phi(x_i), y_i)$ 在训练集上进行优化。分割损失 $L_\text{seg}$ 可以定义为 $c$ 个类别的损失之和：

$$
L_\text{seg}(f_\phi(x_i), y_i) = \sum_{j=1}^c L(p_{ij}, y_{ij}) = \underbrace{\sum_{j=1}^{c-1} L(p_{ij}, y_{ij})}_{\text{ROI classes}} + \underbrace{L(p_{ic}, y_{ic})}_{\text{background class}} \tag{1}
$$

其中 $L$ 是特定类别的准则，例如交叉熵（CE）或软DSC。在这里，我们将 $L_\text{seg}$ 进一步分解为两项，包括ROI损失（在 $c-1$ 个前景类别上计算）和背景损失（仅在背景类别上计算）。

我们的目标是通过使用辅助上下文类别增强背景类别来提高分割性能。具体来说，我们建议利用分配给不同和分解的背景区域的上下文标签。为了将背景类别分解为 $t > 1$ 个类别，我们创建了另一个模型 $\tilde{f}_\theta(\cdot)$，其输出为 $\tilde{z}_i = \tilde{f}_\theta(x_i) \in \mathbb{R}^{c+t-1}$，并具有预测概率 $\tilde{p}_i$。我们还需要一个额外的 one-hot 标签 $\tilde{y}_i \in \mathbb{R}^{c+t-1}$，其中我们要求 $\tilde{y}_{ij} = y_{ij} \forall i, j \in \{1, \dots, c-1\}$ 并且 $\sum_{j=c}^{c+t-1} \tilde{y}_{ij} = y_{ic} \forall i$。有了这个概念，分割损失可以写为：

$$
L_\text{seg}(\tilde{f}_\theta(x_i), \tilde{y}_i) = \sum_{j=1}^{c+t-1} L(\tilde{p}_{ij}, \tilde{y}_{ij}) = \underbrace{\sum_{j=1}^{c-1} L(\tilde{p}_{ij}, \tilde{y}_{ij})}_{\text{ROI classes}} + \underbrace{\sum_{j=c}^{c+t-1} L(\tilde{p}_{ij}, \tilde{y}_{ij})}_{\text{background classes}} \tag{2}
$$

在下面的方法章节中，为简化起见，我们始终考虑一个简化的常见情况，即我们只有一个ROI类别（$c=2$）。换句话说，我们只考虑二元ROI分割，其中 $f_\phi(x_i) \in \mathbb{R}^2$，尽管该方法可以自然地扩展到多类别ROI分割。在此假设下，公式(2)可以简化为：

$$
L_\text{seg}(\tilde{f}_\theta(x_i), \tilde{y}_i) = \underbrace{L(\tilde{p}_{i1}, \tilde{y}_{i1})}_{\text{ROI class}} + \underbrace{\sum_{j=2}^{t+1} L(\tilde{p}_{ij}, \tilde{y}_{ij})}_{\text{background classes}} \tag{3}
$$

### B. 背景类别的假阳性

为了更好地理解背景类别对模型学习的影响，我们训练了多个CNNs，用于包含异构背景的分割数据集。我们在具有挑战性的任务上进行了实验，包括CT图像中的肝肿瘤分割、CT图像中的肾肿瘤分割、CT图像中的结肠肿瘤分割、T2加权磁共振（MR）图像中的前庭神经鞘瘤（VS）分割、T1加权MR图像中的脑卒中病灶分割以及CT图像中的胰腺肿瘤分割。我们采用配置良好的3D U-Net作为所有实验的分割模型，该模型已在不同医学图像分割任务中显示出具有竞争力的结果。详细的数据和网络配置总结在第五节。

分割结果的可视化如图2(a)所示。当使用二元分割任务进行训练且没有上下文标签时，模型倾向于过度分割ROI，产生许多FP。具体来说，在二元肝肿瘤任务上训练的模型将肝脏以外的其他器官预测为肝肿瘤；在二元肾肿瘤任务上训练的模型将健康肾脏区域的一部分预测为肾肿瘤；而二元脑肿瘤任务上训练的模型将周围脑组织预测为脑肿瘤；在二元脑病灶任务上训练的模型将不相关的健康脑区域预测为脑病灶。

### C. 背景样本的欠拟合

为了研究模型在异构背景类别训练时的行为，我们可以监控测试数据中ROI和背景样本的logit分布。我们对肝肿瘤、肾肿瘤和脑肿瘤分割的观察总结在图3(a, d, g)中。

我们发现CNN模型将ROI样本映射到logit空间中的紧凑聚类，而背景样本形成了更为分散的分布。这表明模型不能轻易地将所有背景样本映射到代表背景类别的单个聚类。尽管模型似乎在特征空间中将ROI与背景样本分离，但它构建了复杂的背景表示，并且无法在ROI和即时上下文之间捕捉准确的决策边界。一个可能的原因是CNN将其大部分能力用于提取具有不同特征的背景区域之间的共同特征。不幸的是，这些共享特征不是很具区分性。

具体来说，我们观察到背景样本的logit分布与学习到的决策边界重叠。这就是当背景类别异构时，模型预测许多FP导致ROI结构过分割的原因。我们假设分布的宽度是特定类别异构性的指标，也是学习期间难度的一个标志。由于样本的异构性，CNN可能难以减少背景类别的类内差异，并欠拟合背景样本，未能识别与ROI样本具有相似特征的背景样本。

值得注意的是，我们没有观察到训练背景样本和测试背景样本的logit分布之间有显著差异，正如之前的研究所示，这表明背景样本的logit偏移确实是由于欠拟合而不是过拟合。

### D. 上下文标签的影响

上下文标签的可用性极大地帮助了ROI分割，它们为CNN提供了额外的信号，以更好地拟合异构背景样本的训练数据。我们通过在模型训练中包含人类定义的上下文标签来经验性地证实了这一点。具体来说，我们采用肝脏掩膜（$t=2$）用于肝肿瘤分割，肾脏掩膜（$t=2$）用于肾肿瘤分割，脑组织掩膜（包括脑室、深部灰质、皮质灰质、白质和其他组织，$t=6$）用于脑肿瘤分割。肾脏和肝脏掩膜是手动标注的，而脑组织掩膜是使用配对的T1加权MR图像和基于期望最大化精炼（MALP-EM）的多图谱标签传播自动生成的。为了进行公平比较，我们确保所有实验都共享相同的训练计划，除了标签空间。我们只考虑ROI采样训练补丁。具体来说，我们确保50%的训练补丁包含ROI，并均匀采样另一半训练补丁。

测试集和训练集上的观察结果总结在图4中。我们发现模型在解剖学掩膜训练时总体性能更好，DSC（定义为 $DSC = 2 \frac{sensivity \cdot precision}{sensivity + precision}$）有所改善。此外，我们观察到使用上下文标签训练的模型在保持相似灵敏度的同时获得了更高的精确度。该观察结果与图2(b)中的可视化结果一致，我们发现使用人工定义上下文标签训练的模型减少了FP。

类似地，我们在图3(b, e, h)中可视化了相应的网络行为。由于我们只考虑ROI（类别1）的分割性能，我们在 $(z_1, \max(z_2, \dots, z_{t+1}))$ 平面上可视化logit。我们观察到使用解剖学掩膜训练的模型将背景样本映射到更窄的分布，并减少了背景logit跨越决策边界的偏移。这表明模型在上下文标签的帮助下更好地拟合了训练数据。CNNs不再为所有背景样本构建通用过滤器，而是可以为具有共同特征的背景样本的更均匀子部分分配专用过滤器。这些模型面临着简化的分割任务，具有同质背景子类别，从而在相同的模型容量下实现了更好的整体性能。

尽管解剖学掩膜被发现是有效的上下文标签，但它们在实际应用中并不总是可用。具体来说，获取手动标注的上下文标签耗时，并且需要人类专家付出大量精力进行大规模标注。因此，我们提出了**CoLab**，它可以使用元学习策略自动发现特定的软上下文标签。CoLab通过使分割模型更好地拟合背景样本而受益于分割模型训练，与在手动定义解剖学掩膜上训练的模型相比，取得了相似甚至更好的性能。

## IV. CoLab (上下文标签学习)

### A. 概述

现在我们考虑用于二元语义分割的CNNs。通常，我们有一个基线分割模型 $f_\phi(\cdot)$，它将输入图像 $x_i$ 映射到标签空间 $f_\phi(x_i) \in \mathbb{R}^2$。为了在标签空间中使用上下文标签进行拟合，我们首先将 $f_\phi(\cdot)$ 的分类层扩展一些额外的 $t-1$ 个输出神经元，得到 $\tilde{f}_\theta(\cdot)$，它将 $x_i$ 映射到 $\tilde{f}_\theta(x_i) \in \mathbb{R}^{t+1}$。我们使用另一个模型 $g_\omega(\cdot)$ 作为任务生成器，由 $\omega$ 参数化，用于生成上下文标签，网络输出 $o_i = g_\omega(x_i) \in \mathbb{R}^t$。我们对 $g_\omega(\cdot)$ 的骨干网络没有要求，并且经验性地使其与 $f_\phi(\cdot)$ 保持一致。

我们在图5中展示了所提出的CoLab的训练过程。在每次迭代开始时，我们通过利用 $o_i$ 和ground truth $y$ 获得称为距离约束标签 $\hat{\tilde{y}}_i$ 的上下文标签。这个过程在 **①** 标记，并将在第IV-B节和第IV-C节中进行说明。然后，我们通过 **②** 计算一个新的 $\theta^*$，进行一步梯度下降，以评估 $\hat{\tilde{y}}_i$ 对ROI分割模型训练的影响。接下来，我们通过 **③** 通过元学习方案基于二阶导数优化 $\omega$，这将在第IV-D节中展示。最后，我们根据更新后的上下文标签通过 **④** 优化分割模型 $\tilde{f}_\theta(\cdot)$。

### B. 标签聚合（Label aggregation）

我们通过 softmax 函数根据 $o_i$ 计算上下文概率 $(q_{ij})_{j=1}^t$：

$$
q_{ij} = \frac{e^{o_{ij}}}{\sum_{j=1}^t e^{o_{ij}}} \tag{4}
$$

扩展标签 $\tilde{y}_i \in \mathbb{R}^{t+1}$ 通过将原始标签 $y_i = (y_{i1}, y_{i2})$ 和上下文概率 $q_i$ 聚合计算：

$$
\tilde{y}_{ij} = \begin{cases}
y_{i1} & \text{if } j=1, \\
q_{ij} & \text{if } j>1 \text{ and } y_{i1}=0, \\
0 & \text{otherwise.}
\end{cases} \tag{5}
$$

标签聚合过程也如图6所示。通过这样做，我们可以将背景类别 $y_{i2}$ 分解为 $t$ 个子类别，同时确保 $\tilde{y}_i$ 包含足够的ROI分割信息。对于总共有 $c$ 个类别的多类别分割，$\tilde{y}_i$ 可以计算为：

$$
\tilde{y}_{ij} = \begin{cases}
y_{ij} & \text{if } j < c, \\
q_{ij} & \text{if } j \ge c \text{ and } y_{ij}=0 \forall j < c, \\
0 & \text{otherwise.}
\end{cases} \tag{6}
$$

### C. 上下文约束（Context constraints）

与更远的背景样本相比，靠近ROI的背景样本与ROI样本具有相似的特征，更容易被错误分类。为了让分割模型更多地关注那些靠近ROI的困难背景样本，我们假设所有远离ROI的样本都需要较少的关注，并且应该安全地分配相同的背景标签。具体来说，我们创建一个硬标签 $b_i \in \mathbb{R}^{t+1}$ 来表示远离ROI的背景样本：

$$
b_{ij} = \begin{cases}
1 & \text{if } j=2, \\
0 & \text{otherwise.}
\end{cases} \tag{7}
$$

通过利用ROI标签 $y_i$，我们计算相应的距离图 $d_i$，它是像素到ROI任何类别的最近边界点的欧几里得距离。我们设置ROI内部像素的 $d_i$ 为零。

然后，我们根据 $d_i$ 计算一个软膨胀掩膜 $M_i$:

$$
M_i = \begin{cases}
1 & \text{if } d_i < m, \\
e^{-\frac{d_i+m}{\tau}} & \text{otherwise},
\end{cases} \tag{8}
$$

其中 $m$ 是控制模型关注ROI附近像素的裕度，$\tau$ 是控制膨胀区域概率的温度。经验上，所有实验中 $m$ 设置为30，$\tau$ 设置为20。$M_i$ 在ROI周围的像素为1，对于远离ROI的像素趋近于0。我们在图7中展示了肝肿瘤的 $M_i$ 示例。距离约束标签 then is calculated as:

$$
\hat{\tilde{y}}_i = M_i \tilde{y}_i + (1 - M_i)b_i \tag{9}
$$

通过这种方式，只有ROI附近的区域才被认为是上下文背景类别。具体来说，$\tilde{f}_\theta(\cdot)$ 和 $g_\omega(\cdot)$ 都将被训练以关注靠近ROI的区域。

### D. 基于元梯度的任务生成器优化

我们将CoLab的优化公式化为一个双层问题：

$$
\min_\omega \frac{1}{N} \sum_{i=1}^N L_\text{ROI}(\tilde{f}_{\theta^*}(x_i), y_i) \tag{10}
$$

满足条件：

$$
\theta^* = \arg\min_\theta \frac{1}{N} \sum_{i=1}^N L_\text{seg}(\tilde{f}_\theta(x_i), \hat{\tilde{y}}_i) \tag{11}
$$

其中 $L_\text{ROI}(\tilde{f}_\theta(x_i), y_i) = L_c(\tilde{p}_{i1}, y_{i1})$ 在ROI类别上计算。与 $L$ 不同，我们选择 $L_c$ 作为一种准则，可以以 one-versus-all 的方式计算，例如二元交叉熵（BCE）和软DSC损失，以表示具有多于两个输出logit的ROI类别的二元分割性能。

我们使用批大小为 $n$ 的训练样本批次来训练模型。为简化起见，我们将 $\frac{1}{n} \sum_{i=1}^n L_\text{ROI}(\tilde{f}_{\theta^*}(x_i), y_i)$ 记为 $L_\text{ROI}(\theta^*)$，并将 $\frac{1}{n} \sum_{i=1}^n L_\text{seg}(\tilde{f}_\theta(x_i), \hat{\tilde{y}}_i)$ 记为 $L_\text{seg}(\theta, \omega)$。公式10和11中定义的双层优化问题可以通过梯度下降求解。具体来说， $L_\text{ROI}(\theta^*)$ 相对于 $\omega$ 的导数可以通过链式法则计算：

$$
\nabla_\omega L_\text{ROI}(\theta^*) = \left(\frac{\partial \theta^*}{\partial \omega}\right)^\top \nabla_\theta L_\text{ROI}(\theta^*) \tag{12}
$$

其中 $\nabla_\omega = \left(\frac{\partial}{\partial \omega}\right)^\top$ 和 $\nabla_\theta = \left(\frac{\partial}{\partial \theta}\right)^\top$。可以基于隐函数定理计算 $\frac{\partial \theta^*}{\partial \omega}$。然而，派生结果将包含一个Hessian矩阵，计算成本昂贵，并且对于深度神经网络来说并不总是可获得的。在许多梯度近似启发式方法中，我们遵循文献中的解决方案，通过单步优化来近似 $\theta^*$。具体来说，我们采样一个训练数据批次，并通过一步梯度下降来近似最优内部变量 $\theta^*$：

$$
\theta^* \approx \theta - \alpha \nabla_\theta L_\text{seg}(\theta, \omega) \tag{13}
$$

其中 $\alpha$ 是步长，与 $\theta$ 的学习率相同。我们对这个方程两边对 $\omega$ 求导得到：

$$
\frac{\partial \theta^*}{\partial \omega} = - \alpha \nabla^2_{\theta, \omega} L_\text{seg}(\theta^*, \omega) \tag{14}
$$

其中 $\nabla^2_{\theta, \omega} = \frac{\partial \nabla_\theta}{\partial \omega}$。通过将公式14代入公式12，我们可以得到 $\omega$ 的梯度并对其进行更新：

$$
\omega^{t+1} = \omega^t - \beta \nabla_{\omega^t} L_\text{ROI}(\theta^*) \\ = \omega^t + \alpha \beta \nabla^2_{\omega^t, \theta} L_\text{seg}(\theta^*, \omega^t) \nabla_\theta L_\text{ROI}(\theta^*) \tag{15}
$$

其中 $\beta$ 是更新 $\omega$ 的学习率。通过这种方式，任务生成器 $g_\omega$ 通过二阶梯度显式地训练以生成有效的上下文标签。尽管公式15包含一个昂贵的向量-矩阵乘积，但使用流行的机器学习框架（如PyTorch）计算是可行的。我们发现CoLab是高效的，因为它只需额外30%的训练时间。我们在补充材料中总结了实现细节。完整算法总结在算法1中。

**算法1 上下文标签学习 (CoLab)**

**输入**: $D = \{(x_i, y_i)\}_{i=1}^N$: 训练数据；$t$: 上下文类别数量，$f_\phi(\cdot)$: 生成 $f_\phi(x_i) \in \mathbb{R}^2$ 的分割模型；$g_\omega(\cdot)$: 生成 $g_\omega(x_i) \in \mathbb{R}^t$ 的任务生成器。
$\alpha, \beta$: 更新 $\theta$ 和 $\omega$ 的学习率。

1. 扩展 $f_\phi(\cdot)$ 的分类层以获得 $tilde{f}_\theta(\cdot)$，生成 $\tilde{f}_\theta(x_i) \in \mathbb{R}^{t+1}$。
2. **对于** 每次迭代 **执行**:
3. &nbsp;&nbsp;&nbsp;&nbsp;从 $D$ 中采样一个数据批次 $B = \{(x_i, y_i)\}_{i=1}^n$。
4. &nbsp;&nbsp;&nbsp;&nbsp;**对于** 若干步 **执行**: (注: 在我们的实验中，一步足够)
5. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;根据任务生成器 $g_\omega(x_i)$ 的输出，通过公式4生成上下文概率 $q_i$。
6. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过公式5将上下文概率 $q_i$ 与 $y_i$ 聚合，生成扩展标签 $\tilde{y}_i$。
7. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过公式8计算损失掩膜 $M_i$，并通过公式9生成距离约束标签 $\hat{\tilde{y}}_i$。
8. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过公式13的梯度下降优化算法计算新的 $\theta^*$。
9. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;基于元梯度通过公式15优化 $\omega$。(训练任务生成器)
10. &nbsp;&nbsp;&nbsp;&nbsp;**结束 对于**
11. &nbsp;&nbsp;&nbsp;&nbsp;基于更新后的 $\omega$ 使用梯度下降更新 $\theta$。(训练分割模型)
12. **结束 对于**

## V. 实验

### A. 实验设置

1. **网络配置**：我们使用最先进的3D U-Net作为分割模型 $f_\phi / \tilde{f}_\theta$ 和任务生成器 $g_\omega$ 的网络骨干。我们按照文献中的方法对所有数据集进行归一化。具体来说，对于MR图像，我们在脑掩膜内采用病例Z-score归一化，而对于CT图像，我们在裁剪Hounsfield单位（HU）从0.5%到99.5%之后，基于ROI样本采用数据集Z-score归一化。我们为所有实验采用默认数据增强策略。我们使用CE和样本软DSC损失的组合作为 $L$（权重相等），而使用BCE作为 $L_c$。我们使用批大小为2，补丁大小为80×80×80。我们训练脑肿瘤和病灶分割网络1000个epoch，肝脏、肾脏、结肠和胰腺肿瘤分割网络2000个epoch，因为我们观察到后者任务需要更多迭代才能收敛。我们在补充材料中总结了所有实验的超参数。所有报告结果都是两次运行（使用不同随机种子）的平均值。

2. **肝肿瘤分割**：我们使用来自肝脏肿瘤分割挑战（LiTS）的训练数据集评估CoLab，该数据集包含131张CT图像。我们排除了不包含任何肝肿瘤的样本，剩下118个病例。所有CT图像都按照文献中的方法重新采样到1.9×1.9×2.5毫米的共同体素间距。我们使用83个病例进行模型训练，35个病例进行测试。

3. **肾肿瘤分割**：我们进一步使用肾肿瘤分割挑战（KiTS）的训练数据集进行实验，该数据集包含210张CT图像。所有CT图像都按照文献中的方法重新采样到1.6×1.6×3.2毫米的共同体素间距。我们使用70个病例进行测试，其余140个病例作为训练数据。

4. **结肠肿瘤分割**：我们评估CoLab在CT图像的结肠肿瘤分割中的应用。我们从医学分割十项全能挑战的训练数据集中收集了126张结肠癌CT图像。所有CT图像都按照文献中的方法重新采样到1.6×1.6×3.1毫米的体素间距。我们使用88个病例进行模型训练，其余38个病例进行测试。

5. **脑肿瘤分割**：我们还使用VS数据集进行脑肿瘤分割实验，该数据集包含243张配对的T1加权和T2加权MR图像。我们只使用T2加权MR图像评估CoLab，但使用T1加权MR图像通过MALP-EM生成脑结构掩膜。我们没有使用脑掩膜进行此任务的直方图归一化，因为VS可能出现在脑边界，在使用常见脑提取算法时可能会被排除。所有MR图像都具有1.0毫米^3的相同各向同性体素间距。我们按照文献中的方法使用176个病例进行模型训练，46个病例进行测试。

6. **脑卒中病灶分割**：此外，我们使用中风后病灶解剖追踪（ATLAS）数据集评估CoLab在脑卒中病灶分割中的应用，该数据集包含220张T1加权MR图像。MR图像都具有1.0毫米^3的相同体素间距。我们随机选择145个病例作为训练数据，其余75个病例作为测试数据。

7. **胰腺和胰腺肿瘤块分割**：我们进一步在多类别分割设置中评估CoLab。具体来说，我们训练分割模型分割三个类别，包括胰腺、胰腺肿瘤块和背景。我们的目标是找到可以促进这两个前景类别分割的上下文标签。我们从医学分割十项全能挑战的训练数据集中收集了281张包含胰腺肿瘤的CT图像。所有CT图像都按照文献中的方法重新采样到1.3×1.3×2.6毫米的体素间距。我们将数据集随机分为197个病例用于训练，84个病例用于测试。

### B. 比较方法和处理

1. **基于K-means的上下文标签**：我们将CoLab与替代的上下文标签生成方法进行比较，包括通过聚类生成上下文标签。在这里，我们以内体掩膜或脑掩膜内的像素作为样本，并使用K-means构建 $t$ 个聚类。我们将 $t$ 设置为与人工定义解剖掩膜的类别数相同。具体来说，我们选择 $t=2$ 用于肝脏、肾脏、结肠和胰腺肿瘤分割，选择 $t=6$ 用于脑肿瘤和脑卒中病灶分割。

2. **基于膨胀掩膜的上下文标签**：我们还与使用ROI膨胀掩膜作为上下文标签的基线进行比较。这种思想与标签平滑有些类似，其中模型使用模糊的ROI标签进行训练。具体来说，我们采用公式8中定义的软膨胀掩膜 $M_i$，并将上下文概率设置为 $p_i = [1 - M_i, M_i]^\top$。

3. **使用外部数据集预测的上下文标签**：我们进一步评估并比较了一种利用来自其他数据集的先验知识的方法。具体来说，我们使用来自文献的数据集（包含14个腹部器官（包括肝脏和肾脏）的标签）训练了一个分割模型，该数据集包含20张CT图像。我们将这20张CT图像重新采样到1.6×1.6×3.2毫米的体素间距。我们减少了模型对纵轴的依赖性，并使用128×128×32的补丁大小训练分割模型，因为切片数量在不同数据集之间有所不同。然后，我们将这个分割模型应用于LiTS和KiTS的重新采样训练分割，并提取肝脏和肾脏掩膜作为自动生成的上下文解剖掩膜。

4. **后处理**：我们还与一种常见的策略进行比较，该策略基于基于组件的后处理来抑制分割中的FP，这广泛应用于许多分割管道。具体来说，我们假设总是存在一个ROI，并删除除最大区域之外的所有区域。对于ROI包含多个类别的情况（胰腺和胰腺肿瘤分割），我们将所有ROI作为一个整体，只保留最大的组件。

### C. 定量结果

我们在表I中总结了使用不同类型上下文标签在五个二元分割数据集上训练的模型，以及在表II中总结了一个多类别分割数据集上的模型的定量结果。我们根据是否需要专家知识和手动标注工作将结果分开。以手动分割结果作为ground truth，我们计算了DSC、灵敏度（SEN）、精确度（PRC）和HD。我们在图2(c)中展示了CoLab的一些分割结果，并在图8中总结了所有相应的上下文标签。我们在补充材料中提供了上下文标签的额外示例。

如第三节所述，基线分割模型似乎欠拟合异构背景样本，导致许多FP和精确度下降。我们发现大多数评估的上下文标签方法都可以通过提高精确度来改善模型的整体分割精度。我们观察到添加上下文标签持续有利于模型训练并提高性能。

1. **基线方法性能**：基于K-means的上下文标签根据像素强度将背景样本划分为不同的类别。这些上下文标签似乎有助于分割模型将腹部器官和骨骼与脂肪和空气等背景分离在CT图像中，而在脑部MR图像中，它可能有助于将图像分割为不同的区域，如白质和脑室。我们发现这些基于K-means的上下文标签对肝脏和肾脏肿瘤分割是有效的，但对结肠肿瘤、脑肿瘤、脑病灶和胰腺肿瘤分割效果较差。这可能是因为CT中大型器官和背景的强度差异明显，生成的标签具有有意义的语义信息，通过增强肾脏和肝脏肿瘤的上下文表示而有利于模型训练。由于结肠肿瘤的外观是异质的，其分割更多地依赖于空间信息，无法从纯粹基于强度的上下文标签中受益。由于胰腺标签已经为胰腺肿瘤分割提供了丰富的上下文信息，我们发现K-means和膨胀掩膜等基线上下文标签技术无法提供额外的益处。大脑解剖结构的复杂性使得K-means生成的类别会变得嘈杂和不连贯。在这里，K-means生成的标签带来的益处较少，因为它们为ROI提供了不足的上下文。

基于膨胀掩膜的上下文标签使分割模型意识到ROI附近的区域。我们发现这些上下文标签对肝脏肿瘤、肾脏肿瘤、结肠肿瘤、脑病灶和胰腺分割有效，但对脑肿瘤分割的改进有限。这可能是因为肝脏肿瘤、肾脏肿瘤、结肠肿瘤和脑病灶出现在主要器官的不同部位。如果作为二元任务进行训练，分割模型会将肝脏、肾脏和结肠区域之外的FP，或大脑解剖学上不相关的部分的FP预测为肿瘤，因为这些样本与ROI具有相似的特征，如图2(a)所示。在这种情况下，膨胀掩膜可以增强ROI与其周围上下文之间的空间关系。例如，膨胀掩膜将肝肿瘤分割与肝脏上下文连接起来，避免了肝脏区域之外的FP。然而，VS数据集的样本每个病例只包含一个ROI，并且VS总是出现在前庭上区周围。因此，分割模型不需要更多的空间信息来定位ROI，并且没有从膨胀掩膜中受益。

如图8的第三列所示，我们获得了高质量的肝脏和肾脏区域自动分割，因为大型器官的分割在CT图像中相对容易和鲁棒。模型预测的掩膜与使用手动标注解剖掩膜相比显示出相似的改进。然而，当对ROI的先验知识不可用，或者无法访问外部手动标注数据集来训练监督模型以生成上下文标签时，这种方法不适用。

我们在补充材料中总结了基于组件的后处理结果。我们发现后处理总是会降低肝脏肿瘤、结肠肿瘤和脑病灶分割的DSC总体性能，因为在这些任务中每个病例总是存在多个独立的ROI。对于肾肿瘤、胰腺肿瘤和脑肿瘤分割，我们发现后处理在大多数情况下可以提高整体分割性能，具有更高的精确度，而使用上下文标签训练的模型始终优于使用二元任务训练的模型。这表明靠近ROI的FP无法通过简单的后处理消除。

2. **CoLab**：如图2(c)所示，CoLab可以有效减少不同类型的假阳性预测，提高精确度，同时保持灵敏度。CoLab可以应用于不同的任务，具有相似的超参数，并显示出持续的改进（DSC提高+2.2至+8.1个点）。我们发现CoLab比所有其他不使用专家知识的上下文标签方法产生更好的分割结果。此外，CoLab与使用器官掩膜进行肝脏和肾脏肿瘤分割相比显示出相似的改进，甚至在脑肿瘤分割方面表现更好，与使用组织掩膜相比。特别有趣的是，CoLab可以改善胰腺肿瘤块的分割性能，在其强大的胰腺上下文标签之上。这表明对于具有人类定义上下文标签的分割任务，上下文表示仍有改进空间。CoLab是一种灵活通用的方法，可以直接应用于具有异构背景类别的各种分割任务，以提高性能。我们进一步根据强度直方图分析了CoLab生成的上下文标签，并在补充材料中总结了结果。我们发现CoLab生成的上下文标签可以突出与背景样本具有不同强度分布的区域。其中一个生成的上下文标签的强度总是与ROI的强度相似。这可能表明CoLab可以生成有用且语义化的上下文标签，从而帮助分割模型更好地将ROI与相似的背景样本区分开来。

我们评估了CoLab在不同数量上下文类别 $t$ 下的性能。我们发现，当分割模型倾向于在远离ROI的地方产生FP时，例如肝肿瘤、肾肿瘤、结肠肿瘤、脑病灶和胰腺肿瘤，$t=2$ 是最有效的。这可能表明分割任务主要需要上下文标签提供空间信息，$t=2$ 使得CoLab专注于ROI的位置，因为任务生成器只需要将一个上下文类别与其余背景分离。这个单一类别将增强ROI与其周围对象之间的空间关系。这与图8所示的结果观察结果一致。具体来说， $t=2$ 生成的上下文标签突出显示了肝脏、肾脏和结肠区域附近的区域，并且可以隐式帮助分割模型专注于ROI边界附近。

当基线分割模型在ROI周围产生FP时，例如VS分割， $t=4$ 和 $t=6$ 似乎更有效。这可能是因为分割需要更多关于周围对象的结构信息，并且大脑解剖的复杂上下文在分解为2个以上类别时可以更好地表示。如图8所示， $t=4$ 生成的上下文标签突出显示了ROI周围的结构信息。具体来说，CoLab为VS分割生成了前庭上区的分割，而基线模型在该区域预测了FP。类似地，在脑病灶分割任务中，上下文标签突出显示了脑室周围的区域以避免该区域的FP。通过这样做，模型通过为脑室区域构建特定的表示来学习空间信息。

我们应该注意到，CoLab在较大的 $t$ 值下可能不太有效，特别是我们发现 $t=6$ 的CoLab对肾肿瘤、结肠肿瘤和脑病灶分割不会带来太多改进。如图8所示，我们观察到生成的上下文标签会出现棋盘状图案。这可能是因为进一步分解背景类别并不能使任务更容易学习。在这种情况下，我们发现任务生成器无法生成连贯的标签，并在这些区域为不同类别生成相似的概率，使得上下文标签变得琐碎且难以学习。

一般来说，我们发现 $t=2$ 在大多数情况下是DSC最有效的选择，特别是对于腹部CT图像中的肿瘤分割。这可能表明背景表示不那么复杂，可以通过添加精细的空间信息来改进。当使用 $t$ 大于2进行训练时，与使用 $t=2$ 训练的模型相比，模型在HD方面可能具有更好的结果。在这种情况下，模型更好地学习了背景类别，因为它们在远离ROI的地方产生的FP更少。然而，选择 $t$ 大于2似乎会使模型未能很好地学习前景类别，导致DSC和灵敏度下降。这可能是因为增加 $t$ 可能会使前景类别的预测更加困难。

我们建议当基线模型在远离ROI的地方产生FP时使用 $t=2$，当在ROI附近观察到过分割时使用 $t=4$。此外，我们研究了不同数据集ROI的强度直方图，并在补充材料中总结了结果。我们发现大多数ROI的强度分布与背景样本的强度分布没有明显区别，除了脑肿瘤。也许对于脑肿瘤分割，模型可以通过了解与ROI具有最相似强度分布的区域而受益，因此需要更多类别的上下文标签。这可能是脑肿瘤的最佳上下文类别 $t$ 为4而不是2的一个潜在因素。实践者可以利用ROI的强度直方图来选择最佳的 $t$。根据这些发现，我们建议对于与背景样本强度相似的ROI选择 $t=2$，而对于与背景样本强度分布不同的ROI选择 $t>2$。

### D. 对 Logit 分布的影响

我们还在图3(c, f, i)中展示了CoLab（肝脏和肾脏肿瘤分割 $t=2$，脑肿瘤分割 $t=4$）对logit分布的影响。我们发现CoLab与使用解剖学掩膜具有相似的正则化效果。通过分解背景类别，分割模型可以鲁棒地将背景样本映射到远离决策边界的不同位置，减少logit偏移，从而减少FP。

## VI. 结论

在这项研究中，我们发现分割模型在存在异构背景类别时容易对ROI进行过分割。通过观察多种分割任务中的网络行为，我们得出结论，这是由于模型无法从背景样本中学习到区分性表示，并且通过在训练过程中整合上下文标签可以显著改善模型。我们提出了CoLab，一种通用的方法，通过元学习方案自动生成有效的上下文标签。我们展示了CoLab在几个具有挑战性的分割任务中大幅提高了整体分割性能，而无需专家知识和繁琐的标注工作。在未来的工作中，我们将评估CoLab在领域转移等环境中的表现。探索在多任务设置中自动生成上下文标签也将很有趣，其中共享骨干模型经过训练可以自动识别跨任务甚至数据集的有趣子类别。

## 补充材料

### A. 训练数据的网络行为

我们在图9中展示了训练数据的网络行为。其行为与测试数据的行为相似。我们观察到训练数据和测试数据之间性能差距很小。这表明模型无法很好识别背景样本的原因是它欠拟合训练数据。因此，即使对于训练数据，模型也可能产生假阳性。我们发现解剖学掩膜和CoLab都可以缓解这个问题。

### B. 实现细节

1. **基于隐函数定理的导数计算**：可以基于隐函数定理获得 $\frac{\partial \theta^*}{\partial \omega}$。为了计算 $\frac{\partial \theta^*}{\partial \omega}$，可以假设 $\nabla_\theta L_\text{seg}(\theta^*, \omega)$ 在 $\omega$ 方面在0附近是连续可微的，然后对 $\nabla_\theta L_\text{seg}(\theta^*, \omega) = 0$ 对 $\omega$ 求全导数：

$$
\frac{\partial \nabla_\theta L_\text{seg}(\theta^*, \omega)}{\partial \theta} \frac{\partial \theta^*}{\partial \omega} + \frac{\partial \nabla_\theta L_\text{seg}(\theta^*, \omega)}{\partial \omega} = 0 \tag{16}
$$

假设 $\nabla^2_\theta L_\text{seg}(\theta^*, \omega)$ 可逆，可以得到：

$$
\frac{\partial \theta^*}{\partial \omega} = -(\nabla^2_\theta L_\text{seg}(\theta^*, \omega))^{-1} \nabla^2_{\theta, \omega} L_\text{seg}(\theta^*, \omega) \tag{17}
$$

然而，Hessian $\nabla^2_\theta L_\text{seg}(\theta^*, \omega)$ 很难计算。因此，在这项研究中，我们遵循一些启发式方法，如文献中的方法来近似 $\frac{\partial \theta^*}{\partial \omega}$。

2. **元梯度计算**：在我们的研究中，我们根据文献中的方法，使用有限差分近似进一步简化了公式15的计算。我们计算网络参数 $\theta^\pm = \theta \pm \epsilon \nabla_\theta L_\text{ROI}(\theta^*)$，给定一些小标量 $\epsilon = 0.01 / \|\nabla_\theta L_\text{ROI}(\theta^*)\|_2$。有了这个概念，二阶梯度可以写为：

$$
\nabla^2_{\omega^t, \theta} L_\text{seg}(\theta^*, \omega^t) \approx \frac{\nabla_{\omega^t} L_\text{seg}(\theta^+, \omega^t) - \nabla_{\omega^t} L_\text{seg}(\theta^-, \omega^t)}{2 \epsilon \nabla_\theta L_\text{ROI}(\theta^*)} \\
\Leftrightarrow \nabla^2_{\omega^t, \theta} L_\text{seg}(\theta^*, \omega^t) \nabla_\theta L_\text{ROI}(\theta^*) \approx \frac{\nabla_{\omega^t} L_\text{seg}(\theta^+, \omega^t) - \nabla_{\omega^t} L_\text{seg}(\theta^-, \omega^t)}{2 \epsilon} \tag{18}
$$

通过这种方式，我们将计算复杂度从 $O(|\omega||\theta|)$ 降低到 $O(|\omega|+|\theta|)$，并且可以通过 $\tilde{f}_{\theta^*}$ 的两个前向过程来近似公式15。

3. **任务生成器更新**：我们发现如果上下文标签变化过于频繁，分割模型将无法很好地学习。因此，我们每隔几个 epoch 才更新任务生成器。具体来说，我们每10个 epoch 才按照算法1中的步骤8更新 $\omega$。每隔几个 epoch 更新 $\omega$ 的另一个好处是，我们不需要比常规训练过程多花费太多的时间。实际上，我们发现CoLab只会增加常规训练时间20%到30%。

### C. CoLab的超参数

我们在表III中总结了我们使用的CoLab超参数。我们为所有任务选择了相似的软膨胀掩膜 $M_i$ 超参数。我们发现，对于肾肿瘤分割，生成的上下文标签在不同的训练 epoch 中变化很大，因此我们选择不那么频繁地更新该任务的 $g_\omega$。类似地，我们发现在结肠肿瘤分割中优化CoLab相对困难，因为生成的上下文标签很容易退化为单个类别。因此，我们也对该任务的 $g_\omega$ 不那么频繁地更新。总的来说，我们发现相同的超参数集可以在不同的数据集上有效，这表明CoLab对不同的应用场景具有鲁棒性和灵活性。

### D. 后处理结果

我们补充材料中总结了所有使用基于组件的后处理的结果（表IV）。我们发现这种后处理总是会降低肝脏肿瘤、结肠肿瘤和脑病灶的分割性能，因为这些任务每个病例通常存在多个ROIs。对于肾肿瘤、脑肿瘤和胰腺肿瘤分割，后处理可以在大多数情况下提高整体分割性能，具有更高的精确度。后处理后，我们发现CoLab可以帮助模型在与其他无需人工努力的上下文标签生成方法比较时，实现最佳分割性能。

### E. 上下文标签的额外可视化

我们在图10中提供了生成的任务的额外示例，这是图8的补充。

### F. ROI和上下文标签的强度直方图

我们分析了不同数据集上下文标签的强度，并在图11的右侧总结了强度直方图。基于K-means的上下文标签是根据像素强度生成的，因此不同类别的直方图通常分布在不同的区域。基于膨胀掩膜的不同类别的上下文标签总是共享相似的强度分布，因为膨胀掩膜只考虑了空间信息，不包含太多语义意义。CoLab通过元学习学习在膨胀区域内生成上下文标签。类似于解剖掩膜，CoLab会突出显示与ROI相似但与背景样本不同的相关语义区域。我们应该注意的是，在这里我们只分析了CoLab最终模型中学到的上下文标签。由于任务生成器也会在训练过程中进行优化，因此很难解释CoLab如何帮助分割模型更好地学习。

我们还在图11的左侧部分研究了ROI的强度直方图。我们发现ROI的强度直方图总是与背景样本的强度直方图大部分重叠。模型可能需要外部空间信息来增强ROI位置的先验知识。$t=2$ 可以使CoLab突出显示周围区域，这可以帮助模型减少对强度相似但远离ROI的样本的假阳性预测。在这种情况下，模型无法从 $t>2$ 的更详细类别表示中受益，因为这会进一步关注分解ROI周围的样本。相反，我们注意到只有脑肿瘤的强度分布会与背景样本的强度分布有所不同。为了进一步提高分割精度，模型可能需要更具体的子区域信息来区分ROI和强度相似的区域。这可能是脑肿瘤分割的最佳上下文类别 $t$ 为4而不是2的一个潜在因素。实践者可以利用ROI的强度直方图来选择最佳的 $t$。根据这些发现，我们建议对于与背景样本强度相似的ROI选择 $t=2$，而对于与背景样本强度分布不同的ROI选择 $t>2$。