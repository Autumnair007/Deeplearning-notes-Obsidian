---
type: paper-note
tags:
  - cv
  - panoptic-segmentation
  - instance-segmentation
  - semantic-segmentation
  - two-stage
  - fpn
  - sfpn
  - mask-rcnn
  - panoptic-fpn
status: done
model: Panoptic FPN
year: 2019
---
论文原文：[1901.02446](https://arxiv.org/pdf/1901.02446)

本地pdf文件：[SFPN](../../../../99_Assets%20(资源文件)/papers/Panoptic%20Feature%20Pyramid%20Networks.pdf)

------
## 摘要

这篇论文介绍了Panoptic FPN，一个统一实例分割（针对“事物”类别）和语义分割（针对“材质”类别）的单网络架构。现有的顶级全景分割方法通常使用分离且不同的网络来处理这两种任务，缺乏共享计算。作者旨在从架构层面上统一这些方法，设计一个**单网络**来同时处理这两种任务。

Panoptic FPN的核心思想是在流行的实例分割方法Mask R-CNN的基础上，为其增加一个语义分割分支，并共享一个特征金字塔网络（FPN）骨干。令人惊讶的是，这种简单的基线不仅在实例分割方面保持了高效，而且在语义分割方面也达到了轻量级、高性能。

论文对这种最简单扩展的Mask R-CNN与FPN的结合进行了详细研究，发现它是一个鲁棒且准确的基线。由于其有效性和概念上的简单性，作者希望Panoptic FPN能作为一个强大的基线，并为未来的全景分割研究提供帮助。

## 1. 引言

语义分割和实例分割是计算机视觉领域的两大重要任务。语义分割旨在对图像中的每个像素进行类别标记（例如，区分“草地”、“天空”等材质类）。实例分割则旨在检测并分割图像中的每个独立对象实例（例如，区分图像中的每一辆“汽车”）。随着这些领域的发展，人们对将两者结合的全景分割任务产生了兴趣。

全景分割任务旨在为图像中的每个像素分配一个类别标签**和一个实例ID**（如果该像素属于一个“事物”对象）。这意味着对于“事物”类别（如人、汽车），模型需要区分不同的实例；对于“材质”类别（如天空、草地），则只需要给出其语义标签，无需区分实例。

以前在语义分割和实例分割方面都取得了显著进展，得益于一些简单而强大的基线方法，例如用于语义分割的全卷积网络（FCN）和用于实例分割的Mask R-CNN。Mask R-CNN尤其以其在实例分割方面的强大性能和灵活性而闻名，并已成为许多后续研究的基础。

尽管全景分割在概念上直观，但设计一个能同时在两个任务上都达到高精度的单网络是具有挑战性的。因为针对这两个任务的顶尖方法在架构上存在显著差异：

*   **语义分割**：通常使用FCNs，配合空洞卷积（dilated convolutions）来增强骨干网络，以捕获更广阔的上下文信息。代表性方法如DeepLab系列。
*   **实例分割**：以区域检测为基础的Mask R-CNN，通常采用FPN作为骨干网络来处理多尺度对象。

尽管已有尝试统一语义分割和实例分割，但为达到顶尖性能所需的专业化差异，使得在单一网络中实现两者难以兼顾。这篇论文的目标是提供一个简单、灵活、高效的架构，通过一个单一网络同时生成基于区域的输出（用于实例分割）和密集像素输出（用于语义分割），且能在两个任务上都达到相当的精度。作者希望这项工作能作为一个强有力的基线，推动未来全景分割领域的研究。

## 2. 相关工作 (Related Work)

本节主要回顾了全景分割、实例分割、语义分割以及多任务学习等与Panoptic FPN相关的前人研究，为理解Panoptic FPN的贡献提供了背景。

### 全景分割 (Panoptic Segmentation)

全景分割作为一个新兴任务，其历史渊源可以追溯到早期的场景解析（scene parsing）、图像解析（image parsing）和整体场景理解（holistic scene understanding）等工作。这些传统任务也尝试结合像素级分类和对象实例识别。然而，直到2017年左右，**全景分割任务被正式提出并引入了简单明确的任务规范和精心设计的评估指标（PQ）**，才重新唤起了社区对这一联合任务的兴趣。

论文提到2018年的COCO和Mapillary识别挑战赛中，全景分割赛道非常受欢迎。但是，所有具有竞争力的参赛作品都**使用了独立的网络来处理实例分割和语义分割，之间没有共享计算**。这与Panoptic FPN的核心目标形成了对比——Panoptic FPN正是要设计一个**单一网络**来有效处理这两个任务。作者指出，尽管一些团队最初使用了分离网络，但后来也有团队意识到了统一网络的潜力，并在其后续工作中尝试了联合网络。

### 实例分割 (Instance Segmentation)

实例分割领域的发展主要由基于区域（region-based）的方法主导，尤其是R-CNN家族：Slow R-CNN, Fast R-CNN, Faster R-CNN, 以及Mask R-CNN。

*   **R-CNN家族**：这些方法的核心思想是在候选对象区域上应用深度网络。它们在对象检测任务中取得了巨大成功，并逐渐演变为能够进行实例分割。
*   **Mask R-CNN**：论文指出，所有最近的COCO检测挑战赛的获胜方案都建立在Mask R-CNN与FPN的基础上。Mask R-CNN通过在Faster R-CNN的基础上添加一个预测二值掩码的分支，实现了卓越的实例分割性能。Panoptic FPN正是以其为起点，并完全兼容其最近的改进（如Cascade R-CNN、可变形卷积、同步批归一化等）。

除了基于区域的方法，还有一些替代方法通过**像素级语义分割然后进行分组**来提取实例。例如，[31, 38, 1]等方法通过预测边缘、边界框或对象断点等信息来辅助分组。然而，这些方法通常仍然需要**单独的网络**来预测这些实例级信息。Panoptic FPN的目标是**设计一个用于联合任务的单一网络**，这与这些方法有所不同。

尽管如此，基于区域的方法仍然在检测排行榜上占据主导地位。Panoptic FPN选择基于区域的方法作为实例分割的起点，但其设计思路也可以兼容其他密集的、像素级预测的实例分割分支。

### 语义分割 (Semantic Segmentation)

现代语义分割方法的基础是**全卷积网络（FCNs）**。为了提高特征分辨率，这是生成高质量分割结果所必需的，最近的顶尖方法主要依赖以下两种策略：

1.  **空洞卷积 (Dilated Convolution / Atrous Convolution)**：
    *   通过使用空洞卷积，网络可以在不增加参数量或减少特征图分辨率的情况下扩大滤波器的感受野，从而捕获更广阔的上下文信息。
    *   代表性方法如DeepLab系列。
    *   **优点**：可以保持高分辨率特征图，同时融合多尺度上下文。
    *   **缺点**：在某些情况下可能增加计算和内存消耗，并可能引入“网格效应”；且限制了骨干网络的灵活性。

2.  **编码器-解码器架构 (Encoder-Decoder Architecture / U-Net)**：
    *   这些架构包括一个下采样（编码器）路径来捕获上下文信息，以及一个上采样（解码器）路径来恢复空间分辨率。解码器通常通过跳跃连接（skip connections）将编码器中的低级、高分辨率特征与高级、低分辨率特征融合，以获得精确的分割边界。
    *   代表性方法如U-Net。
    *   **FPN**：FPN被视为一种编码器-解码器框架。与“对称”解码器（如U-Net）不同，FPN使用一个**轻量级的非对称解码器**，其主要设计目标是用于实例分割。论文的一个关键发现是，FPN在不做任何改变的情况下，也可以非常有效地用于语义分割。

Panoptic FPN选择将**FPN**作为特征提取的基础，这与Mask R-CNN的兼容性是主要动机，同时也避免了空洞卷积可能带来的计算和内存高开销，保持了骨干网络的灵活性。

### 多任务学习 (Multi-task Learning)

多任务学习是指一个模型同时学习多个相关任务。

*   **挑战与机遇**：通常情况下，让一个模型学习多个差异大的任务可能会导致性能下降。然而，对于相关任务，多任务学习可以带来收益。例如，Mask R-CNN中边界框分支和掩码分支的协同学习就是一例。
*   **Thing和Stuff的联合学习**：将“事物”和“材质”分割结合起来，属于一种多任务学习。这篇论文研究了共同训练这两种任务所带来的益处。

通过回顾这些相关工作，论文明确了Panoptic FPN的创新点：在现有强大的实例分割基线Mask R-CNN与FPN的基础上，以最小的改动，将语义分割功能融入**单一网络**，并证明了其在两个任务乃至联合全景分割任务上的高效性和高精度。

## 3. Panoptic Feature Pyramid Network (Panoptic FPN)

作者提出的Panoptic FPN方法是一个**单网络基线**，目标是在实例分割、语义分割以及它们联合的全景分割任务上都达到顶尖性能。其设计原则是从Mask R-CNN与FPN这个强大的实例分割基线开始，并进行**最小化修改**以使其也能生成语义分割的密集像素输出。

### 3.1. 模型架构

#### 特征金字塔网络 (FPN) 详解

**FPN (`Feature Pyramid Network`)** [36] 是Panoptic FPN的==骨干网络==，它在目标检测和实例分割领域取得了巨大成功。FPN能够**有效地处理多尺度目标**，并为不同尺度的目标提供高质量的特征表示。其核心思想是 **结合高层语义信息和低层细节信息** 来构建一个特征金字塔。

**1. 自下而上路径 (Bottom-up Pathway)**：
这是传统的卷积神经网络（如ResNet）的前向传播过程。随着网络层数的加深，特征图的空间分辨率逐渐降低，但感受野增大，提取的语义信息越来越丰富。

*   输入图像经过骨干网络，得到不同阶段的特征图。论文中以`ResNet`为例，通常会使用`C2`, `C3`, `C4`, `C5`这四层特征图，它们的分辨率相对于输入图像分别为`1/4`, `1/8`, `1/16`, `1/32`。
*   `C2`分辨率最高，包含丰富的细节信息；`C5`分辨率最低，但语义信息最强。

**2. 自上而下路径 (Top-down Pathway)**：
为了在所有尺度上都获得包含强大语义信息的特征，FPN从最顶层的特征图（语义最强但分辨率最低）开始，逐步进行上采样。

*   `P5`是`C5`经过一个`1x1`卷积（为了统一通道数，通常为256）得到。
*   `P4`是通过将`P5`进行`2x`上采样，然后与`C4`经过`1x1`卷积后的结果**逐元素相加**（element-wise addition）得到的。
*   这个过程持续到`P2`，即`P3`上采样后与`C3`经过`1x1`卷积后的结果相加，得到`P2`。
*   所有金字塔级别的特征图（`P2`, `P3`, `P4`, `P5`）都拥有**相同的通道维度**（默认256），这使得在不同层级上共享后续的头部网络变得容易。

**3. 横向连接 (Lateral Connections) - 增强信息流**：
这是FPN的关键创新点。它将自下而上路径中的高分辨率特征图（如`C4`）与自上而下路径中上采样后的低分辨率、高语义特征图（如上采样后的`P5`）进行融合。

*   融合方式通常是：`1x1`卷积调整低层特征的通道数，然后与上采样后的高层特征进行**逐元素相加**。
*   这种连接允许高层语义信息流向下层，同时低层特征的精确位置信息和细节得以保留。

**4. 输出金字塔 (Output Pyramid)**：
最终，FPN输出一个特征金字塔，通常包括`P2`, `P3`, `P4`, `P5`或更多。每个级别都包含了来自不同尺度和语义层次的信息。

*   `P2`具有最高的空间分辨率 (`1/4`)，适合检测和分割小物体或精细结构。
*   `P5`具有最低的空间分辨率 (`1/32`)，但包含最抽象、最丰富的语义信息，适合检测和分割大物体。

FPN的强大之处在于它在不同尺度上都提供了语义丰富的特征，这对于需要处理不同大小目标的对象检测和实例分割任务至关重要。

#### 实例分割分支 (Instance Segmentation Branch)

Panoptic FPN的实例分割部分是基于**Mask R-CNN** [24] 实现的，并继承了其在目标检测和实例分割方面的卓越性能。

**1. 区域提议网络 (Region Proposal Network, RPN)**：

*   RPN直接在FPN的每个特征金字塔级别（`P2`, `P3`, `P4`, `P5`, `P6`）上操作。
*   它通过滑动窗口的方式生成大量的**锚点框 (anchor boxes)**，并预测这些锚点框是前景还是背景，并对前景框进行初步的边界框回归。
*   最终，RPN输出一系列高质量的**区域提议 (Region of Interests, RoIs)**，这些RoIs代表了可能包含对象的区域。

**2. ROIAlign (Region of Interest Align)**：

*   传统的`ROIPool`或`ROIAlign`操作将不同大小的RoIs（它们可能来自FPN的不同层级）池化到固定大小的特征图。
*   **ROIAlign**是Mask R-CNN的关键改进，它使用**双线性插值**来避免量化误差，从而保留了像素级别的对齐信息，这对于生成高质量的掩码至关重要。
*   每个RoI根据其大小和分辨率，被分配到FPN金字塔的某个层级（例如，小RoI使用`P2`特征，大RoI使用`P5`特征）。

**3. 共享头部网络 (Shared Head Network)**：

*   池化后的固定大小特征图（例如`7x7`或`14x14`）被送入后续的共享网络分支。
*   这个分支通常包括多个卷积层或全连接层，用于并行地进行三项预测：
    *   **类别预测 (Classification)**：预测RoI中包含的对象的具体类别。
    *   **边界框回归 (Bounding Box Regression)**：进一步精修RoI的边界框坐标，使其更精确地包围对象。
    *   **掩码预测 (Mask Prediction)**：这是一个关键分支，它是一个小型的**全卷积网络 (FCN)**。它对池化后的特征图进行操作，输出一个与RoI空间大小相同的二值掩码（例如 `28x28`），表示RoI内部的像素是否属于该对象实例。这个掩码分支是Mask R-CNN实现像素级实例分割的核心。

**输出**：经过上述步骤，实例分割分支为每个检测到的对象实例提供：精确的边界框、对象类别和像素级的二值掩码。

#### Panoptic FPN：最小化扩展实现语义分割

Panoptic FPN的核心在于，它在Mask R-CNN所使用的FPN骨干之上，**并行增加了**一个**语义分割分支**。这种设计非常巧妙，因为它充分利用了FPN已经具备的特点来满足语义分割的需求，从而实现了“最小改动”的设计原则：

1.  **高分辨率特征**：FPN的`P2`层（分辨率为`1/4`）提供了足够高的分辨率，足以捕捉语义分割所需的精细结构。
2.  **丰富的语义信息**：FPN的自上而下路径确保了所有金字塔级别的特征都融合了高层的语义信息。
3.  **多尺度信息**：FPN的多个层级本身就包含了不同尺度的特征表示，这对于处理不同大小的“材质”区域至关重要。

由于FPN天然地满足了这些要求，因此在FPN之上构建语义分割分支成为一个水到渠成的选择。

#### 语义分割分支 (Semantic Segmentation Branch) 详解

语义分割分支的目的是从FPN的多个层级中融合信息，生成一个密集的像素级语义预测。其设计如图3所示：

**1. 特征上采样与融合 (Feature Upsampling and Merging)**：

*   **输入**：FPN的各个层级，如`P2`, `P3`, `P4`, `P5`（假设通道数均为256）。
*   **处理过程**：
    *   从最深、语义最丰富的FPN层（`P5`，1/32尺度）开始。首先通过一个`3x3`卷积层将通道数从256降至128（这是论文中的实现细节，为了效率）。
    *   然后，进行一系列的**上采样阶段**，直到所有特征图都达到**1/4尺度**（即与`P2`相同的分辨率）。每个上采样阶段包含：
        *   `3x3`卷积：用于进一步提取特征并降低通道数（例如，继续保持128）。
        *   `组归一化 (Group Normalization, GN)` [54]：GN是一种替代批归一化的归一化方法，它在小批量训练、或在多任务、多GPU训练场景下可能比BN更稳定和表现更好。GN将特征通道分组并独立地进行归一化，而不是在整个批量上归一化。
        *   `ReLU`激活函数：引入非线性。
        *   `2x`双线性上采样 (Bilinear Upsampling)：放大特征图空间分辨率。
    *   具体步骤：
        *   `P5 (1/32)`：经过3个上采样阶段，达到`1/4`尺度。
        *   `P4 (1/16)`：经过2个上采样阶段，达到`1/4`尺度。
        *   `P3 (1/8)`：经过1个上采样阶段，达到`1/4`尺度。
        *   `P2 (1/4)`：直接送入后续处理，无需上采样。
*   **特征融合**：将所有达到`1/4`尺度的来自`P2`, `P3`, `P4`, `P5`的特征图进行**逐元素相加（element-wise sum）**。这种求和操作简单高效，且能够有效地融合不同层级的语义信息。

**2. 最终预测头 (Final Prediction Head)**：

*   对融合后的`1/4`尺度特征图进行最终处理，以生成像素级分类。
*   `1x1`卷积：将融合特征的通道数转换为所需的类别数量。这些类别包括所有的“材质”类别，以及一个特殊的“其他”（`other`）类别。
    *   **“其他”类别**：为了避免模型将“事物”类别的像素错误地分类为“材质”类别，专门引入一个“其他”类别来表示所有属于可数对象（即“事物”类别）的像素。在训练时，所有“事物”实例的像素都被标注为“其他”类别。
*   `4x`双线性上采样：将特征图的分辨率从`1/4`恢复到**原始图像分辨率**。
*   `Softmax`激活：将每个像素的输出转换为对应所有类别的概率分布。

**原理与优势**：
这个语义分割分支的设计体现了**“自下而上”的细节补充与“自上而下”的语义增强**相结合的思想。FPN已经完成了多尺度特征的融合，并且提供了一系列语义丰富的特征。语义分支进一步将这些特征统一到高分辨率，并通过简单的卷积和上采样生成最终预测。这种设计不仅高效（相较于复杂的解码器），而且由于共享FPN，整个Panoptic FPN的结构保持了简洁和统一。

**实现细节**：
*   FPN的输出通道默认为256。语义分割分支在处理这些特征时，通常会通过`1x1`卷积或`3x3`卷积将通道数降至128。这种通道数的缩减有助于降低计算复杂度和内存消耗。
*   骨干网络（在FPN之前）通常使用在ImageNet上预训练的ResNet或ResNeXt模型。
*   **批归一化 (Batch Normalization, BN) 的处理**：在微调（fine-tuning）过程中，预训练模型中的BN层通常会被替换为**固定通道仿射变换**。这是因为BN层的行为依赖于当前mini-batch的统计信息，这在训练和推理阶段的行为可能不一致，或者在分布式训练、小批量训练时可能不稳定。将其冻结或替换为固定仿射变换，可以避免这些问题，提升模型的泛化能力和稳定性。

### 3.2. 推理和训练

#### 全景推理 (Panoptic Inference)

全景分割的输出格式相对特殊，它要求**每个像素被唯一地分配一个类别标签和一个实例ID**（对于“材质”类别，实例ID可以忽略）。由于Panoptic FPN同时输出实例分割结果（Mask R-CNN分支）和语义分割结果（语义分支），两者可能会在某些像素上产生冲突或重叠。因此，需要一个后处理步骤来解决这些冲突，从而生成符合全景分割规范的最终输出。论文采用了[30]中提出的**简单后处理算法**，其核心思想是优先处理“事物”类别：

1.  **解决不同实例间的重叠**：实例分割分支可能会对同一区域检测到多个重叠的实例。此时，根据这些实例的**置信度分数**来决定最终保留哪个实例的预测。通常，选择置信度最高的实例。
2.  **解决实例与语义分割输出间的重叠**：这是全景分割后处理的关键规则。如果一个像素同时被实例分割（例如，预测为“汽车”的实例A）和语义分割（例如，预测为“道路”）覆盖，则**实例分割的预测具有更高的优先级**。即，该像素最终会被分配给“汽车”实例A。这个规则符合全景分割的定义：有实例的“事物”类别应优先于“材质”类别。
3.  **移除无效区域**：
    *   移除任何被语义分支标记为“**其他**”类别的区域。这些区域在训练时表示“事物”类别的像素，在最终的全景分割中，这些像素应该被实例分割的结果覆盖，因此语义分支的“其他”预测将被丢弃。
    *   移除任何面积小于给定阈值的“材质”区域。这有助于过滤掉噪声或不重要的背景碎片。

这种后处理方法虽然简单，但有效地将两个分支的输出整合为符合全景分割要求的单一结果，确保了“事物”和“材质”类别的良好协同。

#### 联合训练 (Joint Training)

在Panoptic FPN中，同时训练实例分割分支和语义分割分支需要仔细的策略，因为两个任务的损失性质、尺度和归一化方式可能不同。直接简单地相加损失函数可能会导致**优化不稳定或偏向于某个任务**，从而降低整体性能。

**1. 损失函数构成**：

*   **实例分割损失** ($L_i$)：如前所述，包括分类损失 ($L_c$)、边界框损失 ($L_b$) 和掩码损失 ($L_m$)。
    
    *   $L_c$ 和 $L_b$ 通常通过采样的`RoI`数量进行归一化（例如，Faster R-CNN中采样的`RoI`数量）。
    *   $L_m$ 通常通过前景`RoI`的数量进行归一化（即那些包含真实对象的`RoI`）。
    
*   **语义分割损失** ($L_s$)：通常是像素级的交叉熵损失（`Cross-Entropy Loss`）。
    $$
    L_s = -\frac{1}{N} \sum_{i=1}^{H \times W} \sum_{c=1}^{C} y_{i,c} \log(\hat{y}_{i,c})
    $$
    
    *   其中 $N$ 是图像中被标注的像素总数，$H \times W$ 是图像的像素数量，$C$ 是类别数量，$y_{i,c}$ 是像素 $i$ 属于类别 $c$ 的真实标签（one-hot编码），$\hat{y}_{i,c}$ 是模型预测的像素 $i$ 属于类别 $c$ 的概率。它通过被标注的图像像素数量进行归一化。

**2. 损失加权 (Loss Re-weighting)**：
作者发现，直接将 $L_i$ 和 $L_s$ 相加会导致问题。为了解决不同损失尺度引起的问题，引入了两个超参数 $\lambda_i$ 和 $\lambda_s$ 进行损失加权：
$$
L = \lambda_i (L_c + L_b + L_m) + \lambda_s L_s
$$

*   $\lambda_i$：实例分割损失的权重。
*   $\lambda_s$：语义分割损失的权重。

通过**调整 $\lambda_i$ 和 $\lambda_s$ 的值**，可以在两个任务之间找到一个平衡点，使得模型能够同时在两个任务上达到高性能。这使得训练一个单一模型成为可能，其性能可以与分别训练两个独立任务特定模型相媲美，但计算成本却大约减半。这表明多任务学习的增益不仅体现在计算效率上，还体现在通过任务间的知识共享可能带来的性能提升。

### 3.3. 分析

本节解释了Panoptic FPN为何能在效率和性能上都表现出色，并与当前语义分割领域流行的架构进行了对比。

作者将Panoptic FPN的效率优势归因于FPN本身的特性，而非特意为语义分割做的优化。他们对比了三种生成高分辨率输出的骨干架构：

1.  **空洞卷积 (Dilated Convolution) / Atrous Convolution** (图5b):
    *   **原理**：通过在卷积核元素之间插入空洞（零）来扩大感受野，而不增加参数或减少特征图分辨率。例如，一个`3x3`的卷积核，当空洞率为1时，其感受野相当于`5x5`。
    *   **优点**：能够有效捕获长距离上下文信息，保持高分辨率特征图。广泛应用于DeepLab系列方法。
    *   **缺点**：
        *   **计算和内存开销**：在高分辨率特征图上应用空洞卷积时，尤其是在多尺度应用时，可能会显著增加浮点运算（FLOPs）和内存占用。
        *   **骨干网络限制**：由于空洞卷积的计算特性，某些更复杂的骨干网络可能难以高效地与其结合。
        *   **网格效应 (Gridding Artifacts)**：连续使用相同空洞率的空洞卷积可能会导致特征图中的某些像素无法感知到其他像素的信息，形成类似网格的效应，可能影响分割质量。

2.  **对称编码器-解码器模型 (Symmetric Encoder-Decoder Models)** (图5c):
    *   **原理**：典型的U-Net架构。编码器通过连续的下采样（如最大池化）来提取高级语义特征，缩小空间尺寸。解码器则通过上采样来恢复空间分辨率，并利用**跳跃连接（skip connections）**将编码器对应层级的细节信息（高分辨率、低语义）引入解码器，从而生成精确的分割边界。
    *   **优点**：能够捕捉全局上下文和局部细节，在医学图像分割等领域表现出色。
    *   **缺点**：解码器部分通常比较“重”，包含与编码器对称或类似的层数，因此计算量和内存占用相对较高。

3.  **非对称、轻量级解码器 (Asymmetric, Lightweight Decoder) - FPN** (图5d):
    *   **原理**：FPN的自上而下路径扮演了轻量级解码器的角色。它不像U-Net那样严格对称，而是在每个阶段只包含一个简单的模块（例如，一个`1x1`卷积和一个上采样），并通过横向连接融合语义信息。所有的金字塔级别都共享相同的通道维度。
    *   **FPN的特点**：
        *   **高效**：相比于对称解码器，FPN的解码器部分非常轻量。
        *   **多尺度语义**：在每个金字塔级别都提供了语义丰富的特征，这对于目标检测和实例分割至关重要。
        *   **兼容性**：FPN最初设计用于目标检测，但其生成的多尺度、语义丰富特征对于语义分割同样有效。

**效率对比 (如图4所示)**：

*   图4展示了不同架构在处理一个2百万像素图像时的乘加操作（Multiply-adds）和激活内存。
*   **FPN的优势**：
    *   **FPN在1/4输出尺度下**的计算量大致与**空洞率为16x的DilatedNet**（输出分辨率为1/16）相当，但FPN能够生成**4倍更高分辨率的输出**。这意味着在相似的计算成本下，FPN提供了更精细的输出。
    *   **FPN比典型的DilatedNet（例如，空洞率为8x的）更轻量**。
    *   **FPN比对称编码器-解码模型（U-Net）的效率高约2倍**。
*   **灵活性**：Panoptic FPN避免了使用可能引入高开销的空洞卷积，这意味着它可以不受限制地使用任何标准的高性能骨干网络（如大型ResNeXt），从而提高了灵活性和部署便利性。

综上所述，Panoptic FPN的架构选择不仅与Mask R-CNN兼容，而且在计算效率和内存占用方面具有显著优势。FPN作为其骨干，提供了一种高效、灵活的方式来生成高质量的多尺度特征，这使得它能够同时满足实例和语义分割的需求，而无需引入额外的复杂性或牺牲性能。

## 4. 实验

### 实验目标：

1.  **语义FPN的竞争力**：验证只使用FPN骨干连接一个轻量级密集像素预测分支（Semantic FPN）是否能在语义分割任务上与现有方法竞争。
2.  **多任务训练的效果**：分析语义分割分支与Mask R-CNN集成的效果，以及联合训练对性能的影响。
3.  **全景分割的表现**：在COCO和Cityscapes数据集上展示全景分割结果。

### 4.1. 实验设置

*   **数据集**：
    *   **COCO [37]**：
        *   **实例分割**：使用2017年的数据分割，包含118k训练、5k验证、20k测试图像，以及80个“事物”类别。
        *   **语义分割**：使用2017年的“材质”数据，包含40k训练、5k验证、5k测试图像，以及92个“材质”类别。
        *   **全景分割**：使用2017年所有COCO图像，包含80个“事物”和53个“材质”类别（总共133个类别）的标注。
    *   **Cityscapes [14]**：
        *   一个以城市街景为中心的驾驶场景数据集。包含5k张高分辨率图像（1024x2048），其中有2975张训练、500张验证、1525张测试图像。
        *   图像被精细地标注了19个类别，其中8个类别同时具备实例级掩码。论文中提到未用到额外的20k粗略标注图像。

*   **评估指标**：
    *   **单一任务指标**：
        *   **语义分割**：**mIoU** (mean Intersection-over-Union) 是主要指标，用于衡量预测区域与真实区域的重叠程度。同时报告了**fIoU** (frequency weighted IoU) 在COCO上，以及**iIoU** (instance-level IoU) 在Cityscapes上。
        *   **实例分割**：**AP** (Average Precision) 是主要指标，它在不同类别和IoU阈值（从0.5到0.95，步长0.05）上进行平均。辅助指标包括**AP50** (IoU=0.5时的AP) 和**AP75** (IoU=0.75时的AP)。
    *   **全景分割指标**：
        *   **PQ** (Panoptic Quality) [30]：全景质量是衡量Panoptic FPN性能的默认指标。它综合考虑了识别（recognition）质量（是否正确检测和分类）和分割（segmentation）质量（掩码与真实掩码的重叠程度），并以统一的方式处理“事物”和“材质”类别。PQ的计算包含两个部分：分割质量（SQ）和识别质量（RQ），即 $PQ = \sqrt{SQ \times RQ}$。
        *   **PQ_St**：材质类别的PQ。
        *   **PQ_Th**：事物类别的PQ。
        *   **后处理**：PQ是在应用了实例和语义分支输出的后处理合并程序后进行评估的。

*   **训练细节**：
    *   **COCO训练**：遵循Mask R-CNN [23] 的默认1x训练设置，并使用了**尺度抖动 (scale jitter)**（将图像短边缩放到[640, 800]之间）。语义分割分支预测53个“材质”类别以及一个“事物”像素的特殊“其他”类别。
    *   **Cityscapes训练**：每个**mini-batch**由32个随机裁剪的512x1024图像组成（每GPU处理4个裁剪）。训练持续65k迭代，学习率在40k和55k迭代时分别从0.01降低10倍。此外，对于较大的骨干网络，还采用了**颜色增强 (color augmentation)** [40] 和**裁剪引导 (crop bootstrapping)** [5] 等数据增强技术。为了处理Cityscapes上mIoU的高方差（高达0.4），报告了5次实验的中位性能。

### 4.2. FPN在语义分割上的应用

这项实验旨在证明即使仅仅将FPN作为一个编码器-解码器架构，加上一个简单的语义分割头，它也能达到与SOTA（State-of-the-Art）相竞争的性能，而无需使用空洞卷积。

*   **Cityscapes语义分割性能 (表1a)**：
    *   **Semantic FPN**（使用ResNet-101-FPN作为骨干）在Cityscapes验证集上取得了**77.7 mIoU**。
    *   与DeepLabV3 [11] (ResNet-101-D8, 77.8 mIoU) 和PSANet101 [59] (ResNet-101-D8, 77.9 mIoU) 等方法相比，性能非常接近。甚至与最新的DeepLabV3+ [12] (X-71-D16, 79.6 mIoU) 相比，也只有1.9%的差距。
    *   值得注意的是，表中列出的所有其他顶尖方法（DeepLabV3, PSANet101, Mapillary, DeepLabV3+）都使用了**空洞卷积 (Dilation)**，而Semantic FPN没有。
    *   **效率对比**：在FLOPs（乘加操作，$\times 10^{12}$）和内存（激活量，$\times 10^9$）方面，Semantic FPN (0.5 FLOPs, 0.8 Memory) 比大多数使用空洞卷积的同级别模型（如DeepLabV3的1.9 FLOPs, 1.9 Memory）**更轻量**。这进一步验证了FPN在语义分割任务上的效率优势。
    *   结论：Semantic FPN，尽管设计简单，但能够与当前最先进的语义分割方法在性能上匹敌，并且在效率上更具优势。

*   **COCO-Stuff 2017 Challenge 结果 (表1b)**：
    *   Panoptic FPN的早期版本实际上在2017年COCO-Stuff分割挑战赛中获得了**第一名**。
    *   COCO-Stuff挑战衡量的是材质分割的性能。
    *   论文指出，该早期版本没有使用模型集成（ensembling），并且在所有报告的指标上都至少领先竞争对手2个点。
    *   备注：当时的语义分支设计与最终版本略有不同（例如，每个上采样模块有两层`3x3`卷积和`ReLU`，并在双线性上采样前进行处理；特征融合采用拼接而非求和）。这暗示了该方法的鲁棒性，即即使语义分支的具体实现有所变化，也能保持高性能。

*   **消融实验 (Ablations) - 语义分割分支设计**：
    *   为了验证语义分割分支设计的鲁棒性，作者在COCO Panoptic数据集（其材质标注与COCO-Stuff竞赛略有不同）上进行了消融研究。
    *   **通道宽度 (表1c)**：比较了语义分支中特征的通道宽度（64, 128, 256）。结果显示，**128通道**在准确性（mIoU）和效率之间找到了最佳平衡点。
    *   **特征聚合方式 (表1d)**：比较了融合来自FPN不同层级的特征图时的两种方式：**逐元素求和 (Sum)** 和 **拼接 (Concat)**。
        *   准确性：两者都取得了相似的mIoU（求和74.5，拼接74.4）。
        *   效率：**求和方式更高效**（因为不需要额外的内存来存储拼接后的维度）。
    *   结论：这些消融实验表明，语义分割分支的简单架构对于具体的实现选择具有很强的鲁棒性。

### 4.3. 多任务训练

本节探讨Panoptic FPN如何在多任务（实例分割和语义分割）设置下进行训练，以及如何平衡这两个任务以获得最佳性能。

*   **挑战**：多任务训练常常面临一个困境：如果处理不当，一个任务的优化可能会损害另一个任务的性能（“负迁移”）。这通常是因为不同任务的损失函数可能具有不同的尺度、梯度行为或优化目标。
*   **解决方案**：通过引入**损失加权因子 $\lambda_i$ 和 $\lambda_s$** 来平衡两个任务的损失。总损失函数为：
    $$L = \lambda_i (L_c + L_b + L_m) + \lambda_s L_s$$
    通过调整这两个权重，可以在训练过程中对两个任务的贡献进行精细控制。

*   **实验结果 (表2)**：
    *   **语义损失 $\lambda_s$ 对**实例分割**的影响 (表2a - COCO, 表2b - Cityscapes)**：
        *   当 $\lambda_s = 0.0$ 时，模型只进行实例分割，这是基线。
        *   在COCO上，当 $\lambda_s$ 从0增加到0.1时，**实例分割性能 (AP, PQ_Th)** 反而略有上升（AP从33.9到34.0，PQ_Th从46.6到46.8）。
        *   在Cityscapes上，引入语义损失也导致实例分割性能小幅提升。
        *   **结论**：适当引入语义分割任务，可以对实例分割产生轻微的积极影响（“正迁移”），而不是通常担心的性能下降。这可能因为语义信息提供了额外的上下文线索，有助于实例的识别和分割。
    *   **实例损失 $\lambda_i$ 对**语义分割**的影响 (表2c - COCO, 表2d - Cityscapes)**：
        *   当 $\lambda_i = 0.0$ 时，模型只进行语义分割（即前面讨论的Semantic FPN）。
        *   在COCO上，当 $\lambda_i$ 从0增加到1.0时，**语义分割性能 (mIoU, fIoU, PQ_St)** 显著提升（mIoU从40.2到41.5）。
        *   在Cityscapes上，引入实例损失也显著提升了语义分割性能（mIoU从74.5到75.3）。
        *   **结论**：实例分割任务的训练对语义分割性能产生了**更强烈的积极影响**。这可能是因为实例分割分支迫使模型学习更精细的对象边界和内部结构，这些信息对语义分割同样有用，尤其是在区分邻近物体或细粒度区域时。

*   **总结**：这些实验结果挑战了传统多任务学习中“任务可能相互干扰”的观点，展示了在Panoptic FPN的框架下，通过精心调整损失权重，两个任务可以有效地相互促进。这为实现真正统一的全景分割模型奠定了基础。

### 4.4. 全景FPN

本节是Panoptic FPN的核心结果，评估其在联合全景分割任务中的表现。为了公平比较，作者为每个实验设置选择了最优的 $\lambda_s$ 和 $\lambda_i$ 值（从集合 $\{0.5, 0.75, 1.0\}$ 中选择）。

*   **主要结果：效率与性能权衡**
    *   **Panoptic FPN vs. 两个独立网络：计算效率 (表3a)**：
        *   **R50-FPNx2**：表示两个独立的模型，每个模型都有一个ResNet-50-FPN骨干，一个用于实例分割，一个用于语义分割。
        *   **R50-FPN**：表示单一Panoptic FPN模型，只有一个ResNet-50-FPN骨干，同时处理两个任务。
        *   **结果**：Panoptic FPN在COCO和Cityscapes上取得了与R50-FPNx2**相当的性能**（PQ值非常接近），但**计算量大约减半**。这是因为骨干网络通常是模型中最消耗计算资源的部分，单一骨干大大减少了开销。
        *   **结论**：在保持性能的同时，Panoptic FPN显著提高了计算效率。
    *   **Panoptic FPN vs. 两个独立网络：固定计算预算下的性能 (表3b)**：
        *   **R50-FPNx2**：总计算量约为两个ResNet-50骨干的计算量。
        *   **R101-FPN**：单一Panoptic FPN模型，使用更强大的ResNet-101-FPN骨干。ResNet-101的计算量大致与两个ResNet-50的计算量相当。
        *   **结果**：R101-FPN在COCO和Cityscapes上，在**大致相同的计算预算**下，**显著优于**R50-FPNx2。例如，在COCO上，PQ从39.2提高到40.3（+1.1点）。
        *   **结论**：在相同的计算资源投入下，联合网络（Panoptic FPN）能够取得更好的性能。这进一步证明了联合训练的优势和特征共享的有效性。

*   **消融实验 (Ablations) - 优化和架构选择**
    *   **训练策略 (表3c)**：
        *   比较了两种多任务训练策略：
            *   `alternate`（交替训练）：每个迭代只优化一个任务的损失。这意味着如果需要达到相同的总迭代次数，训练时间可能需要翻倍。
            *   `combine`（联合训练）：每个迭代同时优化两个任务的损失。
        *   **结果**：`combine`策略在COCO和Cityscapes上都显著优于`alternate`策略，尤其在COCO上PQ值提高了1.5点。
        *   **结论**：同时优化两个任务，能够更好地促进任务间的知识共享和协同学习，从而取得更好的性能。这与先前关于多任务学习最佳实践的发现相符。
    *   **FPN通道分组 (表3d)**：
        *   测试了一种变体：将FPN的256个通道分成两组，每组128个通道，并将实例分割分支和语义分割分支分别连接到这两组专用的特征上。
        *   **结果**：性能提升不明显，甚至是混合的（COCO上PQ略降0.2，Cityscapes上略降0.2）。
        *   **结论**：简单的通道分组并未带来显著收益，这表明任务间的特征复用可能比通道隔离更有效。但也暗示了未来可能存在更复杂、更有效的多任务特征共享策略。

*   **与其他SOTA方法的比较 (表4)**：
    *   **COCO测试开发集 (表4a)**：Panoptic FPN（使用ResNet-101骨干）在COCO全景分割排行榜上**大幅超越**所有**单一模型**（非集成模型）的参赛作品。与排名第二的MMAP-seg相比，PQ值从32.1提升到40.9，**提高了8.8点**，PQ_Th和PQ_St也都有大幅提升。这确立了全景分割任务的新的强劲基线。
    *   **Cityscapes验证集 (表4b)**：Panoptic FPN在Cityscapes上也表现出色，比近期提出的DIN [1, 34]（一种基于像素分组的方法）高出4.3个PQ点。值得一提的是，Panoptic FPN在训练中**没有使用额外的粗粒度数据或其他复杂的技巧**，显示了其自身的强大和简洁。

## 5. 结论

论文提出了Panoptic FPN，一个概念简单但高效的全景分割基线模型。该方法从Mask R-CNN与FPN这一强大的实例分割框架出发，仅通过添加一个轻量级的语义分割分支，就实现了在实例分割和语义分割这两个任务上的联合高精度表现。其核心创新点在于：

*   **统一架构**：将“事物”实例分割和“材质”语义分割整合在一个单一的共享FPN骨干网络中，最大限度地实现了计算和特征的复用。
*   **FPN的高效利用**：利用FPN天然生成多尺度、语义丰富的特征的能力，同时满足了两个任务对特征的要求。
*   **轻量级语义解码器**：设计了一个简洁高效的语义分割分支，通过简单的上采样和特征融合将多层FPN特征整合成最终的语义预测。
*   **损失加权策略**：通过对两个任务的损失进行动态加权，有效地平衡了多任务学习的优化过程，并证明了任务间甚至可以相互促进。
*   **强大的基线**：实验证明Panoptic FPN不仅在效率上超越了分离的网络，而且在相同计算预算下能达到更高的性能，并成为了COCO全景分割挑战赛中新的单一模型基线。

作者希望Panoptic FPN能作为一个强大的起点，促进未来全景分割领域的研究和发展。其简洁性和高性能使其成为进一步探索全景理解的理想基础。
