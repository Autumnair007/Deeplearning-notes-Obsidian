---
type: paper-note
tags:
  - cv
  - dense-prediction
  - monocular-depth-estimation
  - semantic-segmentation
  - transformer
  - vit
  - dpt
  - encoder-decoder
status: done
model: Dense Prediction Transformer
year: 2021
---
论文原文：[[2103.13413\] Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)

本地pdf：[DPT](../../../../99_Assets%20(资源文件)/papers/Vision%20Transformers%20for%20Dense%20Prediction.pdf)
***
## 摘要

这篇论文介绍了稠密视觉Transformer（Dense Vision Transformer, DPT），这是一种利用ViT取代传统卷积网络作为稠密预测任务骨干网络的新架构。该架构将Vision Transformer不同阶段的tokens重组成多分辨率的图像状表示，并逐步结合卷积解码器将其融合为全分辨率的预测。Transformer骨干网络在每个阶段都以恒定且相对较高的分辨率处理表示，并且具有全局感受野。这些特性使得DPT在提供更细粒度且更全局连贯的预测方面优于全卷积网络。实验证明，该架构在稠密预测任务上取得了显著改进，尤其是在有大量训练数据的情况下。在单目深度估计方面，与最先进的全卷积网络相比，相对性能提升高达28%。在语义分割方面，DPT在ADE20K数据集上取得了新的SOTA，mIoU达到49.02%。论文进一步表明，该架构可以在NYUv2、KITTI和Pascal Context等较小数据集上进行微调，并同样达到了SOTA。模型已开源。

## 1. 引言

稠密预测任务（如语义分割、深度估计、关键点检测等）的现有架构几乎都基于卷积网络。传统的稠密预测架构设计通常遵循编码器-解码器模式。编码器通常以图像分类网络（骨干网络）为基础，并在大型语料库（如ImageNet）上进行预训练。解码器则负责聚合编码器的特征，并将其转换为最终的稠密预测结果。虽然架构研究常侧重于解码器及其聚合策略，但骨干网络的选择对模型能力至关重要，因为编码器中丢失的任何信息都无法在解码器中恢复。

卷积骨干网络通过逐级下采样来提取多尺度特征。下采样有助于逐步扩大感受野，将低级特征组合成抽象的高级特征，并同时确保内存和计算需求可控。然而，下采样也有明显的缺点，在稠密预测任务中尤为突出：在模型的深层阶段，特征分辨率和粒度会丢失，这使得在解码器中恢复这些信息变得困难。虽然特征分辨率和粒度对于图像分类等任务可能不重要，但对于稠密预测而言却至关重要，因为架构理想情况下应能以接近输入图像的分辨率解析特征。

为了缓解特征粒度损失，人们提出了多种技术，包括：
1. **更高输入分辨率训练**（如果计算预算允许）。
2. **空洞卷积**：在不进行下采样的情况下快速增加感受野。
3. **适当放置跳跃连接**：将编码器多个阶段的特征传递给解码器。
4. **多分辨率并行连接**：在整个网络中并行处理多分辨率表示。

尽管这些技术显著提升了预测质量，但网络仍受到其基本构建模块——卷积的限制。卷积与非线性操作构成了图像分析网络的基本计算单元。卷积本质上是线性算子，感受野有限。有限的感受野和单个卷积有限的表达能力，需要将它们顺序堆叠成非常深的架构，才能获得足够广阔的上下文和足够高的表示能力。然而，这需要生成大量的中间表示，耗费大量内存。为了将内存消耗维持在现有计算机架构可承受的水平，必须对中间表示进行下采样。

本文引入了**稠密预测Transformer (DPT)**，这是一种基于编码器-解码器设计的稠密预测架构，利用Transformer作为编码器的基本计算构建模块。具体来说，DPT使用最新的Vision Transformer (ViT) 作为骨干网络。该方法将ViT提供的“词袋”表示重组成不同分辨率的图像状特征表示，并逐步结合卷积解码器将这些特征表示融合为最终的稠密预测。与全卷积网络不同，Vision Transformer骨干网络在计算初始图像嵌入后，放弃了显式的下采样操作，并在所有处理阶段保持恒定维度的表示。此外，它在每个阶段都具有全局感受野。论文表明，这些特性对于稠密预测任务特别有利，因为它们自然地导致了细粒度且全局连贯的预测。

作者在单目深度估计和语义分割任务上进行了实验。对于通用单目深度估计任务（可获得大量训练数据），DPT与该任务中性能最佳的全卷积网络相比，性能提升超过28%。该架构也可以在较小的单目深度预测数据集（如NYUv2和KITTI）上进行微调，同样取得了新的SOTA。论文通过语义分割实验进一步证明了DPT的强大性能。对于该任务，DPT在极具挑战性的ADE20K和Pascal Context数据集上取得了新的SOTA。定性结果表明，与卷积网络相比，性能的提升可归因于更细粒度且全局连贯的预测。

## 2. 相关工作

### 2.1. 全卷积网络（FCN）

全卷积网络是稠密预测的典型架构。多年来，人们提出了许多这种基本模式的变体，但所有现有架构都采用卷积和下采样作为其基本元素，以学习多尺度表示，从而利用适当的大上下文。一些工作提出了逐步上采样在不同阶段池化后的表示，而另一些则使用空洞卷积或多尺度并行特征聚合来恢复细粒度预测，同时确保足够大的上下文。最近的架构在整个网络中保持高分辨率表示以及多个低分辨率表示。

### 2.2. 基于注意力模型和 Transformer

基于注意力的模型，特别是Transformer，近年来已成为自然语言处理（NLP）领域构建强大模型的首选架构。Transformer是基于自注意力机制的“集合到集合（set-to-set）”模型。Transformer模型在实例化为高容量架构并在非常大的数据集上进行训练时表现出色。有一些工作尝试将注意力机制应用于图像分析。特别是，最近有研究表明，直接将NLP中成功的基于token的Transformer架构应用于图像分类也能获得具有竞争力的性能。这项工作的一个关键发现是，像NLP中的Transformer模型一样，视觉Transformer需要与足够多的训练数据配对才能充分发挥其潜力。

## 3. 架构

本节详细介绍稠密视觉Transformer (DPT)。DPT沿用了过去在稠密预测中成功的编码器-解码器整体结构。DPT利用Vision Transformer (ViT) 作为骨干网络，展示了如何有效地将编码器生成的表示转换为稠密预测，并阐述了这种策略成功的直观原因。完整的架构概览如图1（左）所示。

![](../../../../99_Assets%20(资源文件)/images/31645224d0f32b5312872b68df133e59%201.png)

**图1. 左图：** 架构概览。输入图像被转换为标记（橙色），其方法有两种：一是通过提取不重叠的图像块，然后对其展平的表示进行线性投影（DPT-Base和DPT-Large）；二是通过应用一个ResNet-50特征提取器（DPT-Hybrid）。图像嵌入被一个位置嵌入和一个与图像块无关的读取标记（红色）所增强。这些标记通过多个Transformer阶段。我们将不同阶段的标记重新组合成多种分辨率的类图像表示。融合模块（紫色）逐步融合和上采样这些表示，以生成一个细粒度的预测。

**中图：** Reassemble操作的概览。标记被组装成特征图，其空间分辨率是输入图像的$\frac{1}{s}$。

**右图：** 融合块使用残差卷积单元[23]组合特征并上采样特征图。

### 3.1. Transformer 编码器

从高层次来看，Vision Transformer (ViT) [11] 对图像的“词袋（bag-of-words）”表示进行操作。图像块（image patches）被单独嵌入到特征空间中，或者替代地，从图像中提取的深层特征扮演“词语”的角色。在本文的其余部分，嵌入的“词语”被称为**tokens**。Transformer使用多头自注意力（Multi-Headed Self-Attention, MHSA）的连续块来转换tokens集合，MHSA将tokens相互关联起来以转换表示。

对于DPT的应用而言，关键在于Transformer在所有计算过程中都保持token的数量不变。由于tokens与图像块之间存在一对一的对应关系，这意味着ViT编码器在所有Transformer阶段都保持了初始嵌入的空间分辨率。此外，MHSA本质上是一种全局操作，因为每个token都可以关注（attend to）并因此影响其他所有token。因此，Transformer在初始嵌入后的每个阶段都具有全局感受野。这与卷积网络形成鲜明对比，卷积网络随着特征通过连续的卷积和下采样层而逐渐增加其感受野。

更具体地说，ViT通过处理图像中大小为 $p^2$ 像素的非重叠正方形块来提取图像块嵌入。这些图像块被展平为向量，并使用线性投影单独嵌入。ViT的另一种更具样本效率的变体是通过对图像应用ResNet50 [16] 来提取嵌入，并使用结果特征图的像素特征作为tokens。由于Transformer是集合到集合的函数，它们本身不保留单个token的空间位置信息。因此，图像嵌入与一个可学习的位置嵌入进行拼接，以将此信息添加到表示中。遵循NLP中的工作，ViT还额外添加了一个特殊的token，它不基于输入图像，而是作为最终的全局图像表示，用于分类。我们称这个特殊token为**readout token**。对大小为 $H \times W$ 像素的图像应用嵌入过程的结果是一组$N_p+1$ 个tokens $t^0 = \{t_0^0, ..., t_{N_p}^0\}$，其中 $t_n^0 \in \mathbb{R}^D$， $N_p = \frac{HW}{p^2}$，$t_0^0$ 指的是readout token， $D$ 是每个token的特征维度。

输入tokens通过 $L$ 个Transformer层转换为新的表示 $t^l$，其中 $l$ 指代第 $l$ 个Transformer层的输出。Dosovitskiy等 [11] 定义了这种基本蓝图的几种变体。DPT使用了三种变体：
* **ViT-Base**：使用基于图像块的嵌入过程，并具有12个Transformer层。
* **ViT-Large**：使用相同的嵌入过程，具有24个Transformer层和更宽的特征尺寸 $D$。
* **ViT-Hybrid**：采用ResNet50计算图像嵌入，后接12个Transformer层。

所有实验中图像块大小 $p=16$。

ViT-Base和ViT-Large的嵌入过程将展平的图像块投影到维度 $D=768$ 和 $D=1024$。由于这两个特征维度都大于输入图像块中的像素数量，这意味着嵌入过程可以学习保留信息，如果这对于任务有利。原则上，可以以像素级精度解析来自输入图像块的特征。类似地，ViT-Hybrid架构以输入分辨率的 $1/16$ 提取特征，这比卷积骨干网络常用的最低分辨率特征高两倍。

### 3.2. 卷积解码器

DPT的解码器将tokens集合组装成不同分辨率的图像状特征表示。这些特征表示被逐步融合，形成最终的稠密预测。作者提出了一个简单的三阶段 **Reassemble** 操作来从Transformer编码器任意层的输出tokens中恢复图像状表示：

$$
\mathrm{Reassemble}_{\hat{D}}^s(t) = (\mathrm{Resample}_s \circ \mathrm{Concatenate} \circ \mathrm{Read})(t)
$$

其中 $s$ 表示恢复表示相对于输入图像的输出尺寸比例，$\hat{D}$ 表示输出特征维度。

1. **Read 操作**：
首先将 $N_p+1$ 个token映射到 $N_p$ 个token，这些token适合进行空间拼接以形成图像状表示：

$$
\mathrm{Read}: \mathbb{R}^{N_p+1 \times D} \to \mathbb{R}^{N_p \times D} \tag{1}
$$

该操作主要负责恰当地处理readout token。由于readout token对稠密预测任务没有明确的用途，但仍可能有助于捕获和分发全局信息，作者评估了该映射的三种不同变体：

- **Read_ignore(t)**：简单地忽略readout token。
$$
\mathrm{Read}_{\mathrm{ignore}}(t) = \{t_1, ..., t_{N_p}\} \tag{2}
$$

- **Read_add(t)**：通过将readout token的表示添加到所有其他token中，将信息从readout token传递给所有其他token。
$$
\mathrm{Read}_{\mathrm{add}}(t) = \{t_1+t_0, ..., t_{N_p}+t_0\} \tag{3}
$$

- **Read_proj(t)**：通过将readout token与所有其他token拼接，然后使用线性层（后接GELU非线性激活）将表示投影回原始特征维度D，从而将信息传递给其他token。
$$
\mathrm{Read}_{\mathrm{proj}}(t) = \{\mathrm{mlp}(\mathrm{cat}(t_1,t_0)),..., \mathrm{mlp}(\mathrm{cat}(t_{N_p},t_0))\} \tag{4}
$$

2. **Concatenate 操作**：
在Read块之后，生成的 $N_p$ 个token可以通过根据初始图像块在图像中的位置来放置每个token，从而重塑为图像状表示。形式上，应用一个空间拼接操作，得到一个尺寸为 $\frac{H}{p} \times \frac{W}{p}$ 且具有 $D$ 个通道的特征图：

$$
\mathrm{Concatenate}: \mathbb{R}^{N_p \times D} \to \mathbb{R}^{\frac{H}{p} \times \frac{W}{p} \times D} \tag{5}
$$

3. **Resample 操作**：
最后，将此表示传递给一个空间重采样层，该层将表示缩放到尺寸为 $\frac{H}{s} \times \frac{W}{s}$，每个像素具有 $\hat{D}$ 个特征：

$$
\mathrm{Resample}_s: \mathbb{R}^{\frac{H}{p} \times \frac{W}{p} \times D} \to \mathbb{R}^{\frac{H}{s} \times \frac{W}{s} \times \hat{D}} \tag{6}
$$

DPT通过以下步骤实现此操作：
- 首先使用 $1 \times 1$ 卷积将输入表示投影到 $\hat{D}$。
- 接着，当 $s \geq p$ 时，使用步长为1的 $3 \times 3$ 卷积；当 $s < p$ 时，使用步长为1的 $3 \times 3$ 转置卷积，分别实现空间下采样和上采样操作。

无论具体的Transformer骨干网络如何，DPT从四个不同阶段和四种不同分辨率的特征进行重新组装。来自Transformer较深层的特征以较低分辨率组装，而来自较早层的特征以较高分辨率组装。使用ViT-Large时，DPT从层 $l=\{5,12,18,24\}$ 重新组装token；使用ViT-Base时，使用层 $l=\{3,6,9,12\}$。使用ViT-Hybrid时，使用来自嵌入网络的第一个和第二个ResNet块的特征，以及层 $l=\{9,12\}$。默认架构使用投影作为readout操作，并生成 $\hat{D}=256$ 维的特征图。这些架构分别被称为DPT-Base、DPT-Large和DPT-Hybrid。

最后，DPT使用基于RefineNet的特征融合块 [23, 45] (如图1(右)) 组合来自连续阶段的提取特征图，并在每个融合阶段逐步将表示上采样两倍。最终表示的尺寸是输入图像分辨率的一半。DPT连接一个任务特定的输出头来生成最终预测。完整的架构示意图如图1所示。

### 3.3. 处理可变图像尺寸

与全卷积网络类似，DPT可以处理不同尺寸的图像。只要图像尺寸可以被 $p$ 整除，就可以应用嵌入过程，并会生成不同数量的图像tokens $N_p$。作为一种集合到集合的架构，Transformer编码器可以轻松处理不同数量的tokens。然而，位置嵌入对图像尺寸有依赖性，因为它编码了图像块在输入图像中的位置。DPT遵循 [11] 中提出的方法，对位置嵌入进行线性插值，以适应适当的尺寸。请注意，这可以为每张图像实时完成。在嵌入过程和Transformer阶段之后，reassemble和fusion模块可以轻松处理不同数量的tokens，前提是输入图像与卷积解码器（32 像素）的步长对齐。

## 4. 实验

DPT应用于两个稠密预测任务：单目深度估计和语义分割。对于这两个任务，DPT与容量相似的卷积网络相比，都能显著提高准确性，特别是在有大量训练数据集可用的情况下。

### 4.1. 单目深度估计

单目深度估计通常被视为一个稠密回归问题。已证明，只要对不同深度表示的统一方式（例如，尺度模糊性）以及训练损失中如何恰当处理这些模糊性进行适当处理，就可以从现有数据源构建大规模元数据集 [30]。由于Transformer已知只有在有大量训练数据可用时才能充分发挥其潜力，因此单目深度估计是测试DPT能力的理想任务。

- **实验协议**：DPT严格遵循[30]的协议。使用尺度和移位不变的截断损失（trimmed loss）来学习单目深度预测网络，该损失作用于逆深度表示，并结合[22]中提出的梯度匹配损失。构建了一个元数据集，包括[30]中使用的原始数据集（在该工作中称为MIX 5），并使用五个额外数据集([18, 43, 44, 46, 47])对其进行了扩展，这个元数据集称为**MIX 6**。MIX 6包含约 140 万张图像，是目前已知的用于单目深度估计的最大训练集。

- **训练细节**：使用多目标优化 [32] 和 Adam [19]，骨干网络的学习率为 $1e^{-5}$，解码器的学习率为 $1e^{-4}$。编码器使用ImageNet预训练权重初始化，解码器随机初始化。输出头由3个卷积层组成。输出头逐级将特征维度减半，并在第一个卷积层后将预测上采样到输入分辨率。解码器中禁用批归一化（Batch Normalization），因为它对回归任务有负面影响。将图像尺寸调整为长边384像素，并在大小为384的随机方形裁剪上进行训练。训练60个epoch，每个epoch包含72,000步，批大小为16。为了处理批大小不可被数据集数量整除的情况，通过先随机抽取数据集，然后从相应的数据集中采样来构建迷你批次。进行随机水平翻转进行数据增强。与[30]类似，先在一个精心策划的数据子集[45, 46, 47]上预训练60个epoch，然后才在完整数据集上进行训练。

  ![](../../../../99_Assets%20(资源文件)/images/003b3a575863f588f120a5d373768f4f.png)

- **零样本跨数据集迁移**：表1展示了零样本迁移到训练期间未见的不同数据集的结果。对于所有指标，越低越好。DPT的两个变体都显著优于SOTA。与最佳已发表架构MiDaS相比，DPT-Hybrid的平均相对改进超过23%，DPT-Large超过28%。DPT-Hybrid在网络容量相当的情况下实现此效果（表9），而DPT-Large比MiDaS大3倍。两个架构的延迟与MiDaS相似（表9）。
为了确保观察到的改进不仅仅是由于训练集增大，作者在更大的元数据集MIX 6上重新训练了MiDaS使用的全卷积网络。尽管全卷积网络确实从更大的训练集中受益，但观察到DPT的两个变体仍然显著优于该网络。这表明DPT能更好地从更大的训练集尺寸中受益，这一观察结果与Transformerbased架构在其他领域的现有发现一致。
定性结果如图2所示，DPT可以更好地重构精细细节，同时改善卷积架构难以处理区域（例如，大片同质区域或图像中相对深度排列）的全局连贯性。

- **在小数据集上微调**：在KITTI [15] 和 NYUv2 [35] 数据集上微调DPT-Hybrid，以进一步比较DPT与现有工作的表示能力。由于网络是使用仿射不变损失进行训练的，其预测是任意缩放和偏移的，并且可能具有较大幅度。直接微调会很困难，因为预测与真实值之间的全局幅度不匹配将主导损失。因此，首先使用[30]中描述的鲁棒对齐程序，将初始网络的预测与每个训练样本进行对齐。然后，将训练集上的平均尺度和偏移应用于预测，然后将结果传递给损失。使用Eigen等人 [12] 提出的损失进行微调。对于KITTI，由于该数据集只提供稀疏的真值，因此禁用梯度匹配损失。
表2和表3总结了结果。DPT架构在两个数据集的所有指标上都达到或改进了SOTA性能。这表明DPT也可以有效地应用于较小的数据集。

### 4.2. 语义分割

选择语义分割作为第二个任务，因为它代表了离散标注任务，并且是稠密预测架构极具竞争力的试验场。DPT采用与之前实验相同的骨干网络和解码器结构。使用一个输出头，其预测分辨率为½，并通过双线性插值将logits上采样到全分辨率。编码器再次从ImageNet预训练权重初始化，解码器随机初始化。

- **实验协议**：严格遵循Zhang等人[51]建立的协议。使用交叉熵损失，并在倒数第二个融合层的输出上添加了一个辅助输出头和辅助损失。辅助损失的权重设置为0.2。两个头在最终分类层之前都使用了Dropout，比率为0.1。使用带有动量0.9的SGD和多项式学习率调度器，衰减因子为0.9。在融合层中使用批归一化，批大小为48。图像被调整为520像素边长。使用随机水平翻转和范围在$(0.5, 2.0)$ 的随机缩放进行数据增强。在大小为480的方形随机裁剪上进行训练。学习率设置为0.002。在测试时使用多尺度推理，并报告像素准确率（pixAcc）和平均交并比（mIoU）。

- **ADE20K**：在ADE20K语义分割数据集[54]上训练DPT 240个epoch。表4总结了在验证集上的结果。DPT-Hybrid超越了所有现有全卷积架构。DPT-Large性能略差，这可能是因为数据集比之前的实验显著小。图3提供了视觉比较。观察到DPT倾向于生成更清晰、更细粒度的对象边界描绘，并且预测在某些情况下也更不杂乱。

- **在小数据集上微调**：在Pascal Context数据集[26]上微调DPT-Hybrid 50个epoch。所有其他超参数保持不变。表5显示了该实验在验证集上的结果。再次看到DPT即使在较小的数据集上也能提供强大的性能。

### 4.3. 消融实验

通过消融研究，探讨了DPT中的多个方面和技术选择。选择单目深度估计作为消融任务，并遵循与之前相同的协议和超参数设置。使用一个缩减的元数据集，由三个数据集[45, 46, 47]组成，包含约41,000张图像。选择这些数据集是因为它们提供了高质量的真实值。将每个数据集分成训练集和一个总共约1,000张图像的小验证集。在验证集上报告了预测与真实值进行仿射对齐后的相对绝对偏差指标[30]。除非另有说明，否则使用ViT-Base作为骨干网络架构。

- **跳跃连接 (Skip connections)**：
卷积架构为从编码器到解码器传递特征提供了天然的兴趣点，即在下采样之前或之后。由于Transformer骨干网络保持恒定的特征分辨率，因此不清楚应该在骨干网络的哪个点抽样特征。表6（顶部）评估了几种可能的选择。观察到从包含低级特征的层以及包含更高级特征的深层抽样特征是有益的。采用最佳设置进行所有后续实验。

在表6（底部）中，对混合架构进行了类似的实验，其中R0和R1指使用来自ResNet50嵌入网络的第一和第二下采样阶段的特征。观察到使用来自嵌入网络的低级特征比仅使用来自Transformer阶段的特征能带来更好的性能。对于所有涉及混合架构的后续实验，都使用此设置。

| Layer $l$                                                    | HRWSI  | BlendedMVS | ReDWeb | Mean   |
| :----------------------------------------------------------- | :----- | :--------- | :----- | :----- |
| **Base**                                                     |        |            |        |        |
| {3, 6, 9, 12}                                                | 0.0793 | 0.0780     | 0.0892 | 0.0822 |
| {6, 8, 10, 12}                                               | 0.0801 | 0.0789     | 0.0904 | 0.0831 |
| {9, 10, 11, 12}                                              | 0.0805 | 0.0766     | 0.0912 | 0.0828 |
| **Hybrid**                                                   |        |            |        |        |
| {3, 6, 9, 12}                                                | 0.0747 | 0.0748     | 0.0865 | 0.0787 |
| {R0, R1, 9, 12}                                              | 0.0742 | 0.0751     | 0.0857 | 0.0733 |
| **表6**：跳跃连接到不同编码器层的性能。浅层和深层跳跃连接的组合取得了最佳结果。 |        |            |        |        |

- **Readout token**：
表7研究了实现Reassemble块第一阶段以处理readout token的各种选择。虽然忽略token能带来良好的性能，但投影平均而言提供了略好的性能。另一方面，添加token比简单地忽略它会导致更差的性能。所有后续实验都使用投影。

|                                                              | HRWSI  | BlendedMVS | ReDWeb | Mean   |
| :----------------------------------------------------------- | :----- | :--------- | :----- | :----- |
| Ignore                                                       | 0.0793 | 0.0780     | 0.0892 | 0.0822 |
| Add                                                          | 0.0799 | 0.0789     | 0.0904 | 0.0831 |
| Project                                                      | 0.0797 | 0.0764     | 0.0895 | 0.0819 |
| **表7**：处理readout token的方法性能。使用投影层将readout token融合到单个输入token中可获得最佳性能。 |        |            |        |        |

- **骨干网络 (Backbones)**：
表8显示了不同骨干网络的性能。ViT-Large的性能优于所有其他骨干网络，但其尺寸也几乎是ViT-Base和ViT-Hybrid的三倍。ViT-Hybrid在参数数量相似的情况下优于ViT-Base，并且与大型骨干网络具有可比的性能。因此，它在准确性和容量之间提供了良好的折衷。

|                                                              | HRWSI  | BlendedMVS | ReDWeb | Mean   |
| :----------------------------------------------------------- | :----- | :--------- | :----- | :----- |
| ResNet50                                                     | 0.0890 | 0.0887     | 0.1029 | 0.0935 |
| ResNext101-WSL                                               | 0.0780 | 0.0751     | 0.0886 | 0.0806 |
| DeIT-Base                                                    | 0.0798 | 0.0804     | 0.0925 | 0.0842 |
| DeIT-Base-Dist                                               | 0.0758 | 0.0758     | 0.0871 | 0.0796 |
| ViT-Base                                                     | 0.0797 | 0.0764     | 0.0895 | 0.0819 |
| ViT-Large                                                    | 0.0740 | 0.0747     | 0.0846 | 0.0778 |
| ViT-Hybrid                                                   | 0.0738 | 0.0746     | 0.0864 | 0.0783 |
| **表8**：骨干网络的消融实验。混合和大型骨干网络始终优于卷积基线。基础架构可以通过更好的预训练（DeIT-Base-Dist）超越卷积基线。 |        |            |        |        |

- **推理分辨率 (Inference resolution)**：
虽然全卷积架构在其最深层可能具有大的有效感受野，但靠近输入层的感受野是局部的且较小。因此，当推理分辨率与训练分辨率显著不同时，性能会严重下降。另一方面，Transformer编码器在每一层都具有全局感受野。推测这使得DPT对推理分辨率的依赖性较小。为了验证这一假设，DPT绘制了不同架构在高于训练分辨率（384x384像素）进行推理时性能下降的情况图4。观察到DPT变体的性能随着推理分辨率的增加确实更平稳地下降。

![](../../../../99_Assets%20(资源文件)/images/097084d31351708a40efb8b5402344c6.png)

- **推理速度 (Inference speed)**：
表9显示了不同网络架构的推理时间。计时是在Intel Xeon Platinum 8280 CPU @ 2.70GHz with 8 physical cores和Nvidia RTX 2080 GPU上进行的。使用宽度为384像素的正方形图像，并报告400次运行的平均值。DPT-Hybrid和DPT-Large的延迟与MiDaS使用的全卷积架构相当。有趣的是，虽然DPT-Large在参数数量方面比其他架构大得多，但它具有竞争力的延迟，因为它通过其宽而相对较浅的结构展现出高度并行性。

|                                                        | MiDaS | DPT-Base | DPT-Hybrid | DPT-Large |
| :----------------------------------------------------- | :---- | :------- | :--------- | :-------- |
| Parameters [million]                                   | 105   | 112      | 123        | 343       |
| Time [ms]                                              | 32    | 17       | 38         | 35        |
| **表9**：模型统计数据。DPT的推理速度与最先进模型相当。 |       |          |            |           |

## 5. 结论

论文引入了稠密预测Transformer (DPT)，这是一种有效利用Vision Transformer进行稠密预测任务的神经网络架构。在单目深度估计和语义分割上的实验表明，与全卷积架构相比，所提出的架构能够产生更细粒度、全局更连贯的预测。与之前关于Transformer的工作类似，DPT在大型数据集上训练时能充分发挥其潜力。

## 附录

### A. 架构细节

![](../../../../99_Assets%20(资源文件)/images/21f8bdb3208e3929296b4ccdec90360e%201.png)

- **混合编码器 (Hybrid encoder)**：混合编码器基于具有组归一化和权重标准化 [57] 的预激活ResNet50。它在初始stem后定义了四个阶段，每个阶段在应用多个ResNet块之前对表示进行下采样。RN指的是第N个阶段的输出。DPT-Hybrid因此在第一（R0）和第二阶段（R1）后连接了跳跃连接。

- **残差卷积单元 (Residual convolutional units)**：图A1(a)展示了解码器中使用的残差卷积单元 [23] 的示意图。语义分割使用批归一化，但单目深度估计禁用批归一化。使用批归一化时，禁用前一个卷积层中的偏差。

- **单目深度估计头 (Monocular depth estimation head)**：单目深度估计的输出头如图A1(b)所示。初始卷积将特征维度减半，而第二个卷积的输出维度为32。最终的线性层将此表示投影为一个非负标量，表示每个像素的逆深度预测。使用双线性插值对表示进行上采样。

- **语义分割头 (Semantic segmentation head)**：语义分割的输出头如图A1(c)所示。第一个卷积块保留了特征维度，而最终的线性层将表示投影到输出类别数。使用丢弃层 (Dropout)，比率为0.1。最终的上采样操作使用双线性插值。因此，预测表示每个像素的类别logit。

### B. 额外结果

- **单目深度估计**：注意到零样本迁移在具有密集、高分辨率评估的数据集上获得了最大的性能提升 [15, 55, 59]。这可能得益于更细粒度的预测。对这些数据集的样本结果（参见图A3）进行目视检查证实了这一直觉。与全卷积基线相比，DPT预测中观察到更多细节，并且全局深度排列也更好。请注意，DPT和MiDaS的结果是在相同的输入分辨率（384像素）下计算的。

- **语义分割**：图A2显示了ADE20K验证集的每类别IoU分数。尽管观察到与基线[51]相比，每类别IoU普遍呈改进趋势，但并未在所有类别中观察到强烈的模式。

- **注意力图 (Attention maps)**：图A4和图A5展示了来自不同编码器层的注意力图。两种情况下，都显示了单目深度估计模型的结果。可视化了两个参考token（分别为左上角和右下角）在编码器不同层中对图像中所有其他token的注意力。显示了所有12个注意力头的平均注意力。

观察到注意力在浅层（最左侧列）倾向于在空间上更局限于参考token附近，而深层（最右侧列）则经常关注整个图像。
