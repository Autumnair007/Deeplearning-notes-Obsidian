---
type: "concept-note"
tags: ["cv", "semantic-segmentation", "instance-segmentation", "imbalanced-data", "loss-function"]
status: "done"
---
学习资料：[【语义分割】类别不平衡损失函数合集_ohemcrossentropyloss-CSDN博客](https://blog.csdn.net/qq_40035462/article/details/123448323#:~:text=本文深入探讨了在,ss等损失函数。)

[Focal Loss损失函数（超级详细的解读）-CSDN博客](https://blog.csdn.net/BIgHAo1/article/details/121783011)

------
### 什么是类别不平衡问题？

类别不平衡（Class Imbalance）问题是指在分类学习任务中，不同类别的训练样本数量差异巨大的情况。例如，在一个二分类问题中，一个类别的样本数量远多于另一个类别。拥有较多样本的类别被称为“多数类”（Majority Class），而拥有较少样本的类别则被称为“少数类”（Minority Class）。这种情况在现实世界的很多场景中都非常常见，比如：
*   **金融欺诈检测**：绝大多数交易是合法的，只有极少数是欺诈交易。
*   **医疗诊断**：大部分前来检查的人是健康的，只有少数人被诊断出患有某种罕见的疾病。
*   **网络入侵检测**：网络流量中，绝大部分是正常访问，只有极少数是攻击行为。
*   **工业生产质检**：生产线上绝大多数产品是合格品，只有极少数是次品。
### 为什么类别不平衡是一个严重的问题？
传统的机器学习模型在设计时通常有一个隐性假设，即不同类别的样本数量是均衡的。它们的目标是最大化整体的准确率（Accuracy），即正确分类的样本数占总样本数的比例。当类别不平衡发生时，这种优化目标会导致模型产生严重的偏见。
模型为了最大化整体准确率，会倾向于将所有样本都预测为多数类。举个例子，在一个信用卡欺诈检测数据集中，99%的交易是正常的，1%是欺诈。如果一个模型简单地将所有交易都预测为“正常”，那么它的准确率将高达99%。从准确率这个指标来看，这是一个非常好的模型，但实际上它完全没有能力识别出任何一笔欺诈交易，因此在应用中是毫无价值的。这就是类别不平衡问题的核心：**它会使得模型评估指标（如准确率）产生误导，并导致模型学习不到少数类的特征，从而失去对少数类的预测能力。**
### 如何评估不平衡数据集下的模型性能？
既然准确率在类别不平衡问题中具有误导性，我们就需要使用更合适的评估指标来衡量模型的真实性能。这些指标通常基于一个叫做**混淆矩阵（Confusion Matrix）**的工具。
对于一个二分类问题，混淆矩阵如下：

|                |     预测为正类      |     预测为负类      |
| :------------- | :-----------------: | :-----------------: |
| **实际为正类** | TP (True Positive)  | FN (False Negative) |
| **实际为负类** | FP (False Positive) | TN (True Negative)  |

*   **TP (真正例)**：样本的真实类别是正类，模型也预测为正类。
*   **FN (假负例)**：样本的真实类别是正类，但模型错误地预测为负类。（第I类错误，漏报）
*   **FP (假正例)**：样本的真实类别是负类，但模型错误地预测为正类。（第II类错误，误报）
*   **TN (真负例)**：样本的真实类别是负类，模型也预测为负类。
通常，我们将我们更关心的少数类定义为“正类”（Positive Class）。基于混淆矩阵，我们可以定义以下几个关键指标：
1.  **准确率 (Accuracy)**
    $$
    Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
    $$
    它衡量的是所有样本中被正确分类的比例。如前所述，这个指标在类别不平衡时是不可靠的。
    
2.  **精确率 (Precision)**
    $$
    Precision = \frac{TP}{TP + FP}
    $$
    它衡量的是所有被模型预测为正类的样本中，有多少是真正的正类。这个指标也叫作“查准率”，它反映了模型预测的“准确性”。高精确率意味着模型预测为正类的结果很可信，误报较少。
    
3.  **召回率 (Recall)**
    $$
    Recall = \frac{TP}{TP + FN}
    $$
    它衡量的是所有真实为正类的样本中，有多少被模型成功地预测出来了。这个指标也叫作“查全率”或“敏感度”（Sensitivity），它反映了模型对正类的“识别能力”。高召回率意味着模型能够找出大部分的正类样本，漏报较少。
    
4.  **F1-Score**
    精确率和召回率往往是一对矛盾的指标。如果我们希望提高召回率，可能会把更多样本预测为正类，这可能导致精确率下降。反之亦然。F1-Score是精确率和召回率的调和平均数，旨在对二者进行综合考量。
    $$
    F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
    $$
    当精确率和召回率都较高时，F1-Score也会较高。它是一个比准确率更可靠的指标，尤其是在类别不平衡的情况下。
    
5.  **AUC (Area Under the ROC Curve)**
    ROC曲线（Receiver Operating Characteristic Curve）是一个以**假正例率（FPR）**为横坐标，以**真正例率（TPR，即召回率）**为纵坐标绘制的曲线。
    $$
    FPR = \frac{FP}{FP + TN}
    $$
    $$
    TPR = Recall = \frac{TP}{TP + FN}
    $$
    ROC曲线下的面积就是AUC值。AUC的取值范围在0.5到1之间。
    *   AUC = 1：完美的分类器。
    *   AUC > 0.5：分类器性能优于随机猜测。
    *   AUC = 0.5：分类器性能等同于随机猜测。
    
    AUC是一个不依赖于特定阈值的评估指标，它能够全面地衡量模型在所有可能阈值下的“排序”能力，即模型将正类样本排在负类样本前面的能力。因此，它在类别不平衡问题中是一个非常鲁棒且常用的评估指标。
### 解决类别不平衡问题的主要方法
解决类别不平衡问题的方法主要可以分为三个层面：
1.  **数据层面**
    这是最直接的方法，通过调整数据分布来减轻不平衡。
    *   **过采样 (Oversampling)**：增加少数类样本的数量。最简单的方法是随机复制少数类样本，但这样容易导致过拟合。更高级的方法是**SMOTE (Synthetic Minority Over-sampling Technique)**，它通过在少数类样本之间进行插值来生成新的、合成的样本，从而避免了简单的复制。
    *   **欠采样 (Undersampling)**：减少多数类样本的数量。最简单的方法是随机丢弃多数类样本，但这可能会丢失一些重要信息。
2.  **算法层面**
    通过修改学习算法来适应不平衡数据。
    *   **代价敏感学习 (Cost-Sensitive Learning)**：为不同类别的错分分配不同的代价。例如，在欺诈检测中，将欺诈交易（少数类）错误地预测为正常交易（FN）的代价要远高于将正常交易错误地预测为欺诈交易（FP）的代价。通过在损失函数中引入这些代价，可以引导模型更加关注少数类。
    *   **集成学习方法**：例如，可以训练多个模型，每个模型使用多数类的不同子集和全部的少数类数据，最后将这些模型集成起来。
3.  **评估层面**
    如上所述，放弃使用准确率，转而使用更合适的评估指标，如**精确率、召回率、F1-Score和AUC**。
### 图像分割中的类别不平衡问题
在图像分割任务中，类别不平衡问题有其独特的表现形式。它不再是关于数据集中不同类别图像的数量不平衡，而是**单张图像内部不同类别像素的数量不平衡**。
*   **定义**：在图像分割中，类别不平衡指的是图像中某些类别（通常是背景）占据了绝大多数像素，而我们感兴趣的目标类别（前景）只占了非常小的一部分像素。
*   **典型场景**：
    *   **医学影像分析**：在CT或MRI扫描图像中，微小的病灶或肿瘤（前景）相对于巨大的背景（正常器官和组织）来说，像素数量极少。
    *   **卫星图像分析**：在遥感图像中，道路、河流或建筑物（前景）相比于大片的森林、农田或水域（背景），像素占比很小。
    *   **自动驾驶**：街景图像中，行人、交通标志等关键小目标的像素数量远少于道路、天空和建筑物的像素。
### 图像分割中类别不平衡带来的问题
这个问题在图像分割中尤为突出，因为损失函数通常是逐像素计算的。如果使用标准的交叉熵损失函数，会带来以下严重问题：
1.  **损失函数被多数类主导**：由于背景等多数类像素数量庞大，它们在总损失中的贡献会淹没前景少数类像素的贡献。模型的梯度更新将主要由多数类驱动。
2.  **模型学习偏向**：为了最快地降低整体损失，模型会倾向于将所有像素都预测为多数类（例如背景）。这会导致模型对少数类（例如病灶）的检测能力极差，甚至完全无法识别。
3.  **评估指标失效**：与分类任务类似，像素级别的准确率（Pixel Accuracy）会变得虚高。一个将所有像素预测为背景的模型，在一张前景只占1%的图片上，依然能获得99%的准确率，但这对于分割任务毫无意义。因此，我们需要更关注**IoU (Intersection over Union)** 或 **Dice Coefficient** 这类指标。
### 针对图像分割的损失函数解决方案
在图像分割中，解决类别不平衡最常用和最有效的方法之一就是从损失函数层面进行优化。以下是几种主流的损失函数：
1.  **加权交叉熵损失 (Weighted Cross-Entropy Loss)**
    这是最直观的改进方法。它为标准交叉熵损失中的每个类别分配一个权重，通常少数类的权重大于多数类。
    $$
    L_{WCE} = - \sum_{i=1}^{N} \sum_{c=1}^{C} w_c \cdot y_{ic} \log(p_{ic})
    $$
    *   $N$ 是总像素数，$C$ 是类别数。
    *   $y_{ic}$ 是一个指示变量，如果像素 $i$ 的真实类别是 $c$，则为1，否则为0。
    *   $p_{ic}$ 是模型预测像素 $i$ 属于类别 $c$ 的概率。
    *   $w_c$ 是类别 $c$ 的权重。一个常见的设置是使用类别频率的倒数作为权重，即 $w_c = \frac{1}{\text{frequency}(c)}$。这样，像素数量越少的类别，获得的权重就越高，其在损失计算中的重要性也随之提升。
2.  **Focal Loss**
    Focal Loss 最初是为目标检测中的极端前景-背景不平衡问题设计的，但它在图像分割中同样非常有效。它通过修改标准的交叉熵损失，使得模型能够更专注于学习难分类的样本。
    $$
    L_{Focal} = - \sum_{i=1}^{N} \sum_{c=1}^{C} \alpha_c (1 - p_{ic})^{\gamma} y_{ic} \log(p_{ic})
    $$
    *   $(1 - p_{ic})^{\gamma}$ 是**调制因子 (modulating factor)**。当一个像素被模型轻松、高置信度地正确分类时（即 $p_{ic}$ 趋近于1），这个调制因子会趋近于0，从而极大地降低该像素对总损失的贡献。反之，当一个像素被错误分类时（$p_{ic}$ 趋近于0），调制因子趋近于1，其损失基本不受影响。
    *   $\gamma$ (gamma) 是**聚焦参数 (focusing parameter)**，$\gamma \ge 0$。当 $\gamma > 0$ 时，调制因子的作用被放大，使得模型可以更加忽略易分类样本。$\gamma=0$ 时，Focal Loss退化为标准的交叉熵损失。
    *   $\alpha_c$ 是一个加权因子，类似于加权交叉熵中的 $w_c$，可以用来平衡不同类别的重要性。
    通过这种方式，Focal Loss让模型把“注意力”从大量的、易于分类的背景像素上移开，集中于学习那些稀疏的、难以分类的前景像素。
3.  **Dice Loss**
    Dice Loss 直接优化分割任务中常用的评估指标——Dice系数（Dice Coefficient）。Dice系数衡量的是预测分割区域和真实分割区域的重合度。
    Dice系数的计算公式为：
    $$
    Dice = \frac{2 |A \cap B|}{|A| + |B|} = \frac{2 \cdot TP}{2 \cdot TP + FP + FN}
    $$
    *   $A$ 是预测的分割掩码，$B$ 是真实的分割掩码。
    Dice Loss 就是简单地用 $1 - Dice$ 来定义：
    $$
    L_{Dice} = 1 - \frac{2 \sum_{i=1}^{N} p_i g_i}{\sum_{i=1}^{N} p_i^2 + \sum_{i=1}^{N} g_i^2}
    $$
    *   这里的 $p_i$ 是模型对像素 $i$ 的预测概率，$g_i$ 是真实标签（0或1）。
    Dice Loss 对于类别不平衡问题非常鲁棒，因为它在计算中只关心TP, FP, FN，而忽略了大量的TN（真负例，即正确预测的背景像素）。无论背景有多大，都不会影响Dice Loss的计算。这使得它天然地聚焦于前景的分割效果。
4.  **Tversky Loss**
    Tversky Loss 是 Dice Loss 的一个泛化形式。它引入了两个参数 $\alpha$ 和 $\beta$，可以分别调整假负例（FN）和假正例（FP）的权重。
    Tversky 指数 (TI) 的定义如下：
    $$
    TI = \frac{TP}{TP + \alpha FN + \beta FP}
    $$
    Tversky Loss 相应地定义为 $L_{Tversky} = 1 - TI$。
    *   通过调整 $\alpha$ 和 $\beta$，我们可以权衡精确率和召回率。例如，在医疗诊断中，我们可能更不希望漏掉病灶（高召回率），此时可以增大 $\alpha$ 的值来加大对FN的惩罚。
    *   当 $\alpha = \beta = 0.5$ 时，Tversky Loss 就等价于 Dice Loss。
5.  **组合损失 (Compound/Hybrid Loss)**
    在实践中，将不同的损失函数结合起来往往能取得更好的效果。一个常见的组合是 **Focal Loss + Dice Loss** 或 **交叉熵损失 + Dice Loss**。
    $$
    L_{Total} = L_{CE/Focal} + \lambda L_{Dice}
    $$
    这种组合的好处是：
    *   交叉熵或Focal Loss提供了平滑的梯度，有助于模型在训练初期稳定学习。
    *   Dice Loss直接优化IoU指标，对类别不平衡不敏感，有助于在训练后期精细调整分割边界，提升最终的分割性能。

通过选择或设计合适的损失函数，我们可以有效地缓解图像分割中的类别不平衡问题，引导模型学习到真正有价值的前景特征，从而显著提升分割任务的准确性和鲁棒性。
