---
type: paper-note
tags:
  - cv
  - image-segmentation
  - industrial-vision
  - supervised-learning
  - weakly-supervised-learning
  - unsupervised-learning
status: todo
paper_title: An overview of industrial image segmentation using deep learning models
year: 2025
paper_pdf: papers/An overview of industrial image segmentation using（2025）.pdf
---
论文原文：[An overview of industrial image segmentation using deep learning models](https://www.oaepublish.com/articles/ir.2025.09)

本地论文文件：[论文](../../../../99_Assets%20(资源文件)/papers/An%20overview%20of%20industrial%20image%20segmentation%20using（2025）.pdf)
***
# 工业图像分割：深度学习模型的应用综述

本文对工业图像分割领域中深度学习模型的应用进行了全面综述，详细介绍了传统图像分割算法、深度学习方案以及两者的融合方法。文章根据标注标签的数量和质量，阐述了监督学习、弱监督学习和无监督学习框架下深度学习在图像分割中的开创性工作。同时，比较并分析了大量在工业基准数据集上进行的方法，并讨论了深度学习图像分割所面临的挑战与机遇。

## 摘要

图像分割在人工智能和计算机视觉中扮演着至关重要的角色，在工业分拣、缺陷检测、场景理解和视频监控等领域有着广泛的应用。随着并行计算技术的发展，众多基于深度学习（DL）的分割算法在效率和准确性上展现出卓越的性能。本文以DL图像分割为中心，详细介绍了近年来的文献，包括传统图像分割算法、DL方案以及前两者的融合。文中根据标注标签的数量和质量，阐述了DL在图像分割中的开创性工作，涵盖了监督、弱监督和无监督框架。在工业基准数据集上对多种方法进行了比较和分析，并使用标准评估指标。最后，讨论了DL图像分割面临的挑战和机遇，以期为未来的研究提供方向。

### 关键词
图像分割、深度学习、神经网络

## 1. 引言

计算机视觉是人工智能的重要组成部分，研究如何使机器从图像中感知并做出决策。图像分割是计算机视觉中最基础的任务之一。通常，它指的是根据图像或视频帧中的对象，将图像或视频帧分割成几个目标区域的任务。这在许多感知系统中是关键组成部分，并在广泛的应用中发挥核心作用，例如工业分拣、自动驾驶、缺陷检测、虚拟现实交互等。智能医疗设备、装载工具和识别系统的制造对于推动工业数字化升级和转型至关重要。因此，图像分割值得深入研究。

图像分割依赖于目标和背景的先验知识和抽象表示来将目标从背景或其他错误对象中区分开来。它是图像理解的重要组成部分，旨在分离目标和背景以进行目标识别和其他后续处理。准确的定位将直接影响后续处理结果。为了实现这一目标，多年来开发了广泛而有效的技术，包括基于传统数字图像处理方法的技术，例如阈值分割、边缘检测和区域增长、主动轮廓模型（ACMs），以及最近使用的卷积神经网络（CNNs）、生成对抗网络（GANs）或Transformer。尽管这些方法取得了显著进展，但图像分割在精确描绘复杂对象边界、优化网络结构以及处理多领域数据方面仍面临挑战。

传统图像分割方法主要基于数学和图像处理算法，根据基本图像特征划分图像像素。传统图像分割根据灰度、颜色、纹理、形状等特征将图像分割成若干不重叠的区域。这些分割后的目标使这些特征在同一区域内显示出相似性，而在不同区域之间显示出显著差异。传统图像分割机制广泛应用于纺织、红外、遥感、缺陷检测等领域。常见的分割方案包括阈值法、边缘检测法、聚类算法和图论等，它们通过不同的数学建模实现了图像中感兴趣目标区域的自动提取和识别。这些方法能够以简单的模型实现和低计算复杂度产生可接受的分割结果。

并行计算技术（如深度学习（DL）和计算统一设备架构（CUDA））的快速发展直接推动了计算机视觉和图像处理进入了一个新的技术时代。DL已广泛应用于智能交通导航、缺陷检测、人类行为识别等领域。作为计算机视觉中的基本问题之一，图像分割技术广泛应用于机器人控制、缺陷检测、自动驾驶、辅助医疗等领域。基于DL的图像分割根据灰度、颜色、空间纹理和几何形状等特征将图像划分为几个特定且独特的区域，并提取感兴趣的目标。与依赖手动设计特征的传统图像分割技术不同，基于DL的图像分割自动学习和提取图像的复杂特征，从而实现更复杂的图像分割任务。

基于DL的图像分割可分为三类：语义分割、实例分割和全景分割。语义分割是指将图像中的**每个像素**划分到预定义的类别中，例如车辆、行人、绝缘体等。它们广泛应用于场景理解和缺陷检测等领域。然而，语义分割框架无法区分同一类别内的不同实例。实例分割更加精细，旨在检测图像中的**所有目标实例**。它不仅需要区分不同的语义类别，还需要区分每个类别中的不同目标。全景分割结合了语义分割和实例分割，以预测场景图像中每个像素的语义类别，并为属于实例目标的像素分配实例识别号。全景分割可以对不同场景组件进行可视化，包括各种场景部分的检测、定位和分类。基于DL的图像分割方法发展迅速，但仍面临以下挑战：

* DL模型的性能取决于数据集的质量和规模。标注成本高昂，且标注质量难以保证无噪声。工业数据标注的专业性和准确性要求更高。
* 目标的多种姿态或视角问题限制了DL图像分割在不同实际应用场景中的多样性。
* 基于DL的模型结构复杂，参数众多，需要大量的计算资源（包括CPU、GPU、TPU等硬件设备）进行训练，这降低了实时和灵活应用的可能性。

针对上述问题，图像分割领域的学者们探索了各种方法来解决多源域数据、多模态场景和少量样本等挑战。Pei等人将多级对抗学习和多模态一致性损失引入多模态心脏分割和跨模态肝脏分割。该框架将多源数据特征转换为目标域，并实现了多源无监督域适应。根据样本和域内样本扩展之间的空间相关性，设计了一种弱监督高光谱图像（HSI）分类方案，用于少量样本训练，增强了HSI的分类稳定性和准确性。具有动态参数的卷积滤波器用于各种样本，可学习的描述性卷积自适应地学习轻量级动态卷积网络（LDCNet）中的精细纹理特征，降低了计算复杂度并提高了实时性。

基于DL，利用传统图像处理技术通过网络模型和学习策略增强分割性能和效率的图像分割方法逐渐进入公众视野。DeepSnake将snake算法（传统ACMs中的一种）与基于轮廓的渐进式调整策略相结合。DeepSnake逐步优化初始轮廓以接近目标边界，在保持高实时性的同时实现了出色的性能。然而，DeepSnake传播局部相邻轮廓顶点的特征来细化轮廓顶点，而不是逐像素预测，这能够纠正显著的预测错误。Yin等人将水平集方法（LSM）引入神经网络，将水平集作为输入并构建相关损失函数来限制预测的水平集，例如使用长度项来平滑边界。

随着DL技术的发展，图像分割研究取得了显著进展，并广泛应用于缺陷检测、工业质量检测、料箱拾取和地图生产等领域。本次综述梳理了该领域发展过程中的关键节点，并介绍了一系列重要的算法和架构，重点关注数据状态对DL发展的重要性。DL在缺陷检测和工业分拣等各种领域得到广泛探索。对DL技术的未来发展趋势进行了前瞻性讨论，包括未来发展过程中潜在的挑战和机遇。

在现有工作的基础上，本文总结了传统图像分割的研究成果，并系统地阐述了基于DL的图像分割方法。本综述主要根据数据集的标注水平，对工业图像分割的三个分支（即监督、弱监督和无监督图像分割）的最新进展进行了研究。结合传统分割方法，基于DL的图像分割领域有大量论文。本文提供了在知名会议和期刊上发表的有影响力的工作。然后，阐述了常用的分割数据集、相关评估指标和性能分析。最后，实时和功能性DL图像分割面临着诸多挑战和发展方向，希望为更灵活、高效的DL图像分割提供参考和帮助。

## 2. 传统图像分割

传统分割方法通常依赖拓扑学、数学建模、图像处理等对图像进行分割，主要包括基于阈值、区域、边缘、聚类、能量泛函、图论和小波的方法。

### 2.1 阈值法

阈值法的基本思想是不同目标具有颜色、灰度、轮廓等不同的特征。由于特征之间的小差异，根据比较结果选择特定阈值将像素分类到适当的类别中，从而将目标对象从背景中区分出来，实现快速图像分割。阈值法最关键的一步是根据一定的准则函数求解最优阈值。给定一幅原始图像 $I(x, y)$，特征值 $T$ 能够将原始图像分为前景和背景，分割后的图像表示为：
$$
f(x, y) = \begin{cases} t_0, & I(x, y) < T \\ t_1, & I(x, y) \geq T \end{cases} \quad (1)
$$
此外，Otsu 算法，又称最大类间方差算法，根据均值和方差的概率密度对图像进行分割，不假设特定的概率密度函数，这显著提高了算法的计算速度。许多研究都是基于 Otsu 方法进行的。Bhandari 等人提出了一种结合像素强度值、直方图特性和空间信息的基于能量的三维 (3D) Otsu 算法。该 3D Otsu 算法在日常彩色图像分割方面产生了令人满意的结果。Ma 等人将逆向学习策略和自适应加权策略引入鲸鱼优化算法，以 Otsu 方法作为目标函数，在基准图像上表现出高效的收敛精度。

阈值分割方法适用于目标和背景占据不同灰度范围的图像。然而，不均匀的光照和噪声干扰仍然需要解决。不均匀的光照导致直方图中的目标峰与背景峰混合，从而降低了阈值方法的有效性。噪声对图像处理的整个过程都有影响，导致可分离的灰度峰消失并造成大量分类错误。

### 2.2 基于区域的方法

基于区域的图像分割策略利用图像的空间特性和同一类别像素的相似性准则，例如灰度相似性、纹理相似性、颜色相似性等，来分割出目标区域。它主要包括三种方法：分水岭法、区域划分与合并法及区域增长法。

分水岭法是一种基于数学形态学的分割方法，具有拓扑学原理。其基本思想是将图像建模为测地学中的地形。图像中每个像素的灰度值对应于该点的海拔。每个局部最小值及其影响区域被称为一个分水岭，其边界形成一个分水岭。Tian 等人改进的分水岭算法结合伪彩色图像变换、主成分分析（PCA）和波段比方法，以快速计算速度、准确定位和对微弱边缘变化的敏感性等优点，检测未受损的水果表面缺陷。然而，对于噪声、低对比度和明亮边缘（如气泡图像）的图像，干扰会导致分割轮廓的偏移。因此，Peng 等人提出了一种具有最佳标记和边缘约束的分水岭分割方案，用于融合前景标记和纠正分割结果。

区域划分和合并方法是将图像分割成不相交的子区域，然后根据相关准则分割或合并这些子区域。该方法适用于灰度和纹理图像分割，无需预先指定种子点。然而，分裂和合并算法可能会破坏分割区域的边界。区域增长算法以一组代表不同增长区域的种子像素开始，然后不断将种子像素邻域中符合条件的像素合并到种子像素所代表的增长区域中。同时，它利用新添加的像素作为新的种子像素，直到没有新像素满足增长准则。噪声和不均匀的强度仍然会导致空洞和过分割，并且这种区域增长方法在图像中对比度低的区域表现不佳，尽管区域增长算法广泛应用于水质分析、可见点云分割等领域。

### 2.3 基于边缘的方法

边缘是指图像中两个不同区域边界线上的连续像素集合，反映了局部特征（如灰度、颜色）的不连续性。基于边缘的分割方法源于边缘的灰度值在图像分割中表现出阶跃或屋脊状变化这一观察。阶跃边缘两侧的灰度像素值存在显著差异，而屋脊状边缘位于灰度值上升或下降的转折点。因此，采用一阶导数的极值和二阶导数的零交叉来确定边缘，这通过卷积算子等实现。常见的边缘分割算子包括Sobel和Prewitt算子等。这些方法将图像转换为灰度形式，然后计算像素值之间的梯度或差异以寻找边缘。

传统的边缘检测算法通常需要对梯度或差异进行阈值处理，以区分边缘和噪声。因此，阈值选择和噪声对这些算法的分割精度有严重影响。研究人员也对这些问题和应用进行了一些新的研究。Ghodrati等人将不同分辨率的图像边缘检测解决方案结合起来测量材料表面粗糙度，这为在线评估聚合物材料粗糙度提供了实用的解决方案。Xu等人设计了一种优化的边缘检测方法，用于基于数学形态学、Canny和高斯拉普拉斯算子的不同时间红外图像中的裂缝检测。Lu等人将局部最大类间方差计算引入Canny边缘检测框架，以有效选择阈值，用于热图像中的自动空心检查。这些改进提高了传统边缘检测算法的实用性和灵活性。

### 2.4 基于聚类的方法

聚类算法是一种无监督机器学习方法，无需标签即可发现常见聚类类别。将聚类应用于图像分割领域的本质是迭代地将具有相似特征的像素聚类到同一区域。聚类技术在各种图像分割任务中得到更新和应用。基于时空分离的聚类分割（STSCS）算法增强了脉冲红外热成像图像，通过小波分解和K均值聚类实现有效分割，以检测小至101μm直径的亚表面缺陷。Chen等人提出了结合模糊成员关系和邻域信息的基于模糊聚类的全局特征与所提出的自表示系数模型，以抵抗红外图像中的强度不均匀性和复杂背景。常见的聚类算法归纳为三类：基于距离的算法、基于密度的算法和基于连接的算法。

K-means算法使用距离作为数据相似性的度量，这意味着距离越小，属于同一簇的可能性越高。在K-means算法中，不同簇k的值需要根据不同的应用场景进行选择。基本上，与K-means算法一致，Achanta等人提出了一种简单线性迭代聚类（SLIC），它生成紧凑整齐的超像素，超参数更少，并且在运行速度、超像素紧凑性和轮廓保持方面具有一定优势。后来，提出了一种结合SLIC和自动可调模糊C均值（FCM）算法的图像分割方法，该方法基于高斯径向基函数核。该算法用于图像分割和DL网络，具有强大的鲁棒性和提高的运行效率，尽管它不能很好地获取弱边界信息，导致分割效率不足。

Fukunaga 最早提出的均值漂移算法是一种典型的基于密度的非参数估计。均值漂移算法通过将具有相同模点（mode points）的像素聚类到同一区域来实现图像分割。当聚类中心数量未知时，它能够适应任何形状的聚类，并对初始化具有鲁棒性，对噪声不敏感。然而，其带宽参数 $h$ 的选择显著影响最终的分割结果。如果 $h$ 过小，收敛速度会很慢。当 $h$ 设置过大时，聚类效果不理想。由于器官重叠和噪声，Ranjbarzadeh 选择了使用均值漂移算法来增强器官边缘，并使用 FCM 和 Kirsch 滤波器来分割肝脏和肿瘤，但其运行时间和复杂度较高。

基于密度的空间聚类噪声应用（DBSCAN）是一种源于连接性和密度函数的空间聚类算法，它对灰度数据进行聚类并最终进行着色。由于图像中的多个像素可以聚类在一起形成更大的对象，DBSCAN中确定的每个类别主要由样本分布的聚集程度决定。Qiu等人提出了一种改进的DBSCAN，通过局部窗口和多尺度滑动窗口快速提取候选对象，以实现红外小目标检测的自适应阈值分割。然而，如果处理后的图像具有大量簇或复杂的背景颜色，分割效果不理想，且计算时间较高。

### 2.5 基于能量泛函的方法

基于能量泛函的方案主要指活动轮廓模型（ACMs）。它们采用连续曲线来表示目标边缘，并定义能量函数，使其自变量包含边缘曲线。因此，分割过程转换为解决能量泛函的最小值问题。根据曲线在这些模型中的不同表达形式，ACMs分为两类：参数化ACMs和几何ACMs。参数化ACMs基于Lagrange框架，直接以参数化形式表示曲线。几何ACMs的曲线运动过程以曲线的几何测量参数为基础，而不是轮廓的表达参数。

参数化 ACM 最具代表性的模型是 Kas 等人提出的 Snake 模型，该模型已成功应用于生物图像分割的早期领域，但其分割结果受初始轮廓设置影响很大，且难以处理曲线拓扑结构的变化。此外，其能量泛函仅依赖于轮廓参数的选择，这可能陷入局部极小值，无法分割凹形对象边界。鉴于这种情况，Xu 等人引入了梯度矢量流（GVF）外部力，该力扩散灰度梯度矢量或二进制边缘图，其梯度幅度与距目标的距离成反比。

与Snake模型相比，GVF模型的初始曲线位置敏感性降低，并具有相应的凹形收敛能力。然而，噪声鲁棒性降低，弱边缘保护不足。对于具有弱边缘和噪声的图像分割，2022年利用自适应截断方程半径和去噪变分项的有效ACM（Active Contour Model）被用于分割严重噪声和灰度不均匀的图像，如遥感图像和脑部磁共振图像。随后，设计了一种具有优化偏置校正（BC）和局部预拟合方程的去噪ACM，用于实现弱边界图像分割并获得对重噪声的鲁棒性。对于印刷电路板（PCB）的自动无损检测，Yun等人提出的分层识别技术能够自动、无监督地确定3D X射线CT（计算机断层扫描）堆栈中哪些切片对应于物理PCB的特定层，并在一个4层PCB上进行了验证，事后基于水平集的分割有效地解决了灰度不均匀性问题。

几何 ACMs 与参数化 ACMs 相比，能够处理拓扑结构的变化。LSM 被引入，将曲线演化转化为水平集求解问题，它利用高阶水平集函数来描述轮廓。测地线主动轮廓（GAC）是**最早的基于边缘的几何 ACM**，它利用图像梯度信息驱动演化曲线更接近对象边界，并整合了黎曼几何中的测地线构造概念，使得轮廓能够精确检测模糊边界。然而，这种方法对初始曲线位置的选择敏感。

随着进一步发展，基于区域特征的框架逐渐涌现。在 Mumford-Shah (MS) 模型的基础上，Chan-Vese (CV) 模型将原始平滑拟合方程替换为简化的分段常数计算函数。利用图像的全局信息，它简化了计算复杂性，但在分割灰度不均匀的图像时失败。给定一个像素点 $x$，CV 能量函数写为：
$$
E_{CV}(C, c_1, c_2) = \lambda_1 \int_{outside(C)} |I(x) - c_1|^2 dx + \lambda_2 \int_{inside(C)} |I(x) - c_2|^2 dx + \nu \cdot |C| \quad (2)
$$
其中 $c_1$ 和 $c_2$ 分别表示曲线外部和内部的平均灰度值。$\lambda_1, \lambda_2, \nu$ 是常数，$|C|$ 表示曲线的长度。方程 (2) 的前两项是数据驱动项，使曲线向目标边界演化，而长度项起到平滑曲线的作用。

针对不均匀强度，涌现了许多基于局部图像信息模型，例如局部二值拟合（LBF）和局部 Kullback-Leibler 散度（LKLD）模型等。以最小化 LBF 能量泛函为例，曲线 $C$ 用水平集函数 $\phi$ 表示，其重构能量方程如下：
$$
E_{LBF}(\phi, f_1, f_2) = \sum_{i=1}^{2} w_i \int_{\Omega} \left[ \int K_{\sigma}(x-y)|I(y) - f_i(x)|^2 M_i(\phi) dy \right] dx + \eta P(\phi) + \xi L(\phi) \quad (3)
$$
其中 $f_1$ 和 $f_2$ 分别表示曲线内部和外部附近小领域的平均值，$K_{\sigma}$ 表示标准差为 $\sigma$ 的高斯核，$w_i (i=1,2)$ 是固定的权重参数。此外，$M_1(\phi(x)) = H_{\epsilon}(\phi(x))$ 表示近似的 Heaviside 函数，定义为：
$$
H_{\epsilon}(x) = \frac{1}{2} \left(1 + \frac{2}{\pi} \arctan\left(\frac{x}{\epsilon}\right)\right) \quad (4)
$$
$M_2(\phi) = 1 - H_{\epsilon}(\phi)$ 解释了像素点位于曲线外部；$\eta$ 和 $\xi$ 分别是关于距离正则化表达式 $P(\phi)$ 和长度限制方程 $L(\phi)$ 的常数值，它们写为：
$$
P(\phi) = \int_{\Omega} \frac{1}{2} (|\nabla\phi| - 1)^2 dx \quad (5)
$$
$$
L(\phi) = \int_{\Omega} \delta(\phi)|\nabla\phi| dx \quad (6)
$$
其中 $\delta_{\epsilon}(x)$ 是 Dirac 函数，其定义为：
$$
\delta_{\epsilon}(x) = H'_{\epsilon} = \frac{\epsilon}{\pi(\epsilon^2 + x^2)} \quad (7)
$$
由于偏置场引起的灰度重叠分布，这种 BC（Bias Correction）模型及其相应开发的 ACMs 利用图像乘法模型的偏置假设来推导图像的局部强度聚类特性并构建模型能量泛函。鉴于迭代演化中存在大量的卷积计算，显著的运算消耗影响了实用性。

### 2.6 基于图论的方法

基于图论的图像分割算法将图像分割转换为图划分问题并寻找最优解。通过不同的图划分准则和权重计算表达式，衍生出广泛的基于图的算法，例如 GrabCut 和 Random Walk。Felzenszwalb 等人引入了一种基于图论的最小生成树策略，通过图内和图间差异聚类图中的顶点以实现分割。这种方法具有很高的运行速度，因为其时间复杂度为 $O(N \log N)$。这些算法的目的是最大化划分的子图的内部相似性，并最小化子图之间的相似性。

图像分割与图论中的图最小割问题相关。图像被映射到加权无向图 $G = <V, E>$，其中每个节点 $N \in V$ 对应于图像中的每个像素，而属于 $E$ 的每条边连接一对相邻像素。边权重的值表示相邻像素之间灰度强度、颜色或纹理的非负相似性。然后，图像的割 $S$ 是图像的裁剪，其中每个分割区域 $C \in S$ 对应于该图像中的一个子图。在图论分割中，图像中的每个像素都被视为图中的一个节点，节点之间的边表示它们的相似性。最优分割原则是确保这些划分的子图在内部保持最大相似性，并且子图之间的相似性最小。

基于图的分割的本质是移除特定的边并将图划分为若干子图。根据各种相似性测量方法，构建了不同类型的图，例如 K 近邻图、完全连接图等。随后，图算法（如最小割算法、谱聚类等）被用于将图像分割成多个区域。基于图的分割框架能够处理复杂场景，例如多个对象重叠在一起，而无需预先定义要分割的对象数量。然而，它的缺点是它对图像中的噪声和边缘不敏感，这会导致过分割或欠分割。

### 2.7 基于小波的方法

小波理论由 Morlet 于 1980 年提出，通过引入尺度和平移因子，有效分析和处理信号突变和非平稳特性。小波变换 (WT) 是一种常用的数学工具。与仅获取全局频谱信息的傅里叶变换不同，WT 在时域和频域都具有高局部化特性，并且能够将时域和频域统一起来分析各种信号。它具有多尺度特性，并在不同尺度上分析信号，因此已应用于图像分割。基于 WT 的多尺度特征，Bi 等人设计了 3D 离散 WT，随后采用马尔可夫随机场 (MRF) 来实现极化合成孔径雷达 (SAR) 的图像分割。

由于二元小波变换（WT）具有检测二元函数局部突变的能力，因此被用作图像边缘检测策略。图像中局部灰度不连续处出现的边缘对应于二元WT的模值最大点。通过检测WT模值的这个最大点，可以确定图像边缘位于不同尺度，并且每个尺度的WT都能够提供一定的边缘信息。因此，可以进行多尺度边缘检测以获得理想的图像边缘用于图像分割。Gao等人利用WT获取对角线、垂直和水平方向的详细信息，提出了一种图像分解策略来自动决定分割阈值。这种方法在分割医学图像方面比最大方差和直方图谷阈值分割具有更显著的优势。

## 3. 基于深度学习的图像分割方法

传统图像分割方法在某些特定场景下是有效的；然而，它们通常难以处理复杂图像，并且需要大量的手动调整。随着深度学习（DL）的出现，图像分割领域发生了范式转变。DL 模型在从原始像素数据中自动学习分层特征方面展现出卓越的能力。这种转变提高了图像分割任务的准确性和效率，并能处理多样且复杂的数据集，为缺陷检测、自动驾驶和路径规划等各种应用的进步铺平了道路。

本节总结了许多基于DL的分割方法，包括监督模型，弱监督方法和无监督方案，根据训练数据的标签完整性和准确性进行分类。此外，考虑到传统方法提取纹理等低级特征信息的能力，还涵盖了将DL框架与传统图像分割相结合的方法。根据数据标注级别，表1和图1总结了监督、弱监督和无监督模型。

### 3.1 监督深度学习方法

现代监督深度学习（DL）模型从输入图像及其相应的标注掩码中学习，如 **图2** 所示，模型通过学习这些标注掩码来识别新数据并对其进行分类或预测。对于图像分割任务，训练数据通常包括 $N$ 个输入图像和相应的像素级标签，这意味着每个像素都对应一个标签。监督 DL 的标准评估方式，对于 $N$ 个输入和 $N$ 个输出，称为损失最小化方程：
$$
\tilde{\theta} \in \arg \min \frac{1}{N} \sum_{i} L(z(x_i), f(x_i)) \quad (8)
$$
其中 $L$ 表示衡量估计值 $f(x_i)$ 与图像分割结果 $z(x_i)$ 之间差异的误差公式。根据公式（8），标签数据的质量和数量对监督 DL 模型有严重影响，这对于图像分割来说是耗时且费力气的先验知识。

#### 3.1.1 编码器-解码器模型

卷积网络已成功应用于计算机视觉任务，特别是最初用于对象识别和分类，如 LeNet。这些图像通过输入层、隐藏层和输出层一步步处理，这一概念也已应用于后续大多数计算机视觉任务。此外，隐藏层包括卷积层、全连接层和池化层，并且随着计算资源水平的提高，CNN 因其平移不变性、参数共享和稀疏连接而成为图像分割的有影响力的框架。

与将语义分割视为区域分类不同，Long 等人的全卷积网络（FCN）将其视为像素级分类问题，FCN 中只包含卷积层。如 **图3** 所示，FCN 是基于编码器-解码器模型，其编码器设计用于下采样以提取高级语义特征，然后使用反卷积进行上采样，使分割图与输入图像大小相同。FCN 与结构化森林和小波变换（SFW）相结合，FCN-SFW 是一种融合分割算法，可有效检测钢梁中的微小裂缝，比现有方法实现更优越的分割性能。FCN 的结果分辨率过低，因为其上采样率为16倍，并且其对象之间的分割边界往往出现不正确。由于没有考虑像素之间的相关性，FCN 中空间信息容易丢失。

为了解决上述两个问题，DeepLabV1引入了空洞卷积（dilated convolution），该卷积扩大了卷积核中的扩张，以捕获更大范围的上下文信息，而无需增加计算复杂度，从而提高了CNN的感受野，同时确保了参数量。为了有效学习像素之间的关系，DeepLabV1仅比FCN提高了准确性，但整体准确性仍然不高。SegNet和U-Net都采用了与FCN相似的编码器-解码器结构，并采用精细上采样以恢复到原始图像。SegNet在解码器中利用反池化（unpooling）来上采样特征图，这与FCN中的反卷积相比减少了参数数量和计算量。如 **图4** 所示，U-Net改进了跳跃连接（skip connection），这与DenseNet不同，用于连接不同级别的特征图，使模型能够同时关注低级和高级语义特征。因此，U-Net被用于通过训练绝缘体图像来获取初步的绝缘体掩码。然而，跳跃连接施加了不必要的限制性融合方案，强制融合只在编码器和解码器中具有相同比例的特征图。Li等人改进了U-Net，结合VGG16和混合注意力模块，实现了PCB焊接缺陷的高精度分割，并满足了实时检测要求。根据U-Net，Wang等人设计了一种名为MDOAU-Net的多尺度注意力深度学习模型，该模型具有扩展卷积和偏移卷积，用于通过SAR图像分割监测水产养殖筏。

此外，DeepLabV2、DeepLabV3、DeepLabV3+和PSPNet采用空间金字塔池化 (SPP) 结构，具有精细的多感受野学习像素间关系，该结构提取特征图并将其转换为固定大小的特征向量，用于后续分类和回归任务。SPP 使模型能够处理不同大小的输入图像，并通过在不同尺度上池化特征图来提高对对象位置和大小变化的鲁棒性。受 PSPNet 启发，SE-PSPNet 准确分割 3D 编织复合材料中的缺陷，增强了小对象检测并解决了类别不平衡问题，从而提高了性能。由于多尺度输入，RefineNet 可以获得小尺寸目标的全局上下文信息。尽管这些模型增强了学习像素间关系的能力，但其参数量和推理速度无法满足实时需求。鉴于实际高实时性需求，Mobile-Deeplab 是一种轻量级像素分割的织物缺陷检测策略，在 256x256 大小图像上达到 87.11 帧/秒 (FPS)。改进的 PCB-DeepLabV3 模型结合了 Mobilenetv2 和多尺度注意力池化，实现了芯片焊点内部空洞的高精度智能分割，提高了工业检测效率。

与在解码器中通过上采样恢复分辨率不同，HRNet 并行连接高分辨率到低分辨率的卷积流，并通过多尺度特征融合在不同分辨率之间交换信息，以保持高分辨率表达。Wang 等人通过对 Sentinel-1 SAR 雷达图像进行去噪，并利用深度神经网络对其进行增强，在工业应用中实现了 70.60% 的平均交并比。此外，一些基于 DL 的模型从空间角度高效学习像素之间的上下文连接。DANet 同时引入空间注意力和通道注意力，以捕获任意两个位置和通道维度之间的上下文信息。鉴于 Transformer 能够有效捕获输入数据的全局信息，如 **图5** 所示的多个 Transformer 模块，ABFormer 通过引入边界感知模块和注意力机制，提高了缺陷语义分割的精度，解决了工业产品中类内差异和类间模糊性问题。由于这些缺点，利用来自多尺度（包括骨干网络中浅层和深层特征）的图像特征对提高准确性至关重要。

对于实时工业需求，专业的轻量级架构对于实际应用效率至关重要。ERFNet 和 ESPNetV2 等轻量级模型采用非对称编码器-解码器结构，通过牺牲精度来换取速度来移除低级特征提取结果。Peng 等人利用 ESPNetV2 提出了一种用于轧钢设备的高精度表面裂纹检测架构，该架构利用坐标注意力-深度卷积生成对抗网络（CA-DCGAN）进行数据增强，MLESPNetV2 进行精确检测，MLLSP-GAN 进行半监督学习，显著提升了实时性能。浅层和深层特征分别包含更多的空间信息和上下文信息，对于图像来说是不可或缺的。因此，一些研究人员利用轻量级网络来实现多尺度输入，同时避免使用类似于 RefineNet 中那种大型卷积核。这些典型模型包括 ICNet 等，尽管它们的分割精度可以接受，但实时速度不够理想。

此外，特征提取网络应尽可能轻量级，以减少计算资源的占用。在青光眼诊断中，Mallick 等人提出了一种带有跳跃连接的 ConvNext 编码器和解码器，实现了轻量化，并设计了一种新颖的注意力门模块用于平滑处理。此外，该方法改进了损失函数，以实现准确的模型训练。ConvNeXt-SCC 可视化轮胎冠部缺陷，并在轮胎生产中增强缺陷检测和定位性能，尽管面临数据集有限和小缺陷尺寸等挑战，它通过改进的卷积块注意力模块和 ConvNext 克服了这些挑战。

#### 3.1.2 基于区域提议的方法

基于区域提议的方法通常被认为是语义分割和目标检测任务的结合，因此它们被称为两阶段方法。根据目标检测和语义分割的序列顺序，两阶段方法进一步分为自上而下和自下而上方案。自上而下的深度学习分割技术采用先检测后分割的概念，首先为每个对象预测一个边界框，然后在每个边界框内生成一个实例掩码。相比之下，自下而上的方法利用语义分割模型进行像素嵌入投影，然后使用后处理将像素投影到每个实例上，即在检测之前完成分割。

在自上而下的深度学习图像分割中，He 等人提出的 Mask Region-based CNN (R-CNN) 采用 ResNet 作为其骨干网络，添加了一个分支来预测每个感兴趣区域 (RoI) 中的分割掩码，构建特征金字塔网络 (FPN) 来处理不同尺度的特征，并利用非极大值抑制 (NMS) 来移除具有过多交集的掩码。由于 Mask R-CNN 在 COCO 等标准数据集上优于先前的基准测试，一种名为 ABC Mask R-CNN 的智能焊接质量检测模型，利用增强型 Mask R-CNN 和注意力机制，实现了 98.20% 的准确率，提高了传统专家方法的效率，并支持地铁车身制造中的智能维护。然而，Mask R-CNN 的评估函数仅对目标检测器输出的边界框进行评分，而不是掩码预测，从而扰乱了分割结果。

Mask Scoring R-CNN 增加了 Mask IoU 头，以学习交并比（IoU）评分模板，并获得更准确的掩码。BlendMask 通过对象检测锁定实例像素的近似范围，并在该范围内对实例像素应用掩码细化，以确保实例掩码的质量。后来，Geng 等人将 BlendMask 与自上而下和自下而上的结构结合起来检测隧道缺陷。尽管深度度量学习（DML）等自下而上方法符合人类直觉，但它们通常依赖于性能等后处理方法，导致过分割或欠分割。因此，基于DL的自下而上图像分割通常不如自上而下方法主流。

如果只区分检测和分割的顺序，很难为两阶段图像分割方案带来性能提升。因此，多阶段方法应运而生，其中分割和检测不再具有顺序关系。在典型的多阶段 Cascade Mask R-CNN 中，每个级联都有一个独立的 RPN 来生成提议框，每个检测器过滤由其前一个检测器给出的具有高置信度的边界框，从而使用更准确的框提议进行检测和分割。通过级联，它在计算负担显著增加的情况下提高了分割精度。根据 Cascade Mask R-CNN，Diaz 等人提出了一种快速风力涡轮机缺陷检测模型，该模型具有深度可分离卷积，并通过图像增强和迁移学习进行增强，取得了 82.42% mAP 的卓越性能。

尽管两阶段和多阶段 DL 方法将不同尺度的对象实例转换为标准尺度并提高了分割精度，但它们缺乏足够的表示能力且效率低下。正如实验文献中所示，两阶段和多阶段 DL 方案都需要大量的训练资源。因此，将检测和分割整合到单个网络中的一阶段分割模型应运而生。根据是否存在预设的固定大小对象检测边界框，一阶段 DL 模型分为两类，即基于锚点或无锚点方案。基于锚点的图像分割主要基于 You Only Look Once (YOLO) 系列。Deeplab-YOLO 是一种轻量级的红外光伏 (PV) 面板热点缺陷检测模型，将 MobileNetV3 替换为 YOLOv5 骨干，并将 MobileNetV2 引入到 Deeplabv3+ 中进行分割。SSA-YOLO 是一种通过卷积挤压-激励模块、带有 Swin Transformer 的 Conv2d-BatchNorm-SiLU 和自适应空间特征融合模块增强的 YOLO，从而推进了钢材生产中的质量控制。

无锚点分割检测器主要基于全卷积一阶段目标检测器（FCOS），包括仅通过位置进行掩码分类和使用轮廓回归来分割标签的模型。基于明确形状编码的分割（ESE-Seg）和基于极坐标的实例分割（PolarMask）预测轮廓回归，以输出实例掩码。它们通常使用 20 到 40 个系数来参数化掩码轮廓，推理速度快且易于优化。然而，它们无法准确描绘掩码和中心有孔的物体。通过位置分割对象（SOLO）和条件卷积进行实例分割（CondInst）通过位置和大小定义实例类别。SOLO 将实例分割视为一个分类问题，并消除了任何依赖于回归的问题，使 SOLO 自然地独立于对象检测。CondInst 容易受到不精确轮廓回归方法的影响。相比之下，基于锚点的分割的性能受到检测的影响，而获得有效锚点相对耗时。此外，这些无锚点分割模型可用作比较模型，用于评估为工业应用设计的模型的性能，因为它们推理速度快。

### 3.2 弱监督图像分割

DL分割模型的泛化能力依赖于大规模、高质量的像素级标注数据，而图像分割标注由于人工效率低下，是一个耗时且昂贵的过程。对于需要快速应用的新任务或场景，数据稀缺问题更为严重。因此，高昂的数据标注成本降低了模型在新任务中的适用性和可扩展性，从而阻碍了基于DL的图像分割模型在工业（如缺陷检测等）中的实际应用。为了缓解实际工业应用中数据标注的压力，在半监督和弱监督图像分割方面进行了大量工作。在半监督和弱监督学习中，部分图像像素被标注，而其他像素未标注。如 **图6** 所示，算法利用标注的像素标签来学习生成伪掩码的先验信息图，然后将知识应用于未标注的像素以进行类别和目标定位。

#### 3.2.1 图像级弱监督图像分割

图像级监督是指使用图像级标签（如每幅图像中包含的对象的类别标签）来训练模型，这忽略了图像中对象的位置和大小，并对学习对象边界造成障碍。与像素级标注相比，图像级标注极大地降低了数据标注的人力、时间和资金成本。Mayr 等人设计了带有 ResNet50 的 $L_p$ 归一化方法，用于通过图像级监督进行太阳能电池缺陷检测。Shi 等人通过半监督语义分割和更可靠的动态阈值策略的伪标签，改进了不同场景下的缺陷检测。然而，由于缺乏图像中目标的位置、形状和轮廓信息，通过图像级标注训练分割网络是一个极具挑战性的问题，其关键在于如何将图像类别信息转换为相应的目标位置信息。

大多数现有图像级语义模型的分割过程主要包括三个阶段。首先，利用粗粒度标注信息初步学习对象特征。由于类别激活图（CAM）无法覆盖整个相应目标，需要整合不同的 CAM 以获得更完整的目标激活区域。基于 CAM 的模型，如基于梯度的类别激活映射（Grad-CAM），使分类训练的 CNN 能够学习对象定位，而无需任何边界框。LayerCAM 将来自不同层的激活图结合起来，同时获得细粒度对象细节和精确的空间定位，在工业产品缺陷数据集 Deutsche Arbeitsgemeinschaft fuer Muster-erkennung (DAGM)-2007 上实现了 27.26% 的平均 IoU (mIoU) 的分割效果。Wu 等人提出了一种基于图像级标签和 CAMs 的弱监督缺陷分割算法，通过 Siamese 网络和改进模块增强了性能。He 等人提出了一种弱监督路面裂缝分割方法，该方法使用基于 GAN (U-GAT-IT) 模型生成的 CAMs 来生成和改进 CAMs，有效弥合了无监督和全监督方法之间的差距。一种前景-背景分离变换器 (FBSFormer)，一种弱监督像素级缺陷检测方法，通过前景-背景分离模块和注意力图细化来增强 CAM，在工业缺陷数据集上实现了卓越的性能。

将自然语言处理中的提示范式引入计算机视觉进行分割，Segment Anything Model (SAM) 被应用于半/弱监督模型以获得精确的分割输出。SAM 是 Meta 公司针对图像分割任务的开源通用模型。它利用 CNN 和 Transformer 架构的组合以分层多尺度方式处理图像，并引入提示工程思想以实现基于点、框、掩码甚至自由形式文本的提示分割。此外，SAM 使用包含至少 10 亿个掩码和 1100 万张图像的大型数据集 (SA-1B) 进行模型预训练，从而具备强大的泛化能力。

CS-WSCDNet 采用 CAM 结合定位能力和 SAM 来定位图像对的变化区域，并生成像素级伪标签来训练高分辨率场景的模型。自注意力和模型全局相关性被整合以优化初始 CAM，Siamese 结构和通用 SAM 用于联合优化策略，以在不同尺度的遥感图像中生成高精度目标边界。在光伏发电中，Yang 等人策略性地结合 SAM 和 CAM 来优化高效伪标签，并采用边界感知损失函数来管理从生成伪标签中派生的误差特征。

#### 3.2.2 边界框弱监督图像分割

基于边界框的弱监督方案采用围绕对象的边界框来训练其分割模型，允许模型根据生成的边界框范围生成分割结果。边界框提供对象的类别标签，并包含对象的数量和粗略位置信息。基于边界框的分割方法利用对象边界框的位置和大小信息，而不是对象内部的像素级标注信息，使其成为比图像级标注更强大的监督信号。因此，此类方法往往比图像级标注方法取得更好的性能。由于边界框外部的所有区域都划分为背景，并且前景和背景区域都存在于最小边界框内部，因此边界框弱监督的关键在于准确区分由边界框确定的前景对象和背景区域。

2015 年，Dai 等人提出了 BoxSup，这是第一个基于边界框标注的分割网络。BoxSup 使用边界标注和多尺度组合分组（MCG）来生成目标类别的粗略分割输出，并将其作为监督信息来训练 VGG 的参数。然后，基于当前网络，利用预测的目标分割结果作为监督，继续训练分割网络，迭代优化分割结果作为监督信息并更新网络参数。由于边界标注的类别信息和 MCG 的前景分割结果，BoxSup 实现了良好的分割精度。

在 Box2seg 中，通过预测每个对象类型的注意力图来优化像素级交叉熵损失，并计算最小边界框中每个对象类型的填充率以约束注意力图的生成，从而使注意力图更好地关注前景区域并减少不正确的梯度传播。Zhang 等人使用简单的边界框标注训练 Cut-Cascade R-CNN，在射线照相图像中实现了焊接缺陷检测的高精度。CapNet 是一种新颖的绝缘子自爆炸缺陷检测网络，使用正常样本和边界框标注，具有记忆机制、极坐标对齐损失和 MirrorFill 算法，可在无需额外人工干预的情况下增强缺陷检测。这些方案通过计算最小边界框中每个前景对象的填充率来指导分割过程，从而提高了像素级伪标签的准确性。

与弱监督语义分割相比，弱监督实例分割中使用的监督信号与目标实例直接相关。与语义相比，可学习和利用的通用先验信息相对较少，使其对目标实例的形状、大小、数量等方面变化更为敏感。然而，弱监督图像分割模型中的粗粒度标签存在不准确性、标签缺失或标签间相互干扰的问题，导致训练模型的准确性和稳定性降低。因此，需要进一步研究和改进，以通过更准确的边界框先验和标签来提高弱监督语义分割的准确性和鲁棒性。

### 3.3 无监督深度学习图像分割

无监督学习与深度学习（DL）的结合使DL模型能够发现数据中的隐藏结构，提高其泛化性能，并更好地处理结构复杂的图像分割问题。通过在无标签数据上学习其隐藏模式和结构以进行相同的语义特征描述，无监督DL不依赖标签来解决数据标注困难和大量无标签图像的问题，如 **图7** 所示。

#### 3.3.1 像素级特征关系作为先验信息

传统的无监督分割方案主要通过人工设计的图像特征和低级图像特征实现，如高斯混合模型、谱聚类和K-means聚类，这些方法用于将图像划分为具有高度自相似性或差异的多个区域。鉴于DL抽象和高级特征表示能力，结合DL的无监督特征表示学习发展迅速。正如SimCLR和MoCo中所示，无监督密集特征表示学习实质性地促进了无监督DL图像分割策略。在无监督图像分割中，一个有效的网络必须为给定图像学习密集特征图，而无需任何标注。一个有效的网络根据特征分析和建模像素之间的相似性，这些学习到的特征图用相似的特征描述表示相同语义区域（对象/事物）中的像素，而来自不同语义区域的像素则用不同的特征表示。由于网络学习过程不受标注数据指导，因此无监督分割方案通过提取像素级特征并将像素分组到不同的语义组中，根据各种独立于训练数据的先验规则构建。

Kanezaki 使用经典的机器学习无监督分割算法对输入图像进行预分类，以将相同的语义标签分配给语义信息明显相同的小区域，并采用 CNN 处理来自机器学习的细粒度预分类结果，并逐步迭代合并这些小的语义像素区域以获得预期的分割结果。Wang 等人设计了一个无监督 CNN 模型，该模型具有特征学习和自注意力模块以捕获特征，并且该模型根据特征相似性聚类标签以分割通过选择性激光熔化制造的具有各种材料的组件的表面缺陷。Wei 等人提出了一种基于 DCGAN 的多阶段无监督框架，并通过比较测试图像与从最小正常样本重建图像之间的差异来完成缺陷检测。在这些模型中，超像素分割和图像重建被组合到一个统一的网络模型中，并利用超像素特征块之间的相似性或差异来升级网络参数。从随机初始化的 CNN 中提取的像素在特征图上进行分组，以最小化相似像素之间的距离，同时最大化不同特征之间的距离，以保持特征多样性。

存在一些模型，通过最大化同一输入图像的两个视图之间像素特征的互信息，来学习图像中重复语义对象的特征表示。信息最大化和对抗正则化分割（InMARs）利用互信息聚类生成的超像素区域，以最大化输出与输入之间的依赖关系，然后将对抗正则化与数据增强策略相结合进行训练和优化。Li 等人设计了一种 PCA 拉伸对齐操作和损失函数，用于融合红外和可见图像特征，并利用可见特征图和红外特征图之间的互信息最大化来获取这些图像间像素关系，并将其与损失函数统一以优化计算和融合表示。一种混合噪声引导的互约束（MNMC），一种无监督异常模型，利用混合噪声生成和互约束来增强特征学习，有效解决了异常检测中的挑战，并在 MVTec 数据集上展示了具有竞争力的性能。Midwinter 等人提出了一种无监督语义分割方法，该方法利用姿态信息来增强视觉检测，并通过剥落量化任务进行了验证。

此外，其他模型根据启发式先验（如跨视图一致性、跨像素相似性和跨图像关系）生成密集的自监督信息，以完成无监督图像分割任务。尽管视角不同，但同一目标对象被认为是一致的，这被称为跨视图一致性。SimSiam 是一种简单的 Siamese 网络模型，无需大型批次、负样本对和动量编码器。它通过同一输入图像中两个解码器分支对两个随机增强图像的跨视图一致性进行操作。一种用于热图像热点检测的自监督学习方法，利用基于 SimSiam 的集成分类器，实现了高精度和精确的热点隔离，解决了工业安全问题。

跨像素相似性是指图像中同一语义区域包含具有高度相似线索（如颜色、纹理或亮度）的像素。FreeSOLO 是一种用于实例分割的无监督框架，它结合了分割和密集自监督学习，通过跨视图一致性生成类无关的掩码。来自不同图像的同一类别目标像素具有语义关系。由于缺乏监督信息，提取图像间语义相似的像素特征具有挑战性。Zhang 等人引入了一种隐式跨图像关系无监督分割方案，该方案具有逐像素对比学习。该模型通过聚类图像特征为训练图像中的所有像素分配伪标签，并利用这些伪标签选择合适的正样本或负样本对进行对比学习。

无监督深度学习探索如何生成密集表示信息仍处于初步阶段。与像素级特征学习不同，密集表示需要区域先验来提取像素之间的关系，这用于确定这些像素是否从属于同一语义空间。然而，先验规则通常无法处理复杂场景。不同类别的对象可能具有相似的外观，而同类别对象则可能具有显著的类内外观变化，导致算法无法有效区分特征空间中每个像素的语义特征差异。因此，如何引入更准确的区域先验并对其进行细化以实现更高效的分割学习过程，值得进一步探索。

#### 3.3.2 中间特征作为额外线索

一部分无监督学习方法不直接处理像素级特征，而是采用中间特征作为额外线索来指导语义特征分组，包括显著图、超像素和形状先验。显著性是一种图像分区模式，而显著图表示每个像素独特性的特征。提取显著图是为了简化或改变通用图像的表示，使其适合深度学习策略，以发现和分析具有相同语义类别的显著和常见前景对象。超像素通过直接聚类空间连接的像素组而不是像素来生成，从而增加了统计的可靠性，同时增加了训练批次大小，并降低了操作成本。与纹理和颜色不同，形状先验表示更适用于数据规模有限且形状变化大但颜色特征不显著的应用场景，例如器官或肿瘤区域提取。

利用一组像素组（即超像素）的特征，将无监督图像分割从像素级分类转化为无监督子区域分类。MaskContrast 采用两个额外的无监督显著性模型，为每幅图像中的前景对象生成伪标签，并分两步自举机制训练其最终分割模型。随后，通过对比学习将收集到的前景掩码聚类形成语义概念。一种无监督 PolSAR 图像分类分割框架 利用高置信度超像素伪标签和半监督方法，在三个真实 PolSAR 数据集上演示，取得了比现有方法显著更高的精度。一种基于显著性的多目标检测和分割框架 利用多分支卷积编码器-解码器网络进行环形扫描合成孔径声纳图像。尽管通过显著图减少了像素级特征表达的复杂性，但在没有通用语义类别信息指导的情况下，难以捕获有效的语义信息。

对于 DL 方案而言，仅仅使用低级图像信息是不可取的；对象边缘细节的分割精度受到限制。超像素不仅有利于保留对象边缘信息，而且还能够代表图像特征，而不是大量的像素，从而减少了模型训练的噪声干扰。Chen 等人利用超像素分割结果来监督梯度下降方向，以实现更好的 FCN 训练，从而实现了对不同尺度遥感图像的像素级分割。S3Net 是一个由超像素引导并受迁移学习启发的深度暹罗网络，它生成伪彩色图以获得同质超像素对象，从而实现理想的边界粘附和多尺度对象级差异特征。基于超像素的方法将小区域作为计算单元，独立提取特征并确定显著性值，但超像素可能生成边界模糊的显著对象特征图，导致训练不稳定。

通过实现中间特征变换、一致性信息比较以及根据显著图、超像素和形状先验的其他方案，增强了特征的语义区分能力，促进了异构像素的分离。采用中间特征作为指导来训练分割，与像素级特征图分类相比，可以有效降低计算成本和复杂性。然而，这些方法假设图像中的对象具有足够的显著性，这在某些复杂场景中并非总是如此，并且可能导致分割不准确和不稳定。

#### 3.3.3 后处理作为精修

在图像分割过程中，无监督模型需要根据颜色、纹理、边缘等特征对像素之间的相似性进行建模和分析。随后，该无监督模型将图像中的所有像素划分为不同的组，不同的组代表不同的对象类别以完成分割任务。然而，由于网络学习过程不受标注数据指导，分割结果往往不尽如人意。由于无监督学习算法涉及无标签数据的处理和学习，因此必须充分了解数据的先验结构和模型以实现预期的收敛。此外，无监督学习算法通常需要更多的领域知识来选择和调整模型，因此需要进一步的后处理或人工干预来提高分割精度和效率。

仔细检查预测掩码后，会分割出小的预测边缘或具有错误预测像素的区域。因此，在无监督学习中添加一个更精细的适应和分割边界的步骤是必不可少的。Wang 等人提出了一种用于深度学习的无监督循环方案及其相应的损失函数，以生成优化的像素级特征表达和语义标签。基于注意力门的 U 形重建网络（AGUR-Net）在 YDFID-1 数据集上实现了 59.38% 的精度，用于彩色图案织物中的无监督缺陷检测，并且双阈值分割后处理优化了检测结果。在该循环框架中，将过分割方法用于模型训练，并对聚类、阈值限制等进行后处理步骤，以将过分割的模型输出合并到预期的聚类数量中，从而进一步提高了分割效果。

此外，条件随机场（CRFs）通常作为后处理工具来提高算法性能，因为它们能够考虑整个序列的特征信息，并更好地捕获序列之间的依赖关系。HOTCRF-PCANet 结合了高阶三联体 CRFs 和无监督主成分分析网络（PCANet），被提出来用于非平稳 SAR 图像的有效分割，增强了标签一致性和特征表示。GAN 通过博弈论在框架中不断从生成网络和判别网络中学习，以实现更好的分布收敛，其中一个伪造，另一个执行检测，从而使模型能够相互训练并达到平衡。尽管 GAN 在 **图8** 所示的游戏中取得了高性能，但像素之间的关系很容易被忽略，导致特征丢失和分割结果出现不连续或显著变形。因此，CRFs 作为一种后处理方法，可捕获整个序列特征并产生更好的结构化分割。

### 3.4 深度学习与传统图像分割模型的结合

传统图像分割通常利用纹理、颜色等低级特征信息，而深度学习在高级语义特征提取方面具有强大的表现力。然而，由于池化等操作，深度学习不可避免地会破坏图像中的浅层细节，这不利于小目标的特征识别。此外，深度学习对设备性能和硬件消耗有较高要求，限制了落地应用的可能性。因此，考虑到实现的复杂性和成本，许多有效的图像分割方法通过将传统图像分割算法与深度学习相结合而涌现。

#### 3.4.1 改进理论的框架

一些框架根据传统的图像分割概念改进了深度学习模型的构建机制。有些方案基于同一对象相似的语义信息生成两个相邻像素的联合分布，并根据一系列聚类质心上的相似性分布获得分割结果。 ACM（Active Contour Model）的分割路线被应用于深度学习图像分割，其操作包括确定初始轮廓、计算轮廓上控制点的偏移量、根据此偏移量收缩轮廓曲线以近似目标边界，然后分割出轮廓。此外，还有一些模型将GrabCut中具有相似特征的像素迭代拟合到一个区域的概念融入到基于深度学习的分割框架中，例如DeepCut。

无监督聚类被应用于将相似的像素级特征聚合到一定数量的簇中，每个簇代表一种语义对象。DeepClustering 利用一个简单的过程来生成语义分布。在 DeepClustering 中，K-means 算法用于聚类模型输出的特征值，以生成分类伪标签。此后，通用分类任务的人工标注被 K-means 生成的伪标签取代，以训练神经网络分类器。作为最早的自监督表示学习方法之一，这种范式尚未取得相当可接受的性能，但其思想启发了后来的众多工作。在线深度聚类（ODC）进一步改进了每次迭代中簇中心的更新方案。将每次迭代中重置簇中心的原始更新策略改进为迭代更新方法，并通过最优匹配算法更新两个相邻的簇中心，一定程度上缓解了收敛不稳定问题。

Snake 模型 的分割思想被融合到 DL 中，以实现精确的轮廓分割。在对象检测器提供的边界框内，DeepSnake 首先生成一个初始轮廓，然后通过预测顶点偏移量来变形轮廓，以精确匹配对象形状，这表明了将结构化轮廓特征学习应用于实例分割的可能性。它使用循环卷积有效学习轮廓特征，减少了对精确边界框的依赖，并增强了处理对象定位错误的能力。与 DeepSnake 相比，一种端到端基于轮廓的方法 (E2EC) 首先通过对图像进行骨干操作生成目标中心位置的热图，并根据中心点特征回归初始偏置来学习初始化轮廓。然后，通过全局变形模块对生成的初始化轮廓进行变形以获得粗轮廓，最后进行两次变形以获得精细轮廓。这些模型特别关注复杂对象的边界检测和分割。它们有效处理不规则形状和模糊边界的对象，并理解不同上下文下对象的形状和结构，从而提高了分割精度。尽管具体的实现和优化策略不同，但它们都专注于实时性能，尤其是在需要快速响应的工业应用场景中。

#### 3.4.2 设计损失函数的框架

在深度学习中，所有算法都依赖于最小化或最大化一个函数，称为损失函数。损失函数用于衡量预测值与其对应的真实值之间的误差。当模型训练时，损失函数被最小化或最大化，使模型达到收敛状态并更新模型参数，以减少模型预测值的误差。因此，不同损失函数对模型的影响至关重要。借助额外的先验信息，如形状、区域和边缘，传统图像分割算法取得了令人满意的性能。

LevelSet R-CNN 是一种深度变分实例分割框架，它结合了 CV 模型和 Mask R-CNN 的架构，其损失函数根据 CV 模型和 Mask R-CNN 设计。Mask R-CNN 旨在对图像中的所有对象进行分类，然后通过卷积操作获得 RoI 来初始化截断符号距离函数 (TSDF) 和实例超参数。TSDF、超参数和特征张量被输入到 CV 优化模型中，以输出目标 TSDF，并通过对该 TSDF 应用 Heaviside 函数生成掩码。因此，基于最终和初始 TSDF 建立损失函数，以计算真实值和预测值之间的误差，从而进行联合端到端模型训练。后来，Nouri 等人利用原始图像及其由局部词方向模式纹理描述符生成的编码图像作为 CNN 的输入，用于参数图和 GVF 图，并引入了关于预测 ACM 参数和 GVF 图的损失表达式，以实现更准确和鲁棒的模糊边界分割。

根据传统图像分割算法定义的损失函数旨在优化分割结果或约束预测轮廓长度，以减少非目标预测结果。由于这些网络中的 softmax 层与 MS（Mumford-Shah）模型中的特征函数之间存在显著相似性，LSM（Level Set Method）自然地被整合到 CNN 中。弱监督深度水平集模型 结合了多分支结构和自监督目标，并提出了自适应算法，以水平集函数作为自监督损失项，有效分割航空发动机视频内窥镜图像中的缺陷，并在 Turbo19 数据集上实现了实时处理。这些设计的损失函数不仅可以作为监督神经网络分割的正则化项，还可以作为半监督或无监督分割，因为获取训练监督分割网络所需的数据集是困难的。

#### 3.4.3 带有预处理和后处理的框架

DL适用于高维数据处理，解决传统图像算法难以解决的问题，如多样化的缺陷分割和检测。然而，DL设备的性能要求高，硬件消耗大，模型训练成本高。此外，DL分割对训练数据有依赖性，一般来说，数据量越大，其性能越好。因此，一些研究人员从优化模型训练效率和平滑分割边界入手，利用传统图像分割作为模型预处理或后处理的一部分。这些方法依赖数据预处理中的传统图像处理，大大降低了模型的学习压力和噪声干扰。

由于样本分布不平衡以及图像数据集中存在噪声和光照变化等干扰，基于深度学习的方法利用传统的策略（如预处理）进行降噪和平滑。Lin 等人提出了 ScribbleSup，它迭代训练分割网络并使用图割来纠正像素标签。ScribbleSup 首先将图像划分为超像素形式，然后将手绘标注与超像素标注对应起来，在超像素上执行图割算法。Feng 等人采用图割方案，根据分类网络的激活种子获取更有效的监督信息，并使用全连接 CRF 进行分割平滑。

此外，基于DL的无监督算法通常需要更多领域知识来优化模型，因此采用后处理来提高分割效率。Raja等人利用非局部均值滤波器在预处理阶段进行去噪，然后联合提出贝叶斯模糊聚类、深度自编码器和softmax回归来完成脑肿瘤分割和分类。S2VNet是一个通用框架，旨在解决医学图像分割问题，它利用聚类技术从先前的切片初始化聚类中心，并与主流3D解决方案相比，具有更快的推理速度和更少的内存消耗（使用2D网络）。

#### 3.4.4 关于传统方法和深度学习分割的讨论

传统方法相对容易实现，适用于快速开发和原型设计。在数据量小、特征明显的工业场景中，传统方法可以取得良好的效果。由于其特征明确，结果通常易于解释，使工程师更容易理解和调试。然而，传统方法对图像噪声和光照变化敏感，这可能导致分割性能不佳并影响工业检测的准确性。在复杂场景中，选择合适的特征和参数需要经验，不适用于多样化的工业图像。在处理复杂或多样化图像时，传统方法的性能往往下降，难以适应不同的工业应用。

在大型数据集上，基于深度学习的方法通常能实现更高的分割精度，并对噪声和光照变化具有更好的鲁棒性。这些模型能够适应不同的工业环境，适用于复杂的工业检测任务。此外，它们能自动学习最优特征，减少了人工干预，无需手动选择特征。然而，训练深度学习模型需要大量的计算资源和时间，这不适用于资源受限的工业环境。对标注数据的需求很高，当数据不足时性能可能会下降，尤其是在特定的工业场景中。深度学习模型的可解释性较差，影响了工程师对检测结果的信任。

传统方法适用于简单、特征丰富、对实时性和可解释性要求高的场景，而深度学习方法在背景复杂、精度要求高、数据集大的应用中表现良好。根据具体的工业需求选择合适的分割策略至关重要，可能需要综合考虑实际应用的特点和资源限制。因此，在缺乏统一高效数据集导致训练监督分割网络面临挑战时，利用传统方法设计预处理、后处理或损失函数是一种有效的弱监督或无监督分割组成部分。

### 3.5 工业图像分割模型的数据分析

根据 2020 年至 2024 年 Web of Science 搜索的统计结果，基于 DL 的工业图像分割模型如 **图9** 所示。技术术语根据图像标注级别设置，即监督图像分割、弱监督图像分割和无监督图像分割。工业应用术语包括六个广泛关注的图像分割搜索领域：绝缘子缺陷、PCB、织物缺陷、磁瓦、钢轨缺陷和钢材缺陷。这些统计分析论文的类型仅限于研究论文，不包括会议论文、综述文章以及博士和硕士学位论文。

不同工业应用中深度学习方法的比例如 **图9A** 所示。可以看出，在图像分割领域，钢材缺陷研究论文所占比例最大，为35%，钢轨缺陷研究论文次之，为25%。缺陷检测应用所占比例在 **图9A** 中最大，为77%，这意味着深度学习在缺陷检测中的图像分割应用相当广泛。在绝缘子检测和磁瓦的工业应用中，深度学习方法数量较少，这可能是因为与PCB缺陷或织物缺陷等其他类型的缺陷相比，绝缘子和磁瓦缺陷的检测要求相对较低，导致相关研发投入不足。

从 **图9B** 可以看出，与监督图像分割相比，弱监督和无监督方法在工业中的应用比例较小。相对成熟的监督学习利用大量标记的训练数据来实现高精度分割结果，使其适用于需要高精度的工业应用。监督学习目标明确，模型通过学习特定的输入-输出关系来准确识别和分割目标对象。弱监督学习降低了标注数据的成本和时间，但它需要设计有效的策略来利用未标记数据，这在工业环境中可能面临复杂的背景和不断变化的条件，增加了实施难度。尽管无监督学习在数据标注成本方面具有优势，但其识别特定目标或细节的能力较弱，使其难以满足工业对高精度和可靠性的要求。

## 4. 基于深度学习的模型分割性能

本节总结了基于 DL 的分割模型的指标和数据集，通常用于评估基于 DL 的分割性能。数据集的质量、规模和多样性对图像分割方法的性能有显著影响。因此，本节还将报告基于 DL 的分割模型在相应几个分割基准上的性能估计。

### 4.1 图像分割模型的评估指标

图像分割模型的性能应从多个方面进行评估，包括准确性、视觉质量、推理速度和内存存储需求。然而，大多数研究人员都专注于评估指标来量化模型的准确性。相应的常用指标如下：

像素精度（PA）的计算基于准确预测类别的像素数量，通过比例计算获得精度比。PA 通过将正确分类的像素数量除以像素总数来获得。对于包括背景和 $N$ 个前景类别的 $N+1$ 个类别，PA 表示为
$$
PA = \frac{\sum_{i=0}^N p_{ii}}{\sum_{i=0}^N \sum_{j=0}^N p_{ij}} \quad (9)
$$
其中 $p_{ij}$ 表示类别 $i$ 被预测为类别 $j$ 的像素数量。然而，像素与分类之间的对应关系可能不准确，精度比通过平均像素精度 (mPA) 反馈，mPA 为每个类别计算，然后对总类别数量进行平均，表示为
$$
mPA = \frac{1}{N+1} \sum_{i=0}^N \frac{p_{ii}}{\sum_{j=0}^N p_{ij}} \quad (10)
$$
Dice 系数 (Dice) 主要用于计算不同样本之间的相似性，是两个集合之间的相似性度量函数。系数越大，分割效果越好。Dice 表示为预测和真实像素图重叠部分的两倍除以像素总数，其定义为
$$
Dice = \frac{2|A \cap B|}{|A| + |B|} \quad (11)
$$
其中 $A$ 是预测分割结果，$B$ 代表真实情况。

交并比（IoU）或 Jaccard 指数表示真实标签与预测图像之间重叠像素的数量除以真实标签与预测图像之间的合并像素数量。IoU 的范围从 0 到 1，定义为：
$$
IoU = \frac{|A \cap B|}{|A \cup B|} \quad (12)
$$
精度（Precision）、召回率（Recall）和 F1 分数（F1 score）可以针对每个分割类别或在整体级别上具体定义。F1 分数通过精度和召回率的调和平均值计算。它们分别定义如下：
$$
Precision = \frac{TP}{TP + FP} \quad (13)
$$
$$
Recall = \frac{TP}{TP + FN} \quad (14)
$$
$$
F1 = \frac{2 \times Precision \times Recall}{Precision + Recall} \quad (15)
$$

### 4.2 数据集

合适的数据集可确保模型能够学习正确和关键的特征，这直接影响其准确性和效率。在选择数据集时，需要根据具体的应用场景和算法要求进行选择。图像分割中常用的公开数据集包括 NEU、Kolektor Surface Defect Dataset (KolektorSDD) 等。表2总结了一些常用数据集的基本信息。

#### 4.2.1 日常场景数据集

COCO 数据集 由微软创建，涵盖了 80 个常见物体和场景类别，例如人类、动物、车辆、家具等。每张图像都配有密集的像素级分割标注，以识别每个物体的边界。COCO 数据集包含三个子集：训练集、验证集和测试集。训练集包含约 118,000 张图像，验证集包含约 5,000 张图像，测试集包含约 20,000 张图像。

Pascal VOC 数据集（[165]）来自 Pascal VOC 挑战赛，是一个用于评估图像分割算法的流行基准数据集。它包含 20 个对象类别（如人类、车辆、动物）和 10 个动作类别。此外，Pascal VOC 为每张图像提供像素级标注。该数据集包含 11,540 张图像用于对象检测和分类识别，6,929 张图像用于图像分割。

#### 4.2.2 表面缺陷检测数据集

KolektorSDD 包含电子换向器缺陷图像。具体来说，电子换向器塑料嵌入表面存在轻微损伤或裂纹。图像是在受控条件下（如均匀光照）采集的。提供了缺陷图像的像素级缺陷标注。该数据集包括从 50 个缺陷电子换向器的每个表面采集的 8 张不重叠图像，总计 399 张图像，其中 52 张缺陷图像，347 张无缺陷图像。

NEU 表面缺陷数据库包含了 1,800 张关于热轧带钢表面缺陷的灰度图像。NEU 收集了六类缺陷：氧化皮、斑点、裂纹、凹坑表面、夹杂物和划痕。每类包含 300 张大小为 200×200 的图像。NEU 数据集的特点是类内缺陷差异显著，类间缺陷存在一定的相似性，这给缺陷检测中实现精确分类带来了困难和挑战。

MVTec 异常检测 (MVTec AD) 数据集包含 5,354 张 15 种不同对象和纹理类别的高分辨率彩色图像，其中 3,629 张图像用于训练和验证，1,725 张图像用于测试。在 15 个类别中，5 个纹理类别涵盖了不同类型的规则纹理（如地毯、网格）和随机纹理（如皮革、瓷砖、木材）。其余 10 个对象类别包括具有固定外观的刚性对象（如瓶子、金属螺母）和非刚性可变形对象（如电缆），有些还包含自然对象。所有图像分辨率都在 700x700 到 1024x1024 像素之间，MVTec AD 为所有异常提供像素级真实标注。

RSDDs 数据集是专门为检测钢轨表面缺陷设计的，包括两种类型的表面缺陷数据集：I 型和 II 型。I 型数据集从快车道采集，包含 67 张 160×1,000 像素的图像。II 型数据集从普通/重载运输轨道采集，包含 128 张 55×1,250 像素的图像。两种数据集中的每张图像都包含至少一个缺陷，背景复杂且嘈杂。RSDDs 中的缺陷包括各种常见的钢轨表面缺陷，如裂纹、磨损、凹槽和异物嵌入，这些缺陷已由钢轨表面检测领域的一些专业人士进行像素级标注。

#### 4.2.3 其他工业场景数据集

DAGM-2007 数据集是专门为在工业光学检测中检测纹理背景上的各种缺陷而设计的。它包含十个子数据集，前六个是训练数据集，后四个是测试数据集。DAGM-2007 的特点是它以灰度 8 位 PNG 格式提供图像。每个数据集包含 1,000 张无缺陷图像和 150 张有缺陷图像，其中“无缺陷”图像显示纹理背景，没有各种缺陷，而有缺陷图像在纹理背景上有一个精确标记的缺陷。

高分辨率船舶数据集 FUSAR-Ship 是一种统一且标准化的船舶目标识别数据集。该数据集切片包含 15 个关键船舶目标及 98 个子类别和非船舶干扰目标。共累积了 16,144 个切片，其中包括与 AIS 信息匹配的 6,252 艘船舶、2,045 个类似于船舶的强假警报亮点、1,461 个桥梁和海岸线、1,010 个沿海区域和岛屿、1,967 个复杂海浪和杂波、1,785 个普通海面图像以及 1,624 个陆地图像。数据集中船舶切片的标注方法是以目标最小外接圆的中心为中点，向外扩展 256 像素，并以 512×512 像素的固定大小存储。

Aitex 织物图像数据集包含七种不同的织物，共 245 张图像，每张图像分辨率为 4,096×256。该数据集中的织物主要为纯色。其中，有 140 张无缺陷图像，每种织物各 20 张。共有 105 张缺陷图像，包括纺织行业中 12 种常见的织物缺陷。图像尺寸较大，允许用户使用不同的窗口大小，从而增加了样本量。所有缺陷均进行像素级标注，白色像素表示缺陷区域，其余像素为黑色。

磁瓦缺陷数据集由中国科学院自动采集，并对磁瓦的六种常见缺陷（包括裂纹、气孔、断裂、磨损、不平整和无缺陷图像）进行了图像采集和语义分割标注。该数据集包含 1,344 张图像，每张图像裁剪为不同大小的感兴趣区域（RoI）。适用于研究复杂背景下小缺陷的检测和分割技术，尤其是那些颜色、纹理和背景相似的缺陷。

### 4.3 深度学习模型的量化性能

为了便于分析图像分割领域当前的研究进展，本节将深度学习模型的量化性能在当前分割基准上列表呈现。模型分割精度，如 PA 和 mIoU，通常用作评估模型性能的标准指标。尽管大多数研究报告了标准数据集和度量指标来评估模型性能，但图像分割框架的下游场景和实现目的多种多样，导致许多研究工作报告的评估指标存在一些差异。以下表格总结了若干基于深度学习的分割模型在各种数据集上的性能，其中“-”表示原始工作中未提供相应值。

结合 **表3**，MDOAU-Net 分割 SAR 图像时，非目标或背景像素较少，其测试图像的整体精度为 0.906，比 SegNet 高 4.1%，比 U-Net 高 2.5%，比 DeepLabV3+ 高 1.8%。形状一致性单样本无监督域适应 (SC-OSDA) 在 RSDDs 数据集上，精度达到 81.7%，比 SegFormer 高 0.7%，比 Mask R-CNN 高 10.8%，且结果通过验证，而其他模型则使用 **表4** 中列出的 RSDDs 数据集进行训练。根据文献 **[88]**，SC-OSDA 生成更精细的分割，即使是容易被忽略的外观。

mIoU 指标在工业图像分割中应用最为广泛。**表5** 总结了 KolektorSDD 数据集上所回顾方法的性能。可以看出，FBSFormer 表现最佳，mIoU 达到 0.787，比 U-Net 高 0.157。除了 mIoU，还有精度、召回率和 F1 分数用于钢材缺陷检测。**表6** 收集了 MVTec 数据集上的钢材缺陷分割结果，表明 ABFormer 获得了 0.915 的 mIoU 值，0.962 的精度值，0.947 的召回率值和 0.954 的 F1 分数。基于 Transformer 的 ABFormer 极大地提高了分割性能。

每秒吉浮点运算次数（GFLOPs）和帧率（FPS）是衡量深度学习计算复杂度的两个常用指标。选择 NEU 数据集和 DAGM-2007 数据集来测试图像分割方法。如 **表7** 所示，ABFormer 在 mIoU、精度、召回率和 F1 分数方面独占鳌头，并且 GFLOPs 参数数量指标最低，这意味着 ABFormer 在计算复杂度、推理精度和参数数量方面明显优于所有其他网络。在 **表8** 中，FBSFormer 在 DAGM-2007 数据集上表现最佳，mIoU 为 79.1%，FPS 达到 78.6。

在过去几年中，基于深度学习的分割模型的性能显著提高，在不同数据集上的各项评估指标相对提高了 30%-40%。然而，由于各种原因，一些模型的性能评估缺乏可复现性。它们评估了非标准数据库的一些性能指标，或仅报告了常用基准测试子集上的少数指标。此外，许多模型实现的源代码未提供，或者模型架构难以复现。然而，随着深度学习模型的日益普及，基于深度学习的图像分割模型的发展趋势是积极和鼓舞人心的。

## 5. 挑战与展望

基于深度学习的图像分割是计算机视觉领域重要的研究方向，具有巨大的理论研究价值和广泛的应用前景，但仍面临一些挑战。深度学习技术的快速发展也带来了新的挑战和机遇。本文将阐述一些有前景和潜在的发展方向以及图像分割算法面临的挑战。

### 5.1 深度学习模型面临的挑战

设备依赖性。深度学习分割模型对硬件设备有很高的依赖性。一般来说，在 GPU 上计算时，分割结果会更理想，速度更快，精度更高。然而，大多数研究人员很难获得可用的硬件设备。因此，如何在未来图像分割的实时发展中摆脱对硬件设备的依赖，使分割模型能够在普通设备上获得理想的实验结果，这是一个值得深思的问题。此外，对于便携式和移动设备等低存储硬件，难以进行大规模操作，在短时间内实现高精度计算结果是一个重大挑战。因此，降低计算负荷和存储需求，将分割网络应用于移动设备等轻量级设备，是实时深度学习图像分割面临的重大挑战。

模型性能。与语义特征相比，基于深度学习的模型更难学习同一语义中不同个体实例的特征表达。鉴于相同的语义对象通常共享相似的语义特征，特征共享降低了特征空间的维度。尽管稀疏向量表示特定对象，但这些与实例对象对应的特征与每个个体的外观、位置和大小的随机差异相关，而这些随机差异导致了各种个体特征。因此，如果期望模型能够学习通用的实例先验特征，其难度通常大于语义特征。由于实例特征在特征空间的搜索维度大于语义特征，学习和优化实例特征表达更具挑战性。如何使深度学习模型充分利用有限的先验知识来学习实例特征，对于自动驾驶、缺陷检测、轨道监控等领域的高效实例分割和全景分割至关重要。

数据稀缺。由于真实标签不一致的约束，样本分布很可能严重不平衡，导致某些类别的样本数量过少，无法充分学习其特征表示。样本不平衡导致这些类别的模型分割性能不佳。由于噪声干扰，存在异常像素值、不完整的目标区域或图像质量低下等问题，对分割结果产生负面影响。由于缺乏真实标签对弱监督和无监督分割的约束，同一目标区域内的像素也可能具有不同的特征，尤其是在分割边界不清晰的图像时。此外，由于手动标注标签的不确定性和应用场景的多样性，在图像分割中形成一致的评估标准具有挑战性，这也给模型的训练和优化带来了一定的困境。

应用场景。工业场景通常具有复杂的背景和多样的纹理，这可能会干扰分割模型的性能。工业物体的尺寸、形状和排列各不相同，使得分割任务更加复杂。工业环境中的光照条件多变，影响图像质量和分割精度。在工业应用中，特别是对于特定类别的物体，缺乏足够的标注数据是有效训练难以克服的挑战。在许多工业应用中，分割模型需要实时处理能力，以满足生产线的需求。自然图像和工业图像之间存在显著的领域差异，导致在一个领域训练的模型在另一个领域表现不佳。

### 5.2 深度学习模型的发展趋势

自适应学习模型。目前大多数基于深度学习的分割模型都在现有数据集上进行训练和测试，其类别是固定的，不超出模型的已知范围。然而，现实世界的场景是开放的，对象类别不固定。模型在应用过程中会不断遇到新出现的类别。在自动驾驶中，可能会遇到前所未有的类别，例如驾驶过程中的洪水。因此，算法是否能够持续将未见过的场景和目标纳入知识库，并自动调整模型参数以保持终身学习能力，是一个值得研究的方向。

跨模态联邦学习。目前，少数研究人员正尝试将视觉任务与语言处理相结合。跨模态联邦学习包括两个方面。一方面，视觉任务负责提供像素级线索，然后语言模型生成标题或其他文本。另一方面，语义模型提供文本线索，视觉模型根据文本信息完成分割任务，如引用分割和引用视频分割。跨模态联合学习也将成为未来重要的研究趋势。

以数据为中心的实时分割。深度学习方案主要以模型为中心，数据相对固定，然后设计各种模型来提高预测精度。鉴于实际应用中数据可能出现的各种问题，关注现实世界中高质量的标注数据，以提高数据的质量和数量至关重要。现有的实时图像分割通常旨在分割图像中像素比例大的对象类别，而对像素比例小的类别分割较少。因此，对于细粒度小尺寸对象分割的数据，图像质量和数量值得关注。

领域自适应技术可以减少自然图像和工业图像之间的领域差异，增强模型的泛化能力。通过同时训练分类和分割等多个相关任务，可以提高模型的鲁棒性和准确性。引入注意力机制可以帮助模型关注重要特征，减少背景噪音干扰，提高分割精度。使用轻量级网络架构（如 MobileNet 和 EfficientNet）以及模型压缩技术，可以使分割模型在工业应用中实现实时处理。这些技术进步使深度学习图像分割在工业场景中的应用更加有效和可靠。

此外，鉴于传统方法在浅层图像特征提取方面的能力，深度学习分割策略宜采用传统算法对数据进行降噪和低级特征增强。利用这些浅层视觉特征，它们与人类直接感知获得的视觉特征相似，有助于改善在具有不同成像设备和环境的各种工业社区中图像的分割结果。尽管这些融合方法产生了令人满意的分割结果，但对于标签较少的工业场景，这些算法有必要整合弱监督学习策略和无监督深度学习策略，以实现更好的普适性。

## 6. 结论

这项工作研究了深度学习在各种复杂环境下图像分割方法的最新进展。介绍了深度学习图像分割任务以及工业图像分割三个分支的最新进展，这些分支根据数据集标注级别进行分类，即监督、弱监督和无监督图像分割，涉及网络架构设计、提高分割精度或速度、优化速度和精度之间的权衡以及减少手动标注数据的负担。结合传统分割方法，深度学习图像分割领域有大量文献。随后，阐述了常用的基准指标，并列举了用于评估所提模型精度和有效性的基准数据集。同时，展示了性能表格和图表，以分析这些方法在工业图像分割中的量化性能。总之，基于深度学习的图像分割既面临挑战，又在灵活实用的应用中拥抱光明前景。
